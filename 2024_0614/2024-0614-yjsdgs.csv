headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIが差別する？ セクハラする？ 人とAIとの共生のために知らなくてはいけない3種のリスク（Yahoo! JAPAN SDGs）,https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-000-1-view.jpg?exp=10800,2024-06-14T12:05:21+09:00,2024-06-14T12:05:21+09:00,Yahoo! JAPAN SDGs,yjsdgs,Yahoo! JAPAN SDGs,3631,"\n様々な業界でテクノロジーの導入が進む中、2023年はChat GPTを中心に生成AI（ジェネレーティブAI）が注目を集めた\n大きな話題を集めるChatGPTをはじめ、世の中にどんどん広まっているAI（人工知能）。しかし、その利点とリスクについて、どこまで正しく理解できているだろうか。AIと人がより良い関係を築いていくため意識すべきことについて、AIのリスク管理プラットフォームを提供するロバストインテリジェンスの政策企画責任者、佐久間弘明さんに伺った。\n""ワクワク""するサステナブルのヒントを教えてくれた人\n佐久間 弘明さん\n佐久間 弘明さん\n経済産業省でAIに関する制度整備・運用に携わった後、外資系コンサルティング会社で大手企業の経営戦略策定に従事。2023年2月からロバストインテリジェンスに入社し、日本市場における政策企画を統括している。\n誰もが知るべき3種類のAIリスク\nロバストインテリジェンスの佐久間さんは、AIの便利な使い方を学ぶと同時に、リスクを理解していくことも必要だと話す\n「AIはこれまで、先進的な企業が生産性向上のために導入するのが中心でした。いわば『閉じられた』技術だったのですが、最近は一般ユーザーにも『開かれた』ものになってきています」\n\nこう語るのは、アメリカを本拠地としてAIのリスク管理事業を展開する、ロバストインテリジェンスの佐久間さんだ。AIが「開かれた」ものになったことを世の中に大きく印象づけた出来事は、やはり2022年11月のChatGPTのリリースだろう。\n\n「プログラミング言語を使わずとも、チャット形式のやり取りの中でAIに高度な作業をこなしてもらえるのが、ChatGPTの画期的なところ。これは私の使用例なのですが、食事メニューを打ち込んで『理想の栄養摂取量と比較してください』と指示すれば、計算結果が出るだけでなく、『糖質が多いので気を付けてください』なんてアドバイスまでしてくれるんです」\n\nChatGPTなど、文章や画像などのコンテンツを自動でつくり出すのは、「生成AI」と呼ばれる技術。これを個人がビジネスシーンなどで活用していくためには、AIの得意・不得意を見極めることが大切だという。\n\n「たとえばChatGPTは、詳細な事実についての回答は精度が低いのですが、文章校正やブレーンストーミングの相手はとてもうまい。このような特性を理解してAIと作業分担をしていくとともに、『プロンプトエンジニアリング』といわれる、指示や質問の設計方法を身に付けることで、より効果的に活用できるようになります」\n\n佐久間さんはさらに、AIの便利な使い方を学ぶと同時に、リスクを理解していくことも必要だと話す。\n\n「AIリスクは大きく3種類あります。まずは、事実と異なる回答をしてしまうなどの『機能・品質』のリスク。正常に作動したとしても、社会通念に反するアウトプットが生じるなど『倫理』のリスクもあります。また、AIが敵対的な攻撃にさらされる『セキュリティ』のリスクを考慮して、個人情報を学習させないといった注意も求められます」\n\nAIが人にもたらすメリットを最大化するためには、しっかりとリスクを見据えなくてはいけない。私たちはAIが発展した今後の社会の姿をいかにイメージし、リスク対策を考えていくべきなのだろうか。\n\n「AIという技術は、人の仕事をサポートすることで人手不足の解消や生産性向上に役立てられるだけでなく、医療や災害対策などで高度なタスクを担わせることにより、これまで人だけでは対応できなかった社会課題の解決にも貢献することができます。こうした技術が社会に大きな影響を与え、人々がAIのアウトプットに日々接する時代が訪れようとしているからこそ、AIリスクへの対策は、ユーザーとサービスの提供者側が足並みをそろえて進めていかなくてはいけません」\n技術と人の共生を、社会全体で考える\nAIリスクは近年ますます複雑化している\n近年、AIリスクが実際に問題化したケースとして、佐久間さんは次のような事例を挙げる。\n\n「生成AIがつくった10枚ほどの弁護士の画像が、すべて白人系の男性と思われる画像だったケースがあるのですが、これは映像作品などの偏りあるイメージをAIが学習して、そのまま出力してしまったために生じた事態です。このような事例は、現実のバイアスを強化してしまうことにつながります。ほかにもAIチャットが自殺を誘導するような回答をしていたり、未成年の女性に性的な発言をしていた問題もありました」\n\n今後、私たちにはこうしたリスクへの対応をはじめ、AIと共生する社会の仕組みづくりが求められるが、その時にどのような価値観を大切にしていけばいいのだろうか。\n\n「内閣府が2019年に策定した『人間中心のAI社会原則』は、AIとの共生社会を考える手がかりになると思います。AIは人の幸せを追求するための技術だという『人間中心の原則』や、『教育・リテラシーの原則』『公平性、説明責任及び透明性の原則』など7項目で示された価値観は、今後も大きく揺らぐものではありません。ただ、そこで定まっているのは、あくまで『なにを目指すべきか』まで。現実に問題が生じた今、『どうやって実現していくのか』という部分が社会に問われています」\n\n2023年7月に始まったハリウッド俳優のストライキも、そうした問いを世の中に投げかけた一例といえるだろう。彼らが所属する組合では、AIが俳優の演技をデジタルデータとして利用する際の肖像権の扱いなどについて、ガイドラインの明確化を求めている。\n\n「新しい技術が浸透していく過程で、人とテクノロジーの関係性についての課題は必ず生じるものですが、AIに関しては社会全体の知見もルールづくりも不十分なまま、急速に技術が普及してしまっている。社会におけるAIのあり方について、あらゆるステークホルダーが一体になって語り合うべき段階に、すでに入っているのではないでしょうか」\n第三者視点の保証が、ユーザーの安心になる\nロバストインテリジェンスでは、誰もがAIに信頼を置ける社会作りを目指す\n佐久間さんが所属するロバストインテリジェンスでは、AIモデルの健全性・堅牢性を高めるソリューションを企業などに提供することで、AIと人の共生という社会課題にアプローチしている。\n\n「AIはつくった時点で性能が決まるわけではなく、新しいデータを学びながら高度な判断をしていくものです。そこで当社は、企業がAIモデルを作成する段階だけではなく、運用していく過程でも、継続的にリスク検証を行うサービスを提供しています。具体的には、膨大な数のテスト入力を行って、偏りのある出力がなされた際には補正をかけていくという作業を、自社のソフトウェアによって行っていくわけです。公平性が求められる人事関係の企業や、自動化の余地が大きい金融関係の企業などから引き合いをいただいていますね」\n\n同社が設立したのは2019年のこと。当時、ハーバード大学でAIの研究をしていた大柴行人さんと、その指導員だったヤロン・シンガーさんの2人が共同代表となって立ち上げると、わずかな期間で約60億円の資金を調達。アメリカの大手企業や国防総省などの顧客を次々と獲得し、2021年には日本市場への参入を達成した。これほどの急成長を実現したのは、同社の取り組む先進的なミッションが広く共感を得たためだ。\n\n「私たちが目指すのは、誰もがAIに信頼を置ける社会です。その実現のためには、AIによるサービスの信頼性を第三者的な視点から保証することで、ユーザーに安心感を持ってもらうという事業モデルが重要になると考えています」\n\n佐久間さんは経済産業省やコンサルティング会社での勤務を経て、今年ロバストインテリジェンスに入社。同社は、いわゆるテック企業と呼ばれる会社だが、佐久間さん自身はAIと社会との関係性という「文系的な関心」が決め手となって入社したという。\n\n「生成AIによるバイアスの強化などをイメージしていただければ分かりやすいのですが、AIについて考えることと、人権などについて考えることは結びついているんです。AIのサービスを提供するのも、使うのも人。私たちの仕事は、人々がAIと向き合うための環境を整えることでもあると思っています」\n\n大きな可能性に満ちたAIという技術。私たちはその恩恵をただ享受するだけでなく、リスクを含めて積極的にあり方を考えていかなければいけない。それが、より良い世の中をつくるための一歩にもつながっていくはずだ。\n取材：三菱電機イベントスクエア METoA Ginza ""from VOICE""","['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-000-1-view.jpg?pri=l&w=640&h=426&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-001-1-view.jpg?exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-002-1-view.jpg?pri=l&w=640&h=426&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-003-1-view.jpg?pri=l&w=640&h=360&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240614-00010000-yjsdgs-004-1-view.jpg?pri=l&w=640&h=426&exp=10800']","['https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee/images/000', 'https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee/images/001', 'https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee/images/002', 'https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee/images/003', 'https://news.yahoo.co.jp/articles/8a54a8bc9c06935dfecb81f4e0ff96a232b5d8ee/images/004']"
