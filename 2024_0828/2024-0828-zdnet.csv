headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AI開発にオープンソースイニシアチブで貢献--The Linux Foundationの取り組み（ZDNET Japan）,https://news.yahoo.co.jp/articles/d172d759dab4c558cafd927f9275a687f94930a6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223199-zdnet-000-1-view.jpg?exp=10800,2024-08-28T07:45:00+09:00,2024-08-28T07:45:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3117,\nAI開発にオープンソースイニシアチブで貢献--The Linux Foundationの取り組みの画像\n香港発--The Linux FoundationのエグゼクティブディレクターであるJim Zemlin氏は「Open Source Summit China」において、同氏が中国で話をした人は皆、人工知能（AI）について語りたがっている、と述べた。それは世界の他の国々でも同じはずだ。\n\n Zemlin氏はさらに、The Linux Foundationがオープンソースソフトウェアイニシアチブを通じてAI開発に多大な貢献をしていることを強調した。同氏はオープンソースの原則がAI開発に寄与している重要な分野をいくつか挙げた。\n\n 微調整された特化型モデル：The Linux Foundationは、エンタープライズ環境で特化型AIモデルを展開するための標準の策定を目指す「Open Platform for Enterprise AI」のようなプロジェクトに積極的に取り組んでいる。このイニシアチブの目的は、共同作業を促進して、AI技術の展開を合理化することだ。\n\n Zemlin氏は次のように語る。「北京で見た阿里巴巴（アリババ）の講演は、すい臓がんの早期発見のためのAIアプリケーション開発に関するものだった。このアプリケーションはすでに中国において、可能な限り早期のすい臓がん発見に貢献し、人命を救っている」。これは素晴らしいことだ。\n\n 大規模言語モデル（LLM）：「Mistral」や「Llama 3」などのセミオープンソースモデルは急速に進化しており、完全なプロプライエタリーモデルに匹敵する性能のモデルも少なくない。The Linux FoundationはこれらのLLMの開発を支援して、企業がクローズドシステムの制約なしに強力なAIツールを活用できるようにしている。\n\n 「これに関しては、『Hugging Face』のようなプラットフォームが明白なリーダーだ」とZemlin氏。「オープンモデルをダウンロードして利用できる全体的なエコシステムがある。これにより、開発者は幅広いAIアプリケーションにアクセスして活用することができる」\n\n AIの安全性：「オープンソース開発の透明性は、AIの安全性に関する懸念に対処するうえで特に有効だ」とZemlin氏は指摘した。「The Linux Foundationは、ツールと標準に関する共同作業を促進することで、コンテンツの信頼性、プライバシー、アルゴリズムの偏見といった問題の解決を目指している」\n\nThe Linux FoundationのAIイニシアチブ\n\n 同氏は続けて、The Linux FoundationはオープンソースAIの促進への取り組みを強調する複数のイニシアチブを主導している、と述べた。それには以下のものが含まれる。\n\n 「Open Model Initiative」（OMI）：取り消し不能なオープンライセンスでのAIモデル開発を推進して、企業による採用の障壁を取り除き、広範な使用を奨励するプロジェクト。OMIは、かつてオープンだったモデルを企業がクローズ化するのを防ぐことも目的としている。\n\n 「Acumos AI」：AIアプリケーションの構築、共有、展開用に設計されたオープンソースプラットフォーム。AI開発に必要なインフラストラクチャーを標準化し、開発者によるイノベーションを実現しやすくする。\n\n 「PyTorch」：The Linux Foundationで最も急成長しているプロジェクトの1つ。機械学習とLLMの作成ツールとして支持されており、AI開発における同財団の役割をさらに強固なものにしている。\n\n 「Unified Acceleration Foundation」：多様なシリコンアーキテクチャーで利用できる共通のアクセラレーションAPIを作成し、競争の促進とAIアプリケーション開発の簡素化を図るイニシアチブ。\n\n 「Coalition for Content Provenance and Authenticity」：電子透かしによってコンテンツの信頼性を担保することに重点を置いた取り組み。これは生成AI技術の影響が強まる一方の世界において重要な側面だ。\n\n Zemlin氏は、AIという文脈における「オープン」の明確な定義を確立することの重要性も強調した。「Open Source Initiative」（OSI）がオープンソースAIの定義という重要な作業に取り組む一方で、The Linux Foundationは「Model Openness Framework」（MOF）を開発した。\n\n Zemlin氏は以下のように説明する。「MOFは、モデルがオープンであるかどうかを評価する手段だ。人間によるモデルの格付けを可能にする。よく耳にするのは次のような疑問だ。『Llama 3は本当にオープンなのか。この特定のモデルは本当にオープンだろうか。データがない。実際にどのように訓練されたか分からない』」\n\n MOFは、このような疑問の解決に役立つオープンフレームワークを提供する。LLMの開発と展開における不確定要素の多さを考えると、これは簡単な作業ではない。The Linux Foundationは、どの構成要素がオープンで、モデルに含まれているかを理解しやすくする評価システムを開発した。\n\n Zemlin氏はこう続ける。「オープン性を3段階とすることで意見がまとまった。最高レベルであるレベル1は、オープンサイエンスの定義だ。データと使用されたすべての構成要素、すべての指示がそろっており、全く同じ方法で独自のモデルを実際に作成できる必要がある。レベル2はそのサブセットで、実際にはすべてがオープンというわけではないが、大部分がオープンだ。レベル3では、一部の領域でデータが公開されない場合があるが、データセットを説明するデータは公開される。モデルがオープンだとしても、すべてのデータが公開されるわけではない、ということをある程度理解できると思う」\n\n 同氏は次のように結論づけた。「これは、リスクベースのアプローチ、よりニュアンスに富むアプローチを採用して、何がオープンで何がそうでないかを理解するための素晴らしい方法だ。特定のモデルのオープン性を、データアクセス、モデルアーキテクチャー、訓練プロセスなど、さまざまな構成要素に基づいて評価することができる。このフレームワークにより、専門家はモデルの透明性を評価し、その使用について情報に基づく意思決定を下すことが可能になる」\n\n オープンソースとAIに関する専門家たちとの議論に多くの時間を費やしてきた筆者は、この段階的なモデルが今後の標準になっていくと予測している。\n\n 全体として見ると、The Linux Foundationのイニシアチブは、AI技術を進歩させるだけでなく、それらの進歩が倫理的かつ責任ある方法で行われるようにする取り組みでもある。同財団はオープンソースの共同作業を促進することで、潤沢な予算を持つ巨大企業だけでなく、誰もがAIイノベーションに貢献して、その恩恵を受けることができる包摂的な環境を作り出そうとしている。\n\nこの記事は海外Red Ventures発の記事を朝日インタラクティブが日本向けに編集したものです。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223199-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/d172d759dab4c558cafd927f9275a687f94930a6/images/000']
「Hot Chips」カンファレンス、議論の中心はAI処理向けプロセッサー（ZDNET Japan）,https://news.yahoo.co.jp/articles/330b55a3dfc0b53579d6859a61cadd9929d6d693,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223233-zdnet-000-2-view.jpg?exp=10800,2024-08-28T09:53:00+09:00,2024-08-28T10:04:56+09:00,ZDNET Japan,zdnet,ZDNET Japan,1200,\n「Hot Chips」カンファレンス、議論の中心はAI処理向けプロセッサーの画像\n人工知能（AI）の処理に特化したチップの製造に関連した科学と工学の分野は、かつてないほど活気に満ちている。その証拠に、スタンフォード大学で米国時間8月25～27日に開催された高性能プロセッサーに関する国際カンファレンス「Hot Chips」は、参加者であふれかえっていた。\n\n 36回目となる2024年のHot Chipsには、1500人の参加者が集まった。その半数以上はオンラインライブを通じた参加者で、残りはスタンフォード大学のMemorial Auditoriumに足を運んだ人たちだ。このカンファレンスは数十年にわたり、Intel、Advanced Micro Devices（AMD）、IBMなど、さまざまなベンダーが開発した最新プロセッサーについて議論する場となっている。また、企業がこのカンファレンスを利用して新製品を発表することも多い。\n\n 26日午前のセッションでは、Qualcomm Technologiesのデータセンター向けプロセッサー「Qualcomm Oryon」やIntelの「Lunar Lake」（開発コード名）プロセッサーのプレゼンテーションが行われ、満員の聴衆から数多くの質問が寄せられていた。\n\n 近年、大きな注目が集まっているのは、ニューラルネットワークを活用したAIをうまく動かすための専用チップだ。2024年のカンファレンスでは、OpenAIのハードウェア責任者Trevor Cai氏が基調講演で「予測可能なスケーリングとインフラストラクチャー」について語った。\n\n OpenAIでコンピューティングインフラストラクチャーの構築に長く取り組んできたCai氏によれば、「ChatGPT」は同社が「次の単語をよりうまく予測するために長い年月と膨大な費用を費やしてきた」成果だという。そのおかげで、「ゼロショット学習」のような機能が次々と実現した。\n\n 「これがうまくいくことがなぜ分かったのだろうか」と、Cai氏は聴衆の注目を引きつけるように問いかけた。それは、使用される計算量の「べき乗則」に従って能力が予測通りに向上することを示す「スケーリング則」が存在するからだ。計算能力が倍増するごとに、精度が「それ以上減少できない」エントロピー状態に近づくと、同氏は説明した。\n\n 「このことが、大規模なクラスターを構築するための投資を可能にしている」と、Cai氏は言う。その上で、スケールカーブに沿って進み続けるには「とてつもない逆風」があるため、OpenAIは今後も極めて困難なアルゴリズムのイノベーションに取り組まなければならないと語った。\n\nこの記事は海外Red Ventures発の記事を朝日インタラクティブが日本向けに編集したものです。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223233-zdnet-000-2-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/330b55a3dfc0b53579d6859a61cadd9929d6d693/images/000']
GitLab、「GitLab Duo Enterprise」を一般提供--エンドツーエンドのAIアドオン（ZDNET Japan）,https://news.yahoo.co.jp/articles/32cba32036f624b0019035a1ff13977d697e3f92,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223247-zdnet-000-1-view.jpg?exp=10800,2024-08-28T11:15:00+09:00,2024-08-28T11:15:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,878,\nGitLab、「GitLab Duo Enterprise」を一般提供--エンドツーエンドのAIアドオンの画像\nGitLabは米国時間8月22日、「GitLab Duo Enterprise」の一般提供を発表した。\n\n 同アドオンは、「Ultimate」プラン向けにユーザー当たり月額39ドルで提供され、マルチテナントSaaS、シングルテナントSaaS、セルフマネージドといった全GitLabデプロイオプションで利用できる。ソフトウェア開発ライフサイクルのあらゆる段階にわたりエンドツーエンドのAI機能を提供し、安全なソフトウェアの迅速な開発を支援するという。\n\n 「GitLab Duo Pro」に含まれる全機能に加え、ソフトウェア開発ワークフローの効率性改善、セキュリティ脆弱（ぜいじゃく）性のプロアクティブな検出・修正、プライバシーを最優先したAIによるチームコラボレーションの強化を支援するエンタープライズに特化した機能を備える。\n\n GitLab Duo ProとGitLab Duo Enterpriseでは、コード生成とコード補完により、コンテキストに基づいたコード行の自動補完やコメントからのコードブロック作成が可能。自然言語のチャットインターフェース「GitLab Duo Chat」を使うことで、コードのリファクタリング・説明、テスト生成もできる。組織内のユーザー管理機能は、許可されたユーザーにワークフロー内でのAI利用を可能にする。\n\n GitLab Duo Enterpriseだけで利用可能な機能としては、脆弱性とその侵害手法、自動生成されたマージリクエストによる修正方法の理解を支援する脆弱性の説明と解決がある。ログを分析して継続的インテグレーションおよび継続的デリバリー（CI/CD）におけるボトルネックと失敗を解決する根本原因分析、AI機能利用とソフトウェア開発ライフサイクル指標（サイクル時間やデプロイ頻度など）に対する影響についてインサイトを提供するAIインパクトダッシュボードなども利用できる。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223247-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/32cba32036f624b0019035a1ff13977d697e3f92/images/000']
ルームキーで入店から決済まで--東急リゾーツ＆ステイ、ホテル内の無人店舗刷新（ZDNET Japan）,https://news.yahoo.co.jp/articles/b94516fbe0e5d213f4ecff664a92b9174627bcea,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223164-zdnet-000-1-view.jpg?exp=10800,2024-08-28T09:24:00+09:00,2024-08-28T09:24:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,639,\nルームキーで入店から決済まで--東急リゾーツ＆ステイ、ホテル内の無人店舗刷新の画像\nCloudpick Japan（Cloudpick）とLMCUは、東急リゾーツ＆ステイが運営する長野県上水内郡信濃町の宿泊施設「ホテルタングラム」の24時間レジレスコンビニ「タングラムスマートストア」において、ルームキー1つで買い物ができる仕組みを提供した。Cloudpickが発表した。\n\n 中国に拠点を置くCloudpickは、ウォークスルー無⼈店舗などの店舗DXソリューションを⼿がける企業。現在、世界19カ国でウォークスルー無⼈店舗を900店以上展開している。LMCUは、無人店舗ソリューションを提供する企業。Cloudpickはプログラムの開発と実装、LMCUは要件定義を担当した。\n\n 両社はタングラムスマートストアにおいて、コミュニケーションアプリ「LINE」を活用して入店から決済までを行う仕組みを提供していたが、宿泊者のさらなる利便性向上に向けて、客室のルームキーで入店から決済までを行える仕組みを開発した。AIカメラと重量センサーを活用することで、実現している。\n\n これにより宿泊者は、会員登録や二次元バーコードの表示などを行うことなく、ルームキーのタグを入場ゲートにかざすだけで入店が可能になる。宿泊客は、ルームキーをかざして入店後、店内で欲しい商品を手に取ったら、そのまま退店可能。商品精算は、ホテルをチェックアウトする際に宿泊費などとまとめて行う。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223164-zdnet-000-1-view.jpg?exp=10800'],['https://news.yahoo.co.jp/articles/b94516fbe0e5d213f4ecff664a92b9174627bcea/images/000']
ブロードコム・ヴイエムウェアが本格始動--大企業のオンプレ回帰に照準（ZDNET Japan）,https://news.yahoo.co.jp/articles/a8bde21c77b735f981e740c7b2984b8e7a43790a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223266-zdnet-000-1-view.jpg?exp=10800,2024-08-28T16:39:00+09:00,2024-08-28T16:39:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,5641,"\nブロードコム・ヴイエムウェアが本格始動--大企業のオンプレ回帰に照準の画像\nVMware by Broadcomは米国時間8月26～28日、米国ラスベガスで年次イベント「VMware Explore 2024」を開催している。メインとなる会期2日目の基調講演では、Broadcom プレジデント 最高経営責任者（CEO）のHock Tan氏が登壇し、企業の方向性がオンプレミスやプライベートクラウドにあると宣言。製品・サービスを大規模に再編し、「VMware Cloud Foundation 9」（VCF9）や「VMware Tanzu Platform 10」などを発表した。\n\n 今回のVMware Exploreは、2023年11月のBroadcomによるVMware買収完了後初の年次イベントになる。基調講演の冒頭でTan氏は、「多くの皆さんから『製品をより良くしてほしい』『より使いやすくしてほしい』と言われてきた。われわれを求める皆さんを集めたい」と切り出し、「10年前に多くの経営層がパブリッククラウドの将来性にほれ込んだ。しかし、コスト（Cost）、複雑性（Complex）、コンプライアンス（Compliance）の3つの“C”に直面して、今ではPTSD（心的外傷後ストレス障害）を抱えている」と指摘した。\n\n 企業のクラウド利用の拡大に応じてコストが増大し続け、同時にシステム環境も複雑化する一方となり、コンプライアンスの観点でも法規制など厳しい領域では、小規模で複雑な環境ほど高いコストを伴うとする。\n\n 他方で、生成AIのブームを契機にデータのセキュリティやプライバシーとそれらの保護や統制の確保が必須とされ、AIアプリケーションの実行や大規模言語モデル（LLM）の開発などにおける電力消費やコストの増大も課題となり始めた。\n\n こうした現状を踏まえてTan氏は、企業がこれらの問題や課題の解決策をオンプレミス／プライベートクラウドに求めていると説き、企業の83％がパブリッククラウドからオンプレミスへの回帰を検討しているという「Barclay CIO Survey 2024」のデータなどを示した。Tans氏の見立ては、企業がオンプレミス／プライベートクラウドを中核として、俊敏性や拡張性などパブリッククラウド特徴を適材適所で組み合わせていくという。\n\n Tans氏は、オンプレミス／プライベートクラウドにおいて、VMwareが「vSphere」や「vSAN」「NSX」といった仮想化技術でITインフラの集約・統合に貢献し、Tanzu Platformによるモダンアプリケーションの効率的な運用管理、セキュリティ対策や事業継続、さらには2023年の同イベントで発表したAI基盤「VMware Private AI Foundation with NVIDIA」に至るまで、企業のIT環境の進化と最適化を支援してきたと実績を強調して見せた。\n\n また、BroadcomがVMwareの買収において「簡素化」「イノベーションへの投資の強化」「エコシステムの拡充」の3つ約束を果たすとも述べた。例えば、簡素化では、買収以前に8500以上あったSKUを大きくパッケージ化してVCF中心の体系に変更し、それに伴う機能の統合や性能、連携などの強化と顧客が容易に展開できるようにすることがイノベーションへの投資の強化になるとする。最後にTans氏は、「非常に重要なことはわれわれがパートナーや顧客とのエコシステムを強化するために投資を行っていくことである。顧客の成功はわれわれの成功を意味する」とアピールした。\n全ての中核となるVCF\n\n 続いて登壇したVCF部門 製品担当バイスプレジデントのPaul Turner氏は、Tan氏が示した企業のオンプレミス／プライベートクラウドへの“回帰”において、サイロ化した旧態依然のアーキテクチャーでは、技術面だけでなく、セキュリティや運用管理、ワークフロー、プロセスなども足かせとなってコストの増大を招き、企業がビジネスで求めるアジリティー（俊敏さ）も獲得できないといった問題を生じさせると指摘した。\n\n そこでBroadcomとなってからは、コンピュート、ストレージ、ネットワークなど領域ごとにも分かれていた製品群をVCFに統合。Turner氏は「われわれは全ての部門も統合するとても大規模な取り組みをした。VCFは、単なるテクノロジーオペレーターではなく、顧客のビジネスにクラウドの体験を提供するための戦略的な選択肢であり、コンピュート、ストレージ、ネットワーク、自動化、運用の全てを1つに統合したプラットフォームだ」と説明した。\n\n VCFは、これまでもITインフラに必要なあらゆる機能を持つ統合型製品として提供されていたが、大規模環境を対象にしていた。Broadcomは、以前のような領域ごとの製品展開では顧客の多種多様なニーズに対応できても、サイロ化している伝統的なアーキテクチャーのITインフラが抱える問題の解決は難しいと判断。VCFを全ての製品・サービスの中核に位置付け、領域ごとに分かれた製品・サービスをパッケージにした。\n\n Turner氏は、新たなVCFを中心とするスタックでは、自動化を柱にアプリケーションのビルドやデプロイ、運用を支えるインフラレイヤー、Kubernetesなどモダンアプリケーションの稼働を担うプラットフォームレイヤー、そしてプライベートなAI環境や災害復旧（DR）対策、高度なセキュリティなどユーザーが必要とするワークロードの機能を“カタログ”から選んで実行するアドバンストサービスレイヤーで構成されると説明した。\n\n Broadcom体制でのVCFは、Amazon Web Services、Microsoft「Azure」、Google Cloudのクラウドハイパースケーラー、マネージドサービスを提供する300以上のクラウドサービスプロバイダー（CSP）、ハードウェアなどと組み合わせて提供するOEM、1万4000社以上のディストリビューター／リセーラーの各パートナー経由で提供され、顧客が各種環境において同じライセンスでVCFを利用できるポータビリティーなどを備えるとした。OEMでは富士通、日立製作所、NECの国内3社が引き続きパートナーとなっている。\n\n 新たに発表されたVCF 9は、バージョン番号が現行の5.2から一気に増えたが、これはvSphere 8のメージャーバージョンアップという建付けになったことによるという。プライベートクラウド環境の導入や統合化された運用管理、リソース管理、セキュリティ／コンプライアンス、テナント管理（VMware Cloud Directorの統合）、自動修復などの新たな機能を備えるほか、中核機能としても、NVMeを使用してAI実行やリアルタイム分析の際に最適なメモリーの割り当てを実施しコストを節減する「Advanced Memory Tiering for NVMe」などを加えた。\n\n Broadcomは、「Private Cloud Maturity Model」という顧客のプライベートクラウドに対する成熟度に応じて段階的にVCFを導入していけるようにするという。\nVCFの上で動くサービス群\n\n VMware by Broadcomが示すプライベートクラウドでは、VCFをプラットフォームとして、その上でAIやモダンアプリケーション、高度なセキュリティ対策といった各種サービスをカタログから選択して実行するような構成となっている。\n\n プロダクトマネジメントディレクターのValentina Alaria氏は、これからの企業がプライベートクラウドを利用していく上で、プラットフォームエンジニアリングのチームとアプリケーションのチームが連携しながら、セキュリティやコンプライアンスを担保してパブリッククラウドのオートスケーリングのような使い勝手の機能を具備した環境でモダンなアプリケーションやさまざまなサービスを迅速に展開できるようしていくと説いた。\n\n 新たに発表したTanzu Platform 10では、KubernetesおよびCloud Foundryに基づいて、一貫したガバナンスとコンプライアンス、モダンアプリケーション実行を可能にするとし、アプリケーションからプラットフォームまでの広い範囲を可視化するオブザーバビリティ（可観測性）や、Javaフレームワーク「Spring」のアプリケーションにおけるコンプライアンス監査やポリシーの実施、脆弱（ぜいじゃく）性修正パッチの自動適用といったセキュリティ強化などを備える。\n\n また、AIで大規模アプリケーションなどの開発や運用、最適化を図る「Tanzu AI Solutions」も組み込む。VCFとの連携も強化され、シンプルなコマンドラインインターフェース（CLI）からKubernetesクラスターを容易に展開することなども実現した。\n\n Tanzu Platform 10やVCF 9の連携の中では、ロードバランサーの「Avi Load Balancer」と、アプリケーション保護での分散ファイアウォール、侵入検知／防御（IDS/IPS）機能を持つ「vDefend」の統合強化が図られた。ここでもAIを活用して、ネットワークにおける高度な脅威分析や検知、対応を効率的に支援できるようにしている。\n\nエッジ環境とAI基盤の進化\n\n 分散コンピューティング領域の「Software-Defined Edge」では、エッジAIへの対応とSD-WAN環境のセキュリティ強化を図った。エッジAIは、店舗などデータの発生源（データポイント）に近い場所で、カメラ映像分析などのAIを実行する概念になり、特に小売・流通や製造などの業界で関心が高まっているという。\n\n Software-Defined Edge部門ジェネラルマネージャーのSanjay Uppal氏は、多拠点インフラ向けの「VMware Edge Compute Stack」では、エッジAIへの対応としてエッジAIアプリやLLMおよび小規模言語モデル（SLM）などのマルチモーダルなAIワークロードを一貫性あるポリシーで効率的に管理する「VMware Edge Cloud Orchestrator」の追加などを説明。ここではパートナーエコシステムの本格展開も始めており、NTTデータが認定パートナーの1つとして発表された。\n\n また、広域分散環境向けの「VeloCloud SD-WAN」では、Symantecとして提供してきたクラウドセキュリティのセキュアウェブゲートウェイ（SWG）やデータ損失防止（DLP）機能をPoint of Presence（PoP）レベルで統合した初のリリースとなる「VeloCloud SASE, Secured by Symantec」を挙げた。エッジのPoPにおいて高い処理能力と高度な安全性を両立させることができるとしている。\n\n Tanzu Platform 10やSoftware-Defined EdgeなどがVCF上に組み合わせて利用するアドバンストサービスになり、カタログとして高度化セキュリティ、データサービス、災害対策、コンテナー環境の運用、エッジオーケストレーション、ロードバランサー、ワークロード自動化、プライベートAIといったカテゴリーをそろえている。\n基調講演の最後には、AIおよびアドバンストサービス担当グローバルヘッドのChris Wolf氏が、2023年に発表したVMware Private AI Foundation with NVIDIAを含むプライベートAIのアップデートを説明した。\n\n VMware Private AI Foundation with NVIDIAは、VCFとNVIDIAのGPUやソフトウェアスタックで構成され、企業や組織がデータのセキュリティやプライバシーを担保しながらLLM開発やAIアプリケーションを実行するための基盤になる。2024年5月に一般提供が開始され、Wolf氏は「製造や医療など機密性の高い情報を扱う分野で活用され、セキュリティとガバナンス、プライバシーを確保しつつAIの複雑なアプリケーションの迅速な展開とコストの節減、運用管理の収集を可能にする」と話した。\n\n 今回は、同ソリューションのエコシステムがさらに拡大。新たにIntelの「Gaudi 2 AI Accelerators」をサポートしたほか、システムサービスでTabnine、Codeium、World Wide Technology、OEMで富士通、Supermicro、日立ヴァンタラ、エフサステクノロジーズが参加している。\n\n また、新機能となる「Model Store」も発表した。Model Storeでは、LLMへのセキュリティやコンプライアンスの適用、LLMへのアクセス制御、無許可のLLMから自社環境への接続の遮断など安全性を向上できるとする。ほかにも仮想GPUの管理やGPUの高可用性構成、チャットボット作成といった機能が追加された。\n\n AIのネットワーク接続では、主要なハイパースケーラー7社のうち6社がイーサネットに対応済みで、Broadcomが強みとする性能とコストに優れたイーサネットの利用が進みつつあるという。\n\n（取材協力：VMware by Broadcom）",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240828-35223266-zdnet-000-1-view.jpg?exp=10800'],['https://news.yahoo.co.jp/articles/a8bde21c77b735f981e740c7b2984b8e7a43790a/images/000']
