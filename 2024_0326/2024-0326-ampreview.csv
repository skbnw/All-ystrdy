headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「犬」を「猫」と認識させる？　画像生成AIの“無断学習”を阻止するツールが登場（AMP［アンプ］）,https://news.yahoo.co.jp/articles/6a00a92f9a2b947d1029935d39d2f080c6876cdd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240326-00010000-ampreview-000-1-view.jpg?exp=10800,2024-03-26T06:02:48+09:00,2024-03-26T06:02:48+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,2353,\n「犬」を「猫」と認識させる？ 画像生成AIの“無断学習”を阻止するツールが登場\nテキストを入れるだけで、瞬時にリアルでそれっぽい画像を生成してしまう画像生成AI。すでにその活用範囲は広がりを見せているが、アーティストやクリエイターからは著作権の侵害を危ぶむ声や作品保護への要望が上がっている。\n\nそんな中、デジタルアート作品をAIスクレイピングから守るツールも続々と登場している。本記事ではその代表的な2つのツール「Nightshade」と「Kin.art」を紹介する。\nAIモデルに「毒」を与えて誤認させる「Nightshade」\nhttps://nightshade.cs.uchicago.edu/index.html\nシカゴ大学のベン・ザオ教授率いる研究チームは、デジタル作品に「毒」を仕込んでAIに学習させないようにするソフトウェア「Nightshade」を開発した。Nightshadeは無料でダウンロードでき、早速アーティストたちの間で話題となっている。\n\nNightshadeは画像に対して、人の目には見えないピクセルレベルに「無秩序」で「予測不能」な微細な変更（毒）を加える。するとAIは変更が加えられた間違った情報をモデル学習してしまい、結果的にまったく違うものを表示してしまう。例えば、「毒」を加えた「犬」の画像をAIは「猫」と認識し、犬のつもりで猫を描画してしまうというようなことである。\n\nNightshadeは、すでに様々なAI画像生成ツールで実験しており、「DALL-E」「Midjourney」「Stable Diffusion」で効果を発揮したと報告している。\n\n同チームはNightshadeの前に「Glaze」というツールを発表している。こちらは画像のピクセルを少し変えて機会学習のアルゴリズムを混乱させ、画像を実存するものと異なるスタイルで認識させるプログラムだ。Nightshadeと似てはいるが、Glazeは「防御的」であるのに対し、「毒」を加えるNightshdeはより「攻撃的」な設計だ。\n\n研究チームは、Nightshadeの目標は「AIによるクリエイター作品の不正使用を防ぐ」ことであり、AIモデルの開発者は“破損していない作品”を有料で利用するようになるべきだと訴えている。\n後を経たないAIによる「不正学習」\nアートコンテストのデジタルアート部門で1位を獲得したAI作品\nネット上の画像やアート作品がAIのモデル学習に無断で使用されるケースは後を経たず、著作権を巡って訴訟に発展することもある。\n\n2023年1月、米国の複数のアーティストが「素材や個人情報を同意なくスクレイピングされた」として、Midjourneyなどに対して集団訴訟を起こした（同年10月に棄却）。また、2月には写真販売サイトのGettyImagesがStable Diffusionの親会社Stability AIを相手に提訴している。\n\n自身の才能や個性こそが「売り」であるアーティストたちにとって、自分の作品が勝手に学習され、“模倣”されてしまう懸念は強い。\n\nまた、生成AIによる「作品」の著作権についても議論が始まっている。例えば、2022年8月にMidjourneyで生成されたAI作品がアートコンテストのデジタルアート部門で1位を獲得して“大炎上”した。SNS上では「ロボットをオリンピックに参加させるようなものだ」とバッシングされている。\n\n一方、翌年8月ワシントンD.C.では「AIが生成したアート作品は著作権保護の対象外」という連邦判事の判決が下っている。日本では2024年1月に文化庁が「AIと著作権に関する考え方について」という素案を発表し、ようやく規範作りに乗り出したところだ。\nそもそもAIに学習をさせない「Kin.art」\nhttps://kin.art\nもう1つ、AIスクレイピングからデジタル作品を守ってくれるのが「Kin.art」だ。こちらは画像に「毒」を持って防ぐNightshadeとは異なり、作品をKin.artのプラットフォームにアップするだけで、AIの不正アクセス自体を防御してくれるという。\n\nKin.artの共同設立者であるRosmans De Vryは次のように述べている。「たとえばAIは『鳥』を学習するとき、インコやワシや青い鳥といった『ラベル』の付いた画像のデータセットで訓練します。でもその画像やラベルをぐちゃぐちゃにすると、学習できなくなりますよね」\n\nつまり、Kin.artの仕組みはこうである。まずKin.artにアップされた画像を小さく分割（セグメンテーション）してAIの学習を阻害する。さらに、画像に付随するメタデータやテキストなど、画像に関連づいているラベルをごちゃ混ぜにしてしまうのだ。\n\nAIのトレーニングアルゴリズムは画像とメタデータの両方に依存するため、「四本足と尻尾と鼻を持ち、毛皮で覆われた生き物」を「犬（だろう）」と学習する。しかしKin.artでは画像の構成自体もしくはラベルのいずれかを破壊して「ごちゃ混ぜバージョン」を作ってしまうため、AIが正確に学習することを実質的にできなくしてしまうのである。\n\nDe Vryは「この二重のアプローチによって、アーティストの作品をAIの不正学習から保護するのです」と述べている。\n\nKin.artは利用登録をすれば誰でも無料で利用できる。生成AIにヒヤヒヤしているクリエイターたちにとっては、心強いツールとなることだろう。\n文：矢羽野晶子 /編集：岡徳之（Livit）,"['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240326-00010000-ampreview-000-1-view.jpg?pri=l&w=640&h=454&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240326-00010000-ampreview-001-1-view.jpg?pri=l&w=640&h=343&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240326-00010000-ampreview-002-1-view.jpg?pri=l&w=640&h=456&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240326-00010000-ampreview-003-1-view.jpg?pri=l&w=640&h=395&exp=10800']","['https://news.yahoo.co.jp/articles/6a00a92f9a2b947d1029935d39d2f080c6876cdd/images/000', 'https://news.yahoo.co.jp/articles/6a00a92f9a2b947d1029935d39d2f080c6876cdd/images/001', 'https://news.yahoo.co.jp/articles/6a00a92f9a2b947d1029935d39d2f080c6876cdd/images/002', 'https://news.yahoo.co.jp/articles/6a00a92f9a2b947d1029935d39d2f080c6876cdd/images/003']"
