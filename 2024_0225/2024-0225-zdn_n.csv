headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
コラボモデルだって妥協なし！　マンガ家を驚かせた、「カウボーイビバップ」ワイヤレスイヤフォンの“音”（ITmedia NEWS）,https://news.yahoo.co.jp/articles/4c270d82becc793a37c2847fc892fdcfa7c88db9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000058-zdn_n-000-1-view.jpg?exp=10800,2024-02-25T17:47:39+09:00,2024-02-25T17:47:39+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1122,\n（写真：ITmedia NEWS）\n以前、ワイヤレスイヤフォンを取り上げた回で「コラボモデルってスペック的にそんなに高くない製品が使われることが多い」というセリフがあったのですが、「音質面にこだわったコラボモデルだってあるよ！」とオーディオメーカーのAVIOTさんから挑戦状……ではなく荷物が届きました（機材提供：AVIOT。いわゆる案件ではないです）。\n【まんが全27コマを読む！】\n入っていたのは3つの完全ワイヤレスイヤフォン。中でも人気アニメ「カウボーイビバップ」とのコラボモデル「TE-ZX1」には驚きました。ボクはメガドライヤフォン購入前にAVIOT製品を愛用していたのですが、それを含めて“聞いたことのない音”でした。\n\n TE-ZX1は最新のフラグシップモデルで、3種類、計5基のドライバー（音を出すユニット）を搭載しています。マンガの中ではオーディオ好きの担当編集が詳しく解説していますが、シロウトのボクが聞いても違いは明らか。今まで聞こえていなかった音の存在に気づかされ、何というか“音の深み”のようなものまで感じました。\n\n 「AVIOT SOUND ME」という専用アプリを使うと、音の調整（イコライジング）やカウボーイビバップの主要5キャラによるボイスガイダンスの切り替え、ノイズキャンセリング／外音取り込み機能などの調整も可能です。特に外音取り込み機能は、風の音の影響を結構受ける印象だったので、調整するのを個人的にはオススメします。\n\n デザインもかっこいいですし、4万9500円という価格は決して安くないものの、実際に使ってみると納得感はあります。今まで1万円前後のイヤフォンばかり買っていたためか、新しい世界の扉を開けてしまったような気分。もし「ワイヤレスだから」「コラボモデルだから」といった理由でワイヤレスイヤフォンやコラボモデルを敬遠している人がいたら、ぜひ一度聞いてみてほしいです。\n著者紹介：サダタロー\n1998年にテレビ番組「トロイの木馬」出演をきっかけに漫画家デビュー。代表作は「ハダカ侍」（講談社、全6巻）、「ルパンチック」（双葉社、1巻）、「コミックくまモン」（朝日新聞出版、既刊7冊）など。現在、熊本日日新聞他で4コマ漫画「くまモン」を連載中。Pixivはsadataro、Twitterは@sadafrecce。\n連載：サダタローのゆるっと漫画劇場\n漫画家のサダタローさんが、世界初の電脳編集者「リモたん」と一緒に話題のアレコレについてゆる～く語るまんが連載。たぶん週末に掲載します。連載一覧はこちら。過去の連載はこちらからどうぞ。\nITmedia NEWS,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000058-zdn_n-000-1-view.jpg?pri=l&w=282&h=640&exp=10800'],"['https://news.yahoo.co.jp/articles/4c270d82becc793a37c2847fc892fdcfa7c88db9/images/000', 'https://image.itmedia.co.jp/l/im/news/articles/2402/25/l_ts0153_aviot02.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240225-058&utm_term=zdn_n-prod&utm_content=img']"
Bluesky、フェデレーション開始　Mastodonと異なるプロトコルの長所を説明（ITmedia NEWS）,https://news.yahoo.co.jp/articles/c1f705528b702298dd8a98374f6e81c0226690f6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000039-zdn_n-000-1-view.jpg?exp=10800,2024-02-25T09:56:23+09:00,2024-02-25T09:56:23+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1073,\n（写真：ITmedia NEWS）\n米Blueskyは2月22日（現地時間）、自社が開発する分散型SNS「Bluesky」での「フェデレーション」機能の早期アクセスを開始したと発表した。\nユーザー数500万人突破のアナウンス\nBlueskyは立ち上げ当初から、「AT Protocol」と呼ばれる分散型オープンプロトコルを用いたフェデレーションの実現を目指してきた。将来的には、このプロトコルを採用するSNS同士が横断し、ユーザー同士がサービスを意識せずに会話したり、アカウントを移動したりできるようになる見込み。\n\n 今回の早期アクセスでは、「多数のユーザーで大規模なサーバをホスティングしたい人々にフェデレーションを開放する」。ユーザーは、Blueskyのネットワークに接続する独自のサーバを立ち上げ、独自のルールでアカウントをホストできるようになる。\n\n フェデレーションのためのオープンプロトコルとしては、MastodonやThreadsが採用する「ActivityPub」があるが、Blueskyはこれを採用しなかったため、BlueskyとMastodonやThreadsとのフェデレーションは望めない。\n\n Blueskyは、AT Protocolを採用する自社サービスがActivityPub採用のMastodonより優れている点について、以下のように説明している。\n\n・Mastodonではインスタンスと呼ばれるサーバがコミュニティを決定するので、参加するサーバによってユーザー体験が異なるが、Blueskyではユーザー体験はフォローしているフィードとアカウントに基づくので、いつでもグローバルな会話に参加できる\n・Mastodonのモデレーションはサーバに関連付けられているが、Blueskyでは関連付けられておらず、ブロックリストなどのツールはコミュニティが構成可能\n・Mastodonのタイムラインはユーザーがフォローしているアカウントからの投稿のみで構成されているが、Blueskyはタイムラインもサーバに関連付けられないように設計されているので、独自のフィードを作成できる\n・Blueskyでは、ユーザーはサーバを簡単に移動でき、移動してもユーザー名やそれまでに構築した友達関係、投稿を失うことはない\n\n Blueskyは2023年3月に招待制で提供を開始し、この2月6日から誰でもサインアップできるようになった。ユーザー数は22日には500万人を超えた。\nITmedia NEWS,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000039-zdn_n-000-1-view.jpg?exp=10800'],"['https://news.yahoo.co.jp/articles/c1f705528b702298dd8a98374f6e81c0226690f6/images/000', 'https://image.itmedia.co.jp/l/im/news/articles/2402/25/l_yu_500.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240225-039&utm_term=zdn_n-sci&utm_content=img']"
任天堂、Webサイトのドメイン変更へ　26日から　「nintendo.com/jp」に（ITmedia NEWS）,https://news.yahoo.co.jp/articles/0d6cc1faf7bf46b95012c0ee00b719cb1dc5f1b7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000056-zdn_n-000-1-view.jpg?exp=10800,2024-02-25T17:28:15+09:00,2024-02-25T17:28:15+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,255,\n任天堂、Webサイトのドメインを変更へ\n任天堂は2月25日、Webサイトのドメインを変更すると発表した。一部ページを除き、現在の「nintendo.co.jp」から「nintendo.com/jp」に変更するという。理由は「サーバ環境の整備に伴ったもの」と説明している。\n【画像を見る】変更後のURL【全2枚】\nドメインの変更は26日に実施。旧URLへアクセスしても自動的に新URLへ転送されるという。会社情報やサポートページなどは旧URLのままで、変更はないとしている。\nITmedia NEWS,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000056-zdn_n-000-1-view.jpg?exp=10800'],"['https://news.yahoo.co.jp/articles/0d6cc1faf7bf46b95012c0ee00b719cb1dc5f1b7/images/000', 'https://image.itmedia.co.jp/l/im/news/articles/2402/25/l_tm1636144_02251_2_w490.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240225-056&utm_term=zdn_n-sci&utm_content=img']"
「王様戦隊キングオージャー」終幕　“無謀だった”という制作の舞台裏、上堀内監督に聞いた（ITmedia NEWS）,https://news.yahoo.co.jp/articles/cb737ca923816b42e7403b3c3af1235906cee9d6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000041-zdn_n-000-2-view.jpg?exp=10800,2024-02-25T10:43:28+09:00,2024-02-25T11:01:22+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,8451,\n（写真：ITmedia NEWS）\n「王様戦隊キングオージャー」が最終回を迎えた。2023年3月から約1年にわたって放送された特撮作品だが、綿密なストーリー展開に加え、最新テクノロジーをふんだんに取り入れたことで「背景CGのクオリティーが高すぎ」「予算は大丈夫なのか？」など、X（旧Twitter）で話題になったことも記憶に新しい。\n【詳細はこちらをクリック】キングオージャー制作の舞台裏を見る（写真7枚）\n1年間、毎週放送する特撮作品でこれだけのハイクオリティーな映像表現ができた理由には、「バーチャルプロダクション」と「ボリュメトリックキャプチャー」の存在が欠かせない。\n\n バーチャルプロダクションとは、バーチャル背景とその前景にいる被写体を一緒にカメラで撮影することで、リアルタイムに合成する撮影手法。近年では、LEDを敷き詰めた巨大スクリーン（LEDウォール）を使う方法も増えている。LEDは輝度が高く、CG合成でよく使われる「グリーンバック」では難しい反射や映り込みが再現できる他、天候やスケジュールに左右されやすい外ロケ撮影よりも制約が少なく、コロナ禍を経て一気に拡大した。\n\n また、バーチャルプロダクションの一種に「インカメラVFX」と呼ばれる仕組みもある。物理カメラの動きをトラッキングし、ゲームエンジン「Unreal Engine」などで作成した仮想空間内のバーチャルカメラとリンク。バーチャルカメラが映す仮想空間を背景としてLEDウォールに映すことで、パンやズーム、動きのあるアングルを狙っても、それに合わせて背景が変化。奥行きや立体感のある、本当にその空間にいるかのように撮影できる。\n\n ボリュメトリックキャプチャーは、膨大な数のカメラを取り付けた円形のスタジオを使った3D撮影を指す。実写でありながら360度の3Dデータを撮影できる。映像も収録でき、例えばダンサーの動きを1人ずつキャプチャーすれば、バーチャル上で一堂に踊らせ、それをバーチャルカメラで“再撮影”することができる。360度データなのでアングルも自在だ。\n\n ただ、毎週放送されるテレビ番組で、こうした先端技術をフルに活用した事例はこれまであまりなかった。しかし「僕らにはもうこれしかなかった」と語るのは、キングオージャーを監督した上堀内佳寿也氏。なぜ、同作品はバーチャルプロダクションとボリュメトリックキャプチャーに全てを賭けることになったのだろうか。\n全ては“勘違い”から始まった\nもともと、東映作品でバーチャルプロダクションを使う試みは以前からあったという。「最初は機界戦隊ゼンカイジャーのコックピットなどでトライしながらでした」と語るのは東映テレビ・プロダクションでラインプロデューサーを務める佐々木幸司氏。\n\n 上堀内氏も「Ultimatte（豪Blackmagic Designの合成ソフト）を使ったリアルタイム撮影は一度経験していました。ただし、トラッキングなしの書き割り、1枚絵を先に出しておく状態でした」「仮面ライダーセイバーから考えると3年ぐらいやっていますけど、進み度合は階段を1段ずつ上ろうとしていたぐらいだったんですよ」と振り返る。\n\n ところがキングオージャーでは、通常であれば必ず構築する「レギュラーセット」なし、外ロケ以外は東映のLEDスタジオと、ソニーPCLが運営する「清澄白河BASE」のバーチャルプロダクションスタジオ／ボリュメトリックキャプチャースタジオなどで撮影という、進み度合いからするとかなり無謀ともいえる構成で挑むことになった。\n\n 「ホップ、ステップ、テークオフですよ」（上堀内氏）\n\n 「普通ジャンプだろっていう（笑）」（佐々木氏）\n\n 「僕らパラシュートを付けないで飛んだんだと思います。落ちることは考えないぞっていうやり方をしてしまった」（上堀内氏）\n\n そもそも、キングオージャーでバーチャルプロダクションをフル活用するというのは、勘違いの連鎖によるものだった。\n\n 東映で数多くの特撮作品を手掛けてきた大森敬仁プロデューサーは、キングオージャーの構想を練っていた際、東映に設立されたばかりのバーチャルプロダクション部から「（もしバーチャルプロダクションを）やるなら早く準備してください」と言われていた。\n\n 特撮から少し離れていた大森氏は、これを「バーチャルプロダクションで（撮影を）やっていいんだ」と解釈。キングオージャーの構想を上堀内氏に「バーチャルプロダクションも使えるなら使って」と伝えたところ、上堀内氏は「バーチャルプロダクションでやるんだ」というメッセージに受け取ったという。\n\n もともと大森氏から、5つの王国を作るというキングオージャーの構想を聞いた際に「そんなロケーションあるわけないじゃんと思っていた」という上堀内氏。いわく「最悪な伝言ゲーム」になったものの、キングオージャーで「アニメ的表現を取り入れたかった」という監督の想いもあり、ロケーションの制約が少ないバーチャルプロダクションでの撮影を前提に話が進むことになる。\n“見切り発車”で始めた素材集め\nバーチャルプロダクションを使うということは、撮影した映像なり、Unreal Engineで作られたバーチャル空間なり、LEDウォールに表示するものが必須。つまり、下絵が必要となる。\n\n 上堀内氏は、「いっぱい下絵がないとダメだとなって、いっぱい（日本各地を）回ろうっていう子供みたいな考え方から始まった」「もう、るるぶの出番ですよ」と、九州からスタートし、合計1カ月ほど各地を撮影して回ったという。\n\n ただし、途切れることなく毎年続くシリーズ作品のため、1～2年は必要な準備を9カ月で行うことになった。それでもテレビシリーズとしては多めの準備期間。当然コストもかさむ。上堀内氏は「ランニングコストを抑えるために、（本編の）撮影が始まったらロケにあまり出ないようにする」と佐々木氏、大森氏に説明。それであればコストを掛ける価値があるとOKが出た。\n\n とはいえ、見切り発車の状態で始めた撮影は、失敗の連続だったという。\n\n 「撮影した12Kの360度映像だと解像度が追い付かないので、途中から16Kのカメラに変えて持っていったら、今度は16Kがオンライン（本編集）で処理できないと分かって」（上堀内氏）\n\n 「ノウハウがあれば誰か指摘してくれるんですけど、誰も分からない状態から僕らは始めてしまった」「16Kで撮ってきたら『はぁ？』みたいに言われ、『データをダウンコンバートするので1週間もらえますか？』という感じで、恥ずかしいんですがいろいろ学んでいきました」（同氏）\n\n これと並行して、インカメラVFXで使用する各国のバーチャル世界（ワールド）も、Unreal Engineをベースに作り上げていった。\n\n 「脚本家とプロデューサーの方でキャラクターの設定は何となく出来上がっていたんです。そのキャラクターをもとに各国の設定書を作って、イメージを出して、企画チームに共有して、コンセプトに発展させていきました」と上堀内氏。各国の最終ビジュアルは設定書をベースにコンセプトアーティストが担当したという。\n\n 「僕の設定にコンセプトアーティストが発想を載せた感じです。ビジュアル化したものをアセット製作チームに渡しました」「ただ、シュゴッダムという国だけは、全てのアセットの基盤になると思ったので、Unreal Engineのマーケットプレースでベースになりそうなものを買って、東映バーチャルプロダクション部のスタッフと僕の2人で簡易的な基盤を作り、それを製作チームに渡しています」（上堀内氏）\n\n 監督のこだわりによって作り込まれていったバーチャル世界だが、精緻すぎるゆえ、それぞれのワールドはかなり重たいデータに膨れ上がっていた。\n\n ソニーPCLで空間映像プロダクションエキスパートを務める増田徹氏は、上堀内氏のワールドについて「カメラのアングルに入らないところまで、本当に広い世界が作り込まれていて、最初LEDウォールに出したらまともに動かなかった」と振り返る。\nソニーPCLとの出会い\nソニーとは、もともとカメラの技術協力などで交流自体はあったものの、バーチャルプロダクションについては全くなかったという。上堀内氏が清澄白河BASEを知ったのは、Webサイトからだった。\n\n 「もう東映さんの（LEDスタジオ）がダメだとなった時に、日本にあるスタジオさんのWebサイトを何社か拝見させてもらいました」「その中で、スタジオの形とやりたいことの全てが合致しそうだと思ったのが、『清澄白河BASE』のバーチャルプロダクションスタジオだったんです」（上堀内氏）\n\n 以前、ソニーの別部署から取材を受けていた上堀内氏。その時の関係者の姿がサイト上にあったことで「あれ、1人だけ知っている方がいると思って。そこからお話しさせてもらいました」「本当に感謝しかなくて、こんな無謀な連中でもよく受けてもらえたなと」（同氏）\n\n 話を受けたソニーPCLは、すぐに検証に入る。\n\n 「こういう話が来ている、と資料を送っていただいた企画書に丸い床の図面があって、まずこれがスタジオに入るか検証したいと」「じゃあ検証しましょうと入ってもらったらピッタリで」（バーチャルプロダクションプロデューサーを務めるソニーPCLの遠藤和真氏）\n\n 「東映のLEDスタジオに合わせて、美術にかなり重たい床を作ってもらったんです。そうしたら東映のスタジオが使えないと言われ、ソニーPCLさんにその図面を渡してみたらピタっとハマって。ウソだろ……と」（上堀内氏）\n\n 「作り直しだったら、またスケジュールどうしようかと思っていました」（佐々木氏）\n「無理難題」はご褒美だった\n上堀内氏が構築したバーチャル世界は、先述の通りカメラのアングルの外も作り込まれており、リアルタイムでレンダリングするにはヘビーなもの。「ンコソパ（王国の一つ）も最初は全く動かなかったですね」と同氏は語る。\n\n そのため、最初の撮影は後処理できるグリーンバックに変更しつつ、ソニーPCL側でワールドを調整していった。不要な部分を削ったり、撮影に合わせてレベル分けしたりすることで最適化。それでも、通常のバーチャルプロダクションで必要な60fpsをキープすることは難しく、途中まで24fpsに固定してリアルタイム出力していた（キングオージャーは全編24fps撮影）。\n\n 「面白いのは、最終回のとあるシーンでめちゃくちゃ良いクオリティーを出しているんですけど、ちゃんと60fpsが担保されていたんです」（上堀内氏）と、チューニングを続けた結果、クオリティーを高くしても60fpsを維持できるようになっていた。\n\n このエピソードも関連するが、監督が一番驚いたのが同社の姿勢だったという。無謀ともいえるチャレンジに対し「どこかで折れてくれ」「やれるか分からない」というマイナスな意見はつきもの。一方、ソニーPCLからは「あんまりマイナスの言葉を聞いたことがなかった。めっちゃ嬉しかったんですよ。『取りあえずやってみます』って言ってもらえること、なかなかないんです」（上堀内氏）\n\n 「技術畑の方は特にそういう姿勢の人はいないと思います。やはり、リスクや納期を考えると簡単に『うん』って言えない方が当然だと思うんですよね」（佐々木氏）\n\n こうした姿勢は、清澄白河BASEの特殊な立ち位置に由来する。「常に頂いたオーダーをどうクリアするかという方向のスタジオなので、できないものはできない中で、改善できる方法を探っていく感じでした」「1回現場に出してみて、こういう要求が来たということは『まだ足りないんだな』と開発し、また投入していきます。無理難題ってわれわれからするとご褒美なんです」（増田氏）\n\n そんな増田氏でも「これはないよ……」と悩ませるものもあった。それが「王様戦隊キングオージャー」と「仮面ライダーギーツ」の劇場公開を記念し制作された、両作のキャラクターが踊るダンス動画「天下一舞踏会『映画スペシャルチーム・ギーツオージャー』」だ。\n\n この映像は、ボリュメトリックキャプチャーでキャラクターのダンスを動画としてスキャンし、Unreal Engineでワールド上に展開して制作。広大すぎるワールド、大量に分身するキャラクター、ボリュメトリックキャプチャーが苦手とする寄りのアングルなど「あれが一番きつかった」「ワールドが広すぎて全然まともに動かないんです。アングルも結構厳しかった」と漏らすほど。\n\n そんなオーダーに対し、安定化させるためのアルゴリズムを開発。分身シーンもうまくいくよう新規開発を入れて対応したという。結果、このダンス動画は無事に完成。「おかげさまでUnreal Engine用に作っていたプラグインの安定度はだいぶ増しました。技術的な進歩はホップ、ステップ、テークオフぐらい」（増田氏）と胸を張る。\n\n 「僕も初めてボリュメトリックキャプチャーを使わせてもらいましたけど、線引きが分からなかったんですよね。分からないからこそ1回限度を知りたくて」「ここまでかなと思ったら何も言われない、この人たちすごいなと思って」（上堀内氏）\n「外ロケ」と「バーチャルプロダクション」どう使い分けた？\nバーチャルプロダクションをフル活用したキングオージャーだが、ロケ撮影が全くなかったわけではない。\n\n 「割と感覚的なところは大きい」としつつも、「林とか、かなり自然物が多いシチュエーションで撮影したい場合は、やっぱりロケーションに出ちゃいます」「海や遠景なら（バーチャルプロダクションでも）良いんですけど、清流だとアセットで組み上げるのは難しい」と上堀内氏は語る。\n\n 一方で「清流って近郊にないんですよ。やはりコストの話があって、その時は3～4人で清流の下地になる映像を山奥に撮りに行って、ソニーPCLさんのLEDウォールで撮影したんです」「清流の中にいるという設定だったので、あまり動きの激しくないシーンだった。じゃあ水の中でバチバチにアクションしますとなったら、それはロケーションに出ると思います。ただ、『こうなったら完全にロケーションだな』となる前に、もう一段階ある感じですね」（上堀内氏）\n\n 下絵の撮影時に両プロデューサーと取り決めしたように、バーチャルプロダクションの活用はコスト管理だけでなく、スケジュール管理にとってもプラスに働いた。\n\n 「スケジューリングであったり、コスト面が分かりやすくなりました。すごく見えやすくなるというか、都合がつきやすくなる」「雨天というのもなくなってくるので、キャスティングの融通も利くようになってきます」（上堀内氏）\n\n とはいえ、仕組みをゼロから作っていく必要があったため、全てで業務を効率化できたわけではない。「こんな大規模にバーチャルプロダクションを使うのが初めてだったので、その構築と、バーチャルプロダクションを使用して撮影を進めていくということの構築でバタバタはしました」（同氏）\n最後のチャレンジは「ロボ戦」に\n最終話では、宇蟲王こと「ダグデド・ドゥジャルダン」と、巨大ロボ「ゴッドキングオージャー」のバトルが繰り広げられたが、このシーンは全面ボリュメトリックキャプチャーが使用されており、自由度の高いカメラアングルを実現している。\n\n 「キングオージャーには、宇宙も1つの大きい部屋という設定があります。箱型だけど縦横無尽に動けるというものを番組の途中で作ったので、最終決戦がこのフィールドになるのは分かっていました。そこで縦横無尽なカメラワークを駆使し、いままでの特撮シリーズで見たことのないロボ戦が表現できたらいいなと」（上堀内氏）\n\n 「キャラクターのアクションってボリュメトリックキャプチャーにすごく向いていると思ったんですよ」「どうしてもモーションキャプチャーの上にCGのテクスチャーを被せるパターンだと、なかなかCG感が抜けない。（ボリュメトリックキャプチャーなら）人間の動き、ちょっとした機微を表現できるというのを39話で確信しました。だから50話（最終話）は割と細かくやっていこうと」（同氏）\n\n そのロボ戦に登場するゴッドキングオージャーのボリュメトリックキャプチャー撮影だが、特撮ロボならではの大変さがあったという。\n\n 「このロボがでかすぎて……」と増田氏。キャプチャー用のスタジオは高さ3mまで想定して作られているが、ゴッドキングオージャーの高さは3m以上。武器を上げるとそれ以上に高くなってしまう。\n\n さらに「ボリュメトリックキャプチャーでは、1カ所を少なくとも4～5台のカメラで撮らないといけないんですけど、ロボがゴツゴツしていて顔も奥に引っ込んでいる。撮れても2台とかで、そうすると形状が出せなくなってしまう」（増田氏）\n\n 清澄白河BASEのボリュメトリックキャプチャースタジオは円形のスタジオに100台以上のカメラが囲っており、これ以上の全体的な増設は難しかったものの、顔を重点的に捉えるためのカメラを追加したことで、奥まっていた顔のディティールを確保した。スタジオから飛び出してしまう部分は、カメラの位置を変えることで対応した。\n\n 「ロボがスタジオに入るか事前に確認してもらって、『入りました』というので当日来てみたら『カメラの位置を変えました』といわれて」「本当にすみません……と」（上堀内氏）\n「陳腐だったんだな……」と気付かされたというカメラワーク\nボリュメトリックキャプチャーは、「ロボ戦」の演出にも影響を与えた。それが、焦点距離にして6mmや9mm相当の超広角カットをふんだんに使用できたことだ。\n\n 「意外と自分の脳内で考えているカメラワークって陳腐なんだなっていうのを突きつけられたんです」「現場にある撮影レンズも11mmが最大ワイド。（ボリュメトリックキャプチャーなら）6mmとかも使っちゃうんですが、それってロケーションとか普通の撮影をやっていたらあまり出てこない発想で、最初のころのダンス動画ってそんなに広角がないんです」（上堀内氏）\n\n 「多分そこに発想が至ってなかったんです。ロボ戦で9mmを選んだのも、ワイドを無理やり見せたいのではなく、足元にグっと入ってツーショットで見せたいから」「リアルだとあの広角って作れなくて。単純に超アオリで2人を入れたい時に、それが可能になる世界を知れたんです」（同氏）\n日本でどう根付かせていくか\nこのように、映像表現の幅を広げるだけでなく、撮影に掛かるコストでもメリットがあるバーチャルプロダクションだが、日本でも浸透していくのだろうか。\n\n 上堀内氏は「日本のドラマ、映画を作る人間がまだ怖がっているというか、踏み入れたら大変そうだなと思っている方が多いと思う」と分析する。\n\n 「バーチャルプロダクションは特撮やハリウッド、例えばマーベルなどが使うものという考え方は、強い言葉だがもう遅い」「いつも苦労してるでしょ？ 空港のシーンを撮るの。だったらバーチャルプロダクションで撮ったらどう？ というのが当たり前になる業界を早く見たい」（上堀内氏）\n\n 「こういうシチュエーションが欲しい、という時にバーチャルプロダクションという手段を持っているか、持っていないかの差は大きい。それを理解する方からどんどん演出なり、撮影の視野が広がってくると思っている」と見解を示す。\n\n 長年戦隊シリーズに携わってきた大森氏も、「（戦隊シリーズは）47作品目、48年間続いている作品として、シリーズを継続していく手段として大きな武器を得たと思っている」「スーパー戦隊シリーズのスタッフが一番（バーチャルプロダクション）のノウハウがある状況になっている。このノウハウを出しながらどんどん成長していくべきなんじゃないかと思う」と語る。\n\n 「1話まるまるバーチャルプロダクション」を実現したことで、無事“テークオフ”を果たした上堀内氏。バーチャルプロダクションとボリュメトリックキャプチャーという新しい武器で、今度はどのような映像表現をわれわれに見せてくれるのだろうか。\nITmedia NEWS,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240225-00000041-zdn_n-000-2-view.jpg?pri=l&w=640&h=335&exp=10800'],"['https://news.yahoo.co.jp/articles/cb737ca923816b42e7403b3c3af1235906cee9d6/images/000', 'https://image.itmedia.co.jp/l/im/news/articles/2402/25/l_my_0225king-ohger01.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240225-041&utm_term=zdn_n-sci&utm_content=img']"
