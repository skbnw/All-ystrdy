headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
行政法学で見る「AIの現在地」～規制と利活用の両面から（Meiji.net）,https://news.yahoo.co.jp/articles/e51dcdb0ab8de748683cf855db4b31ff6fa8506d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240307-00010000-meijinet-000-1-view.jpg?exp=10800,2024-03-07T14:24:28+09:00,2024-03-07T14:24:28+09:00,Meiji.net,meijinet,Meiji.net,4849,\n行政法学で見る「AIの現在地」～規制と利活用の両面から\n横田 明美（明治大学 法学部 教授）\n\n行政サービスに生成AIを活用する動きが広がっています。すでに横須賀市など一部自治体はChatGPT等を導入し、書類の下書きなど業務の効率化を進めています。政府もデジタル庁を中心に、一部省庁の業務に生成AIを利用する方針です。しかし、そこにはいくつもの課題が。法学の立場から「行政とAI」の現状を分析します。\n\n◇「行政とAI」をめぐる法的課題\n\n「行政とAI」というテーマは2017年ごろから議論されていますが、昨今、私たちの身近なところにもAIの活用事例が出てきており、再び話題になっています。行政と法の関係を考える行政法にとっては、二重の意味で問題となります。それは「行政によるAIに関する規制」と「行政によるAIの利活用」です。\n\n前者は、AIに普及がもたらす社会の変化に、行政はどのように対応するべきかというテーマです。従来の規制で変化に対応できるのか。新しい規制の生成過程から、執行に至る過程まで、さまざまな事柄が課題となります。\n\n後者は、行政のデジタル化とも関係するテーマです。人口減少に伴う働き手不足と高齢化の進展に伴う社会の変化に対応するためには、行政サービスの負担軽減（ひいては破綻回避）にAIの利活用は不可避といえます。その場合もやはり、情報などをどのようにコントロールするかが課題です。\n\nこれまでの行政法体系は、海外の法制度を学びながら発展してきました。しかし、プライバシーや個人情報に関する規律など、情報に関する場面ではいろいろと錯綜しています。\n\nそもそも、行政法は紛争の事前予防としての役割が説かれることがあります。それは、民事法・刑事法による事後的な損害賠償や刑罰では解決できない紛争が存在することを示唆しています。\n\n市民にはそれぞれ活動の自由がありますが、社会に危険をもたらし得る活動であれば、行政が先行して規制をかけることで、社会の危険を合理的な範囲におさめることが必要な場合があります。\n\n行政が紛争の未然防止を図る主な手法としては、一定要件を満たしているかを認定する「許可」があります。他方、事後的な対応として調査権限を活用したり、事業者へ報告を求めたり、場合によっては事業停止命令や製品回収命令などを行うこともあります。\n\nたとえば、道路上の交通ルールは道路交通法で定められており、運転については自動免許証など“人”に着目した許可制により規制をしています。そのほか、タクシーやトラック運送など“事業”に着目した各規制（道路運送法等）、車検制度など“物”に着目した規制（道路運送車両法等）、あるいは高速道路の規格など“場”についての規制（道路法等）があります。\n\nこれらの行政権限は、市民の権利・自由を制約する側面を持つため、法律の根拠がなくてはいけません。国民を代表する議会がつくった法律や条例によってのみ、強制力を伴う行政活動は行うことができる。これを「法律による行政の原理」のうち「法律の留保」といい、法治主義の一側面です。これは、現代の日本社会では一定以上は実現されています。\n\nしかし、新たにAIという人間の行動や考え方を左右するようなものが出てきた今、その法治主義の原理に立ち戻って考えるべき課題がいくつも浮上しているのです。\n◇AI社会にはポリシーミックスで対応すべき\n\n「行政によるAIに関する規制」を具体的に考察してみましょう。たとえば、自動運転技術を搭載した自動車が交通事故を起こした場合。行政は道路を整備・確保する義務を負っており、走行する車両等の認証においても関与しています。それらが妥当であったかどうかは、場合によっては国家賠償法等によって法廷で問われることになります。\n\nしかし、ここにAIが絡んでくると、従来の行政規制が前提としていなかった、製品の出荷後の改変・変更可能性の問題が重要になります。もともと“物”に着目した行政規制は、利用者保護の観点から、出荷時の状態がそのまま保たれることを前提としており、メンテナンスが必要な場合や死傷事故につながり得る瑕疵が発見された場合には、自主回収や回収命令等による規律を予定しています。\n\nところが、AIなどのソフトウェアについての慣行はそうなってはいません。むしろ、セキュリティアップデートにより安全を確保するのはユーザー側にも求められています。とくに、プログラムがデータを学習して判断や推論を行うためのアルゴリズムを作成・修正していく機械学習の特性は、安全と規律をめぐる大きな論点となります。\n\n第一に、データ収集それ自体が利用者のプライバシーに与える影響があります。正確性や応用可能性を高めるために、AIは学習データとして大量の情報を収集し、加工し、分析することが想定されますが、その前提となっている収集過程におけるプライバシー侵害はすでにさまざまな方面で問題が表面化しています。\n\n第二に、学習後のプログラムによって何らかの問題が発生した場合、誰が責任をとるのかという問題があります。たとえば、AIが搭載された機器が出荷時には想定されていなかった動き方をした場合、その結果引き起こされた事故につき、その判断過程を検証する仕組みが必要となります。\n \n第三に、行政が規制を導入するとAIの開発に悪影響が及んでしまうという問題です。実際、これまで国はAIの開発に関するガイドライン等を作成してきましたが、これに対するパブリックコメントでは少なくない拒否反応が見られました。\n\nしかし、こうした反応については、開発者に対する禁止と許可、あるいは認証の仕組みだけを想定するような、ある種の誤解や相互不信があったように思います。法学の立場から言えば、原則として企業は開発など営利活動の自由がありますから、反対者たちが想定していたような、規制一辺倒にもならないわけです。つまり、単純に禁止などで対応するのではなく、守るべき方向性を示してその方向に社会を誘導するのが開発ガイドラインの目的であったところ、一種の「規制アレルギー」とでもいうような、過剰反応が出てしまったのはとても残念です。\n\nガイドラインによるべきだ、という考え方は一定程度進展しており、現在ではさまざまなガイドラインが、官民学から出されています。あるいは、行政が厳格な規制を設けるのではなく、情報の公開性を重視するビジョンを共有することで、開発者・メーカー側に自発的に報告書を提出してもらう方法もありえます。各企業が情報を公表して、それを行政が取りまとめる形で報告をする形式も考えられるでしょう。\n\nただ、これらのやり方にも限界はあります。「行政指導で自主的に従え」というだけでは、その考え方に従わない企業に対しては打つ手がありません。そのような場合には、古典的な規制の枠組みも必要となる……というように、行政にしかできないこともあるわけです。この場合でいう「規制内容」や手続も、既に紹介したような情報的規律に着目したやり方も考えられるところです。前述の報告書についても、報告書作成それ自体は義務化するとか、そういう落としどころも考えられます。\n\nグローバル企業が日本の皆さんの生活の隅々にまでサービスを提供している現状を考えれば、規制の枠組みを使うことそのものを躊躇してはいけません。必要な事柄についてはきちんと法律や条例を制定して、行政に規制権限を行使させ、安全を守るという態度決定も重要です。日本で「きちんと」規制がされていることは、海外からみても、日本の法制度はしっかり市民を守ろうとしているのだ、という信頼にもつながります。国内外のデータ流通が当たり前となっている今、このような信頼を得るということも、中長期的に重要な意味を持ってきます。\n\nこのようにさまざまな手法を組み合わせて適正な規律を考えていくというやり方は、環境政策等で一般的に用いられるポリシーミックスの考え方です。\n\n要は、安全確保のための個別法と民事ルールによって確保された、多層的な制度設計が理想だということです。安全性・透明性を確保するためには、規制一辺倒ではなく、また、まったく規制のしくみに頼らないで自主規制に委ねればよい、というのでもなく、さまざまな取り組みをミックスして、官民が試行錯誤しながらベストプラクティスを見つけていくべきであると思います。\n◇安全と利便性のバランスがとれた法整備を\n\nこのように、AIの規制についてさまざまな論点が存在する一方で、同時進行的に「行政によるAIの利活用」が進んでいます。少子高齢化により労働力に制約がかかるなか、国や自治体において自動化・省人化は必須です。\n\nすでに一部自治体で導入されている利活用例としては、「AIによる保育所マッチング」が挙げられます。保育園に入園を希望する膨大な応募者の選考や割り振り、さまざまな希望条件の整理など、これまで自治体職員らが人力で行ってきたサービスについてAIを利用することで、大幅な時間短縮に成功した事例が複数あります。\n\n他方で、行政法の観点からは、行政による保育所入所不承諾決定をめぐる議論があります。つまり、役所からの「希望の保育園への入園はできません」という通知に対して、応募者の不服があった場合に、どのようにしてその判断に至ったのかを行政は説明する責任があります。「AIが判断したことなので理由はわかりません」では困るわけです。行政職員にとっても応募者にとっても、しっかりとシステムの透明性が確保されていなければなりません。\n\n他にも、ChatGPTなどの生成型AIは役所の業務の効率化に期待がかけられていますが、ここで問題になるのが情報との絡みです。生成型AIの精度を上げるためにはデータを学習させる必要があります。しかし、行政としては、その際にどの程度の情報まで与えてよいのかの線引きが難しいと思われます。杓子行儀で大幅な制限をかけてしまうと、せっかくのシステムの利便性が損なわれてしまう結果になりかねません。\n\nここに現在、デジタル庁が進めている法制事務のデジタル化の議論も加わってきます。そこでは、最終的に法律の運用や執行面でもデジタル技術の利用を視界に入れたロードマップが敷かれています。ですが、そこでもやはり「法律による行政の原理」が問題となるでしょう。先ほどは「強制力を働かせる場合には」という古典的な考え方を紹介しましたが、それに従ってきたがために、薄く広く大きな影響を与えるという側面での法的規律は実はあまり進んでいません。どの程度まで、法律が必要なのか、も改めて問われていると思います。\n\n法の世界において、これまでは有権者の代表である議員が法律を定め、法律で決めきれない細かい部分において、行政がルールに基づく判断・運用を行ってきました。これからは、その行政が判断していた部分をAIが補佐する場面が増えてくることが予想されます。その場合においても、安全と利便性のバランスがとれた法整備ができるよう、法や制度をシフトしていかなければばいけません。\n\nAIの普及がもたらす変化は、分野を問わず、あらゆる場面で法的規律のあり方を変えてしまいかねない影響力を持っています。その点、行政法はどうしても人の権利や組織に関する議論が主流で、なかでも情報公開や個人情報保護、公文書管理といった課題を扱う「行政情報法」がやや軽視されてきた節があります。しかし、AIとの共存が不可欠な時代においては、むしろ情報を扱う法分野こそ重要性が増していくのではないかと私は思います。\n横田 明美（明治大学 法学部 教授）,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240307-00010000-meijinet-000-1-view.jpg?exp=10800'],['https://news.yahoo.co.jp/articles/e51dcdb0ab8de748683cf855db4b31ff6fa8506d/images/000']
