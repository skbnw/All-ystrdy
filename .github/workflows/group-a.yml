name: Scheduled Ynews Scraping A

on:
  schedule:
    - cron: '0 10 * * *'  
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: '3.8'
      
      - name: Create directory
        run: |
          current_date=$(date +'%Y_%m%d') 
          folder_name="html-mediaALL_a_${current_date}" 
          mkdir -p $folder_name # フォルダ作成

      - name: Install dependencies
        run: pip install pandas requests beautifulsoup4 pytz boto3
      
      - name: Run scraper
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: python group-a.py

      - name: Set Git Config
        run: |
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
        working-directory: ${{ github.workspace }}

      # リモートリポジトリの変更を取り込む
      - name: Pull remote changes
        run: git pull origin main
        working-directory: ${{ github.workspace }}

      # CSVファイルをコミットしてプッシュ
      - name: Commit and push csv files
        run: |
          git add .
          git commit -m "Update csv files - $(date +'%Y-%m-%d')"
          git push
        working-directory: ${{ github.workspace }}
