headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
GitHub、「GitHub Actions」にArmベースのランナー（ZDNET Japan）,https://news.yahoo.co.jp/articles/b71a5b471d43db3e75a77f7e388153b9dc45d1c4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219627-zdnet-000-1-view.jpg?exp=10800,2024-06-04T12:03:00+09:00,2024-06-04T12:03:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,615,\nGitHub、「GitHub Actions」にArmベースのランナーの画像\nGitHubは米国時間6月3日、「GitHub Actions」向けにArmベースの「Linux」および「Windows」ランナーを発表した。\n\n GitHubがホストするArmベースのハードウェアを利用することで、Armアーキテクチャーが使用されているあらゆる場所でリリースアセットをビルドおよびデプロイできるようになったと同社は述べる。これまで、GitHubにてArm上でビルドするには、セルフホストするか、QEMU仮想化を利用するしかなかった。\n\n 新たに加わったランナーはGitHubによって管理され、Armが構築したイメージには開発者が使用を開始するのに必要なツールが全て含まれているという。電力効率に優れたコンピュートレイヤーを提供することで、価格対性能比を向上できるので、コンピュートコストを最適化して既存の予算内でより多くの作業を完了させつつも、カーボンフットプリントを削減することができるという。さらに、新しいランナーは、GitHubが提供するx64 LinuxやWindowsランナーよりも37％低価格で提供されているという。\n\n 新しいこれらのランナーは、「Team」プランと「Enterprise Cloud」プランで利用できる。オープンソースプロジェクト向けArmランナーの提供を年内には開始する予定という。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219627-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/b71a5b471d43db3e75a77f7e388153b9dc45d1c4/images/000']
大日本印刷と三菱UFJ銀行、豪州企業と連携し分散型IDの国際間接続を実証（ZDNET Japan）,https://news.yahoo.co.jp/articles/2a74ed02068a3639b4beba06f7561a519e7c46e5,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219628-zdnet-000-1-view.jpg?exp=10800,2024-06-04T13:00:00+09:00,2024-06-04T13:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,660,\n大日本印刷と三菱UFJ銀行、豪州企業と連携し分散型IDの国際間接続を実証の画像\n大日本印刷（DNP）と三菱UFJ銀行は、オーストラリアの金融機関やシステム開発企業と共同で、個人のアイデンティティー情報を管理する「分散型ID」に基づく、デジタル証明書の国際間利用に関する実証実験を行い、成功したと発表した。\n\n この実証実験では、OpenID Foundationが策定するデータ形式と通信プロトコルを採用することで、異なるデータ形式を持つ日本とオーストラリア間での相互接続を確認した。この際、欧州委員会が検討する「European Digital Identity Wallet」の技術仕様を参照している。\n\n 今回の実証において両社は、安全かつ簡易なデータ流通を実現するID基盤「ConnectID」を提供するAustralian Payments Plusなどと「日豪クロスボーダー相互運用性ワーキンググループ」を発足した。\n\n DNPと三菱UFJ銀行は、生活者が自身のアイデンティティー情報を管理する「分散型ID」の事業化を検証している。今回の実証は、グローバルで信頼性の高いデータ流通の実現に向け、日本とオーストラリアの企業間で初めて国境を越えたデータ連携の相互運用性を検証することを目的としている。\n\n 今後は、今回の技術的実証実験の結果を踏まえ、移住者の銀行口座開設手続きの効率化や観光客向け専用チケット購入など、日豪の生活者の利便性を高める多様なユースケースを対象に実証実験を進める。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219628-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/2a74ed02068a3639b4beba06f7561a519e7c46e5/images/000']
ライオンとNTTデータ、生成AIで熟練技術者の暗黙知伝承を促進（ZDNET Japan）,https://news.yahoo.co.jp/articles/cd911ca3c909c45e980918363035853e989812a6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219625-zdnet-000-1-view.jpg?exp=10800,2024-06-04T12:57:00+09:00,2024-06-04T12:57:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,852,\nライオンとNTTデータ、生成AIで熟練技術者の暗黙知伝承を促進の画像\nライオンとNTTデータは、ライオンの衣料用粉末洗剤の生産技術領域において、生成AIを活用して熟練技術者の暗黙知を形式知化する取り組みを6月に開始したと発表した。\n\n 具体的には、衣料用粉末洗剤の製造プロセス開発における暗黙知を抽出し、「勘所集」として文書化する。これを検索サービス「知識伝承AIシステム」に取り込み、新たな製造プロセス開発メンバーが熟練者の技術や知識・ノウハウを容易に検索・活用できる環境を構築する。生成AIは、勘所集作成における熟練者へのインタビュー結果のまとめに適用するという。\n\n ライオンは、この取り組みを通じて、国内外の技術力強化とグローバルECM（Enterprise Contents Management）の推進を目指す。\n\n 従来、新規参画者への技術継承は熟練者に大きな負担を強いる課題があった。そこで、アジアでの需要が高く、熟練者の暗黙知が必要とされる衣料用粉末洗剤を対象テーマに選定した。\n\n 勘所集は、NTTデータが熟練者へのインタビューやワークショップを通じて情報収集し、暗黙知化している技術や知識・ノウハウを抽出して作成する。\n\n 知識伝承AIシステムの活用シーンとしては、品質に影響する留意事項などに関する熟練者のノウハウを容易に検索・活用できるようにし、効率的な学習と技術力向上を図ることなどが挙げられている。また、熟練者が長年かけて習得した製造条件設定のコツを生成AIで伝承し、新規参画者への指導負荷を軽減するケースも想定されている。\n\n ライオンは、暗黙知の抽出範囲拡大や定期的な抽出、他製品への展開を通じて、国内外の技術力向上を目指す。\n\n NTTデータは、知識伝承と活用のユースケースを確立し、暗黙知を含む知識抽出と生成AI活用を組み合わせたサービス提供を推進していく。将来的には、NTT版の大規模言語モデル「tsuzumi」の活用も検討する。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219625-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/cd911ca3c909c45e980918363035853e989812a6/images/000']
イーデザイン損保とNTT Com、生成AIアバターによる顧客接点高度化を実証実験（ZDNET Japan）,https://news.yahoo.co.jp/articles/7b3d92c103331a1ea2f3ea2a4ac5fe631126f435,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219630-zdnet-000-1-view.jpg?exp=10800,2024-06-04T13:04:00+09:00,2024-06-04T13:04:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,662,\nイーデザイン損保とNTT Com、生成AIアバターによる顧客接点高度化を実証実験の画像\nイーデザイン損保とNTTコミュニケーションズ（NTT Com）は、自動車保険の車両入替業務を対象に、生成AI搭載アバター（バーチャルコンシェルジュ）の精度検証を実施したと発表した。両社は3カ月間の検証の結果、構築した対話モデルは顧客接点として商用化可能な水準を評価し、実用化に向けた検討を進める。\n\n この取り組みでは、実在する社員を基にしたバーチャルコンシェルジュについて、自然な動作や応答速度に課題が残るものの顧客接点としての活用可能性が示された。\n\n また、悪意のある問いかけや誤情報の生成を想定した対話では、一定の効果が確認されたが、ルールベースとの融合など、さらなる検討が必要と判断された。\n\n 今回の実証実験では、イーデザイン損保が利用シーン定義、対話シナリオ提供、評価を担当し、NTT Comがシステム構築とバーチャルコンシェルジュのデザインチューニングを担当した。\n\n 対話モデルには、車両の入替手続きに関する対話やFAQ（よくある問いと答え）を生成AIに組込み、通常の入替手続きに加え、主な運転者変更などのイレギュラーケースを含む5種類のシナリオで対話精度や応答速度を評価した。\n\n バーチャルコンシェルジュには、De-Identificationの最先端動画生成AI「Creative Reality Studio」を活用し、悪意ある問いかけへの対応は、生成AIのフィルター機能で検証した。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219630-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/7b3d92c103331a1ea2f3ea2a4ac5fe631126f435/images/000']
NVIDIA、次世代GPUアーキテクチャーをサプライズ予告（ZDNET Japan）,https://news.yahoo.co.jp/articles/d8123bd174b39c24ca70dd3ce6b111e7c339cd56,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219617-zdnet-000-1-view.jpg?exp=10800,2024-06-04T09:38:00+09:00,2024-06-04T09:38:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1374,\nNVIDIA、次世代GPUアーキテクチャーをサプライズ予告の画像\nNVIDIAのGPU「Blackwell」とCPUファミリーの後継製品が、米国の天文学者Vera Rubin氏にちなんで「Rubin」と命名され、2026年前半に発売されることが明らかになった。同社の最高経営責任者（CEO）Jensen Huang氏が、台北で開催されたコンピューター見本市「COMPUTEX 2024」において、現地時間6月2日夕方の基調講演で発表した。\n\n 今回の発表は、新しいチップアーキテクチャーを1年周期でリリースするというHuang氏の公約を改めて強調するものだ。\n\n Huang氏は、スライドをクリックしてRubinファミリーを紹介する前に、「このスライドをクリックして次のページを表示するのは本当に今回が初めてで、後悔することになるかもしれない」と、冗談めかして語った。\n\n 「これらのチップはどれも全力で開発中だ。すべてのチップについて、1年という周期で、テクノロジーを限界まで追求し、アーキテクチャー的に100％の互換性を完全に達成する」と、Huang氏は述べ、「そして、ありとあらゆる豊富なソフトウェアがその（アーキテクチャー）上で動作する」と語った。\n\n Rubinの発表が驚きを持って迎えられたのは、3月に開催された「NVIDIA GTC 2024」でBlackwellの正式発表があったばかりだからだ。\n\n ウォール街の証券会社Jefferies & Co.がテクノロジー系ニュースサイトWccftechの記事を引用する形で公開したリサーチノートによれば、GPUチップファミリーを含むRubinチップと、「Vera」と名付けられたCPUでは、コンピューター用DRAMメモリーが、現時点で最速の「HBM3e」から次世代の「HBM4」に変わる予定だという。また、GPUチップは「R100」と呼ばれるようだ。\n\n このチップは、台湾のTaiwan Semiconductor Manufacturing Company（TSMC）が3ナノメートル製造プロセスを使用して製造し、2025年第4四半期に生産が開始される予定だと、Jefferiesのアナリストは述べている。\n\n また、Rubinでは「4倍のレチクル設計」が採用されるため、3.3倍のBlackwellよりも、12インチのシリコンウェハーで有効利用できる面積が増えることになると、Jefferiesのアナリストノートには記されている。「レチクル」とは、標準的なフォトリソグラフィーシステムが、チップの回路を転写する際に1回のパスで対応できるウェハーの領域を指す言葉だ。\n\n Huang氏は、Blackwell GPUの次期バージョンとなる「Blackwell Ultra」も公開した。また、Rubinアーキテクチャーでも、「Ultra」バージョンが2027年にリリースされる予定だと、同氏は語った。\n\n NVIDIAがCOMPUTEXで発表したすべてのニュースは、同社のニュースサイトまたは同社のイベントをまとめたブログ記事で確認できる\n\nこの記事は海外Red Ventures発の記事を朝日インタラクティブが日本向けに編集したものです。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219617-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/d8123bd174b39c24ca70dd3ce6b111e7c339cd56/images/000']
日立製作所とマイクロソフト、生成AIで戦略的提携--3年間で数十億ドル規模を見込む（ZDNET Japan）,https://news.yahoo.co.jp/articles/fd841cd4621b213ceda492956ee260db799cac3e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219624-zdnet-000-1-view.jpg?exp=10800,2024-06-04T11:34:00+09:00,2024-06-04T11:34:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2986,\n日立製作所とマイクロソフト、生成AIで戦略的提携--3年間で数十億ドル規模を見込むの画像\n日立製作所とMictrosoftは6月4日、生成AIを活用した社会イノベーションを加速するため、今後3年間で数十億ドル規模を見込む協業を推進すると発表した。この戦略的提携を通じて、日立はLumada事業の成長を加速させるとともに、グループ27万人の業務効率化や生産性向上を推進する。\n\n 具体的には、LumadaソリューションにMicrosoftのクラウド、「Azure OpenAI Service」「Dynamics 365」「Copilot for Microsoft 365」「GitHub Copilot」などを組み込む。また、生成AIの普及によって対応が迫られているセキュリティ強化などクラウドサービスの高度化や、データセンターの環境負荷低減などの喫緊の課題解決に向け、共同プロジェクトの立ち上げも推進する。\n\n 日立製作所 執行役社長 兼 最高経営責任者（CEO）の小島啓二氏は、「日立は、生成AIの徹底活用による生産性向上など日立グループでのAIトランスフォーメーションを推進していくとともに、生成AIに2024年度で3000億円（21億ドル）の成長投資を行い、新たな成長機会の獲得を目指す。Microsoftとは、これまで製造・ロジスティクス分野向け次世代デジタルソリューション開発・提供や、『Microsoft Teams』上で動作する現場拡張メタバースの開発など、さまざまな協創を推進してきた」と話す。\n\n 加えて、「今後、さらに重要になるフロントラインワーカーの生産性向上に向け、これまでの取り組みを深化させるとともに、エネルギーやモビリティーなど社会インフラの領域へと拡大し、生成AIを適用することで社会イノベーションをさらに加速していく。両社のケイパビリティーを結集することで、お客さまや社会の課題を解決し、サステナブルな社会の実現に貢献できると信じている」とコメントした。\n\n Microsoft 会長兼CEOのSatya Nadella氏は、「私たちは、あらゆる役割と業界において画期的なビジネス成果をもたらすAIの新時代を迎えている。日立とのパートナーシップ拡大により、『Microsoft Copilot』をはじめとするMicrosoft Cloudのパワーと、幅広い業界を熟知した日立の専門知識を結集し、27万人の日立グループの従業員の生産性を向上させ、持続可能性をはじめとするお客さまの最大の課題に対応することが可能になる」と述べる。\nこの提携により、両社は次の4分野において取り組みを進める。\n\n1．日立の全社トランスフォーメーションの推進\n\n 日立の「Generative AIセンター」がMicrosoftと連携しながら、Copilot for Microsoft 365、GitHub Copilotの活用による業務効率化やアプリケーション開発の生産性向上、「Azure OpenAI Service」を活用したカスタマーサービスの高度化を推進していく。\n\n 具体的には、日立全社のAIトランスフォーメーションの一環として、アプリケーション開発においてAzure OpenAI ServiceやGitHub Copilotと日立のシステム開発の知見などを組み込み、ミッションクリティカルシステムにも対応する高い開発品質の維持と生産性向上を実現する。日立のナレッジである詳細設計情報を入力した社内検証では、アプリケーションのソースコードを 70～90％の割合で適切に生成でき、品質の高いアウトプットを得られることを確認したとしている。\n\n また、鉄道事業のグループ会社である日立レールでは、機器監視の強化や予測精度の向上による予知保全を可能にするため、生成AIを活用する。これにより、安全性を強化しながら、故障の低減、サービス品質の向上、運用コストの削減を実現する。この一例として、鉄道インフラをデジタルで監視するためのプラットフォームをAzure上で構築し、データの可視化と分析をAIで最適化することで、インサイトが得られることを確認した。この実績を基に、英国の大手鉄道システム運営会社であるNetwork Rail向けに適用した結果、架線の予知保全の意思決定を強化することができた。\n\n2．革新的なデジタルソリューションの開発\n\n 日立はLumadaソリューションに生成AIのケイパビリティーを取り込むことで強化を図っている。既に2万社規模のユーザーを有する統合システム運用管理「JP1」のSaaS版である「JP1 Cloud Services」において、Microsoftの生成AIを活用したサービスの提供を始めており、金融・公共・製造など幅広い企業のIT部門のオペレーターによる障害対応の初動の迅速化や運用効率化を見込んでいる。先行実施した社内実証では、生成AIによりアラート対処方法を回答し、その根拠となるマニュアルなどの引用元も表示したことで、運用オペレーターの初動の判断時間を約3分の2に短縮できる効果を確認した。\n\n 今後さらに適用を拡大すべく、日立とMicrosoftは、新たにエネルギー業界においてもアセットパフォーマンス管理やエネルギー取引およびリスク管理などのデジタルソリューションを強化することで、エネルギー転換を支援し、ダウンタイムの削減と収益性の拡大を図る。これらのアプリケーションを拡張するためには、コンピューティングパワーとクラウドインフラの向上が不可欠であり、日立エナジーのエンタープライズソフトウェアソリューション技術とMicrosoftとのパートナーシップは、発電から送電・配電に至るエネルギーネットワークを最適化し、信頼性の高い持続可能なエネルギーを企業に提供する上で重要な役割を果たすという。\n\n3．サステナブルな成長を目指した共同プロジェクトの開始\n\n GlobalLogic、Hitachi Digital Services、日立ソリューションズをはじめとする日立グループ各社は、デジタルエンジニアリング、IT、マネージドサービス、クラウド向けアプリケーションサービスなど、幅広いサービスを提供している。今回のパートナーシップによる新たな開発では、Microsoftとの持続的なイノベーションを目指し、幅広いサービスの強化に注力していく。\n\n また、AIに起因する二酸化炭素（CO2）排出量が地球環境に与える影響が増大する中、環境負荷低減に向け、日立とMicrosoftは欧州でのデータセンタープロジェクトをはじめとし、ゼロカーボン化に向けて取り組んでいく。\n\n4．デジタル人財育成の強化\n\n 日立は、企業のAIトランスフォーメーションを支援する人材「GenAI Professional」を育成するプログラムに、GitHub CopilotやAzure OpenAI Serviceを活用した高度なソフトウェアの開発スキルを身につける研修なども組み込み、5万人以上のGenAI Professionalを育成する。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219624-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/fd841cd4621b213ceda492956ee260db799cac3e/images/000']
ネットの現状--M・ヒッポネン氏が指摘するAIの進化とセキュリティ（ZDNET Japan）,https://news.yahoo.co.jp/articles/504720791a3d20d12c44ba72c156fab068c642ff,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219615-zdnet-000-1-view.jpg?exp=10800,2024-06-04T08:28:00+09:00,2024-06-04T08:28:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,4274,\nネットの現状--M・ヒッポネン氏が指摘するAIの進化とセキュリティの画像\nヘルシンキを拠点とするWithSecureは現地時間5月28～29日、同社年次カンファレンス「SPHERE24」を開催した。初日のメディア向けセッションでは同社で最高リサーチ責任者（CRO）を務めるMikko Hypponen氏が登壇した。\n\n 同社の前身であるData Fellowsに6番目の社員として入社したHypponen氏は、サイバーセキュリティ企業が全てスタートアップだった頃のことを今でも覚えていると述べ、いつものように上着のポケットからフロッピーディスクを取り出す代わりに、パンチカードを見せた。\n\n セキュリティ業界で長く働く同氏は、セキュリティの状況を見た時、自分たちがいかに良い状態にあるかを認識するようにしているという。現在、新たなデータ流出、情報漏えい、感染拡大などが日々報じられ、良い状態にあるとは決して思えないが、「一歩下がって、10年前を振り返ってみよう」と同氏。2014年に主流だったのは「Flash」の悪用だ。\n\n 現在と10年前では、コンピューティングに使うデバイスのセキュリティは異なると同氏は指摘する。今日、コンピューティングの大部分はスマートフォンやタブレットで行われる。これらのユーザーは、自身のデバイスをプログラミングする権利を手放す代わりに、優れたセキュリティを手に入れることができる。「だから、良い状態にある」と同氏は述べ、「勝っているとは言わないが、悪いニュースばかりではない」とし、新しいシステムやアーキテクチャーが構築され、WithSecureのような企業が提供するセキュリティーもあると続ける。\n\n ただし、攻撃者もじっとはしていない。同社は現在、中堅・中小企業に注力しているが、そのような企業はさまざまなセキュリティ上の問題を心配するものの、自衛のためのリソースや予算がある大企業と異なり、十分なサービスを受けていないという。このようなシナリオ全体に目を向けた場合、常に浮かび上がってくるのがAIだという\n\n 「誰もがAIに熱狂しているのには理由がある。技術革命は、今日の社会を何よりも大きく変える」（同氏）。インターネット、モバイル、ソーシャルメディアとさまざまな技術革命が起き、人々の生活に利便性をもたらしてきた。ただし、それだけではない。全ての技術革命がプラスとマイナスの面を持ち、プラスだけを享受することはできないとHypponen氏は同カンファレンス2日目の講演でも指摘している。\n\n 人は、技術革命に直面した時、そのスピードを過大評価し、規模を過小評価する傾向にあるという。「革命が起こると分かっていても、それが世界をどう変えるか、少し先の未来を正確に見通すのは難しい」（同氏）\n\n Netscape設立前のMark Andreessen氏が「Mosaic」ブラウザーについてインタビューを受けた際、同ブラウザーで何ができるかを質問され、「何でもできる」と回答したという話にHypponen氏は触れ、まだ何も存在していないため、「天気予報やニュースをネットで見られるようになる」といった具体例を思いつくことができていないと指摘する。「今、自分たちはAIにおいてどうなのか。AIで何が起こるかを本当に分かっていない」と同氏は説く。\n\n 生成AIの用途の一つとして、異常検知システムがある。顧客のネットワークに設置され、データを収集し、その組織における通常の一日についてビューを構築し、それとは異なる動きがあれば検知する。こうした仕組みは、大惨事になる前に情報漏えいなどの可能性を警告する。このようなメカニズムは汎用で、ビルの管理システムといった目的にも利用できる。ビル内の特定の場所に行ったことがない従業員が、夜中の2時にそこにいるといったことを検知する。「この種のシステムは強力だ。コンピューターは人間よりもデータを解析するのが得意だ」（Hypponen氏）\n\n 生成AIシステムを構築している企業については、どのように考えるべきか。OpenAIは、人工汎用知能（AGI）の構築をミッションとしていた。AGIの構築は、私たちができることなら機械でもできるようになることを意味するが、AIが人間のレベルで止まる理由はないと同氏。AIにそのソースコードを与え、「小さな改善で構わないので加え、コンパイルし、新しいバージョンを自身に適用することを何度でも繰り返す」ことを命じると、人間の知性の限界を越えるものに行き着く可能性がある。「とても素晴らしく、同時にとても恐ろしいことだ。自分の生物圏に優れた知性を導入することは、基本的な進化の過ちのように思えるが、どうだろう。彼らがやろうとしていることはそういうことだ」とHypponen氏はいう。\n\n OpenAIはユニバーサルベーシックインカムについて真剣に研究しているという。私たち全員が失業し、全ての富がAIによって生み出される未来を見ているからだとHypponen氏は語る。「結論に飛びつき、この革命のスピードを過大評価するのは簡単だ。おそらく明日や来年には起きないだろうが、いつの日か起きるかもしれないし、起きた場合には、私たちが今考えたり想像したりするよりも大きな変化になるだろう」（同氏）\nWithSecureでは生成AIが可能にする現実的な近い将来の脅威について考えている。その一つがディープフェイクだ。ディープフェイクやそれに類似する攻撃について興味深いのは、大げさに語られる傾向が見られることだという。AIで作成した最高財務責任者（CFO）の顔の画像を使って、財務担当者にある口座への振り込みを命じるといった話が報じられているが、技術的に不可能でないにしても、大規模に起こっているわけではないという。\n\n 生成AIが直面しているもう一つの問題は、デープフェイクを使った詐欺行為である。一般的に消費者攻撃であるロマンス詐欺やオークション詐欺では、加害者が人間ならば、一人で相手ができる被害者の数は限られてくる。しかし、大規模言語モデル（LLM）を使えば、あらゆる言語で数多くの人を騙すことができる。Hypponen氏は、OpenAIとの会合で、これらの行為を防ぐため、「なぜロマンチックな会話を全面的に禁止しないのか」と聞いたところ、バーチャルなボーイフレンドやガールフレンドとのロマンティックな会話を可能にするボットをアプリケーションとして構築している有料顧客がいるため、難しいとの回答だったという。\n\n このような詐欺に利用される不正なモデルは、セキュリティや安全性のための制限が無効化されている。「GPT」を名前に冠していたりするが、GPTをベースにしているものはない。これは、GPTはサービスとして提供されているだけで、オンラインでしかアクセスできないためだ。「OpenAIのGPTはクローズドソースだ。クローズドソースで改変できないので、不正なバージョンは作れない」（Hypponen氏）\n\n OpenAIはかつてオープンソースだったが現在は違う。同社は、コードをオープンにするだけでなく、モデルや方法をオープンにするのは危険すぎると考えている。「私はオープンソースの大ファンなので、このことについては自分の中で意見が割れている」とHypponen氏は述べ、「オープンソースに限界があるとすれば、それはAIの分野かもしれない。フィッシングメールの作成を防ぐ安全性やセキュリティ上の制限となるガードレールがオープンソースでは取り除くことが可能だからだ」と続ける。\n\n LLMを使用するマルウェアも問題となっている。LLMを搭載しているマルウェアはまだ発見されていないが、「LLMorpher」のようにLLMのAPIを呼び出す機能を搭載したマルウェアは存在する。OpenAIは、APIキーをブロックすることで対応しているが、攻撃者は、新しいアカウントを作成することで応じており、イタチごっこの様相を呈しているという。最終的にはインターネットへのアクセスやAPIキーを必要とせず、自身のコード内にモデルを搭載するようなマルウェアが登場すると同氏は予想する。\n\n 実現にはまだ数年が必要となるだろうが、それほど時間を必要としないと思えるのが、マルウェア攻撃の完全自動化だという。WithSecureのようなサイバーセキュリティ企業は自動化を多用しているが、攻撃者は自動化していない。しかし、近い将来自動化するだろうし、その場合は、悪いAIに対して良いAIが対抗することになる。「セキュリティ会社の方が優れていると信じている」（Hypponen氏）\n\n さらに、攻撃者が悪用する可能性があるのは、生成AIを使って未知のセキュリティ脆弱性の発見することだ。プログラムの動作を理解させた上でバグを検出し、その中からリモートで悪用可能なものを見つけ、それをリモートで悪用できるコードを書くということができるようになるまで、あとわずかのところまで来ているという。\n\n AIについては、攻撃側と防御側の競争に加えて、東西間の貿易問題も関わってくる。米国は、中国が最先端のコンピューティング能力へのアクセスを制限するため、「NVIDIA H100」のような製品の輸出を制限しようとしている。ロシア大統領のPutin氏は、人工知能が未来であり、AIを支配する者が世界を支配することになると発言している。「私は彼の意見には全て賛成できないが、この部分では彼が正しい。独裁国家が最も優れた生成AIメカニズムが構築するような未来は見たくない」（同氏）\n\n 「技術革命は世界を変える。私たちが見てきた技術革命ほど、世界を大きく、速く変えるものはない。かつての技術革命である産業革命や電気革命は、何百年もかかった。今日の革命はかつてないほど速い。インターネット革命には20～30年かかった。革命のスピードはさらに速くなり、次の技術革命が何であるかが問われることになる。それが何であれ、ほとんどの場合、人間によって構築されることはなく、AIによって構築されることになるだろう。この全てがとても素晴らしく、少しだけ恐ろしい」とHypponen氏は語った。\n\n（取材協力：ウィズセキュア）,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219615-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/504720791a3d20d12c44ba72c156fab068c642ff/images/000']
フロッピーディスクは今なお現役--発展の歴史と現在の用途（ZDNET Japan）,https://news.yahoo.co.jp/articles/475954dcffc65c77aa55ff5da4ba069f545b0db7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219378-zdnet-000-1-view.jpg?exp=10800,2024-06-04T07:30:00+09:00,2024-06-04T07:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3619,\nフロッピーディスクは今なお現役--発展の歴史と現在の用途の画像\n筆者は1970年代半にフロッピーディスクを使い始めたときのことを覚えていない。ファームウェアをIBMの「S/370」メインフレームにインストールしたときか、図書館の専用ワークステーションで米議会図書館の目録記録を作成したときだっただろうか。何とも刺激的な生活を送っていたものだ。いずれにせよ、当時使っていたのは確か8インチの片面フロッピーディスクで、データの記憶容量は驚異の79.7KBだった。\n\n これは本当に、当時としてはただ事ではなかった。ポータブルストレージの他の選択肢が、IBMの12行／80列のパンチカードや9トラックのテープだった時代だ。これらは一言で言えば、扱いにくかった。\n\n フロッピーディスクは、筆者がコンピューターを使い始める前から存在していた。1960年代後半、IBMのエンジニアだったAlan Shugart氏とDavid L. Noble氏は、データを格納するコンパクトでポータブルな解決策に思いをめぐらせていた。この「Project Minnow」という先駆的な取り組みから、1971年に初の市販8インチフロッピーディスクが生まれた。その79Kという容量は無に等しいと思えるかもしれないが、保存できた容量はパンチカード3000枚に相当する。\n\n 使うのをやめるなら、1枚のディスクと数千枚のカードのどちらがいいだろうか。当時の誰もが思っていたことは、読者の皆さんの答えと同じはずだ。\n\n 1970年代にパーソナルコンピューターが人気になると、フロッピーディスクはメインフレームとワークステーションの世界からPCへと移っていった。そこで、手頃な価格で入手やすいストレージソリューションという地位を確立していく。\n\n その後の1976年に、Steve Wozniak氏という人物が自身の次のコンピューターにフロッピードライブを追加しようとしていた。友人のSteve Jobs氏は、5.25インチのフロッピーディスクをShugart氏の新会社Shugart Associatesから1976年に入手し、大量の改良作業を経て、Wozniak氏は後に「Apple II」となるマシンで初のフロッピードライブを稼動させた。\n\n こうした新型ディスクの当初の容量は、90～110KBだった。その後のアップグレードで、まずは160KBに、続いて360KBに増量された。一般的にはこれがフロッピーディスクのデフォルトの容量と考えられている。1984年には、容量1.2MBのディスクが「IBM PC/AT」とともに登場。それらのディスクと6MHzの超高速コンピューターは大きな人気を博した。\n\n そこからフロッピーディスクは軌道に乗った。プログラムをこれらのポータブルディスクで配布可能になり、ソフトウェア企業は郵送や小売店で製品を販売できるようになった。最初のソフトウェア市場はフロッピーディスクから生まれたということだ。\n\n その影響は大手企業だけにとどまらない。フロッピーディスクによって誰もがプログラムを作成して販売できるようになったことで、フリーウェアとシェアウェアの動きが活発になった。また、ユーザー間での簡単なデータ共有も初めて可能になった。モデムや電子掲示板（BBS）を使って、プログラム、画像、データが共有されるようになるずっと前に、それらの情報が「スニーカーウェア」で共有されていた。これはまさに、ディスクを手で持ち運び、情報をあるコンピューターから別のコンピューターへ移すというものだ。\n\n 1981年には、ソニーが3.5インチのフロッピーディスクを発売した。この製品は、従来のものと比較してサイズが小さく、ストレージ容量が大きいため、すぐに人気を博した。安定性も以前のモデルより大幅に向上していた。それまでの製品は、摩耗によってすぐに故障することが多かった。\n\n もはや「フロッピー」（ペラペラ）ではなかったが、このフォーマットがフロッピーディスクの標準になった。その人気は優に1990年代まで続き、フロッピーディスクは普遍的な記憶媒体としての地位を確立。この設計の当初の容量は720KBだったが、最も人気のバージョンは1.44MBだった。\nコンピューターネットワークと、新しいストレージ形式（USBフラッシュドライブやメモリーカードなど）の台頭に伴い、フロッピーディスクの影響力は1990年代半ばから後半にかけて弱まっていく。フロッピーディスクドライブなしの「iMac」が1998年に発売されたことで、フロッピーディスクの時代は終わりを迎えた。\n\n 2000年代初頭には、フロッピーディスクがますます珍しいものになり、主にレガシーハードウェアや産業機器で使用されていた。ソニーが新しいフロッピーディスクを最後に製造したのは、2011年のことだった。\n\n 衰退したとはいえ、フロッピーディスクの遺産は存在し続けている。その象徴的なデザインはデータストレージのシンボルとなり、フロッピーディスクのアイコンは今でもファイル保存のシンボルとして多くのコンピューターのデスクトップに表示されている。\n\n しかし、時代遅れの技術と思えたとしても、フロッピーディスクは現在も使われている。たとえば、1990年代の工業用刺しゅう機は、模様やデザインをフロッピーディスクから読み取るように作られていた。コンピューター数値制御（CNC）マシンなど、一部の古い産業用機械や産業機器は、今もフロッピーディスクを使用してソフトウェアアップデートやプログラムを読み込んでいる。\n\n 「Boeing 747」の一部の古いモデルでは、重要なナビゲーションデータベースのアップデートとソフトウェアをアビオニクスシステムに読み込むために、まだフロッピーディスクが使われている。フロッピーディスクの販売とリサイクルを手がけるfloppydisk.comのプレジデントのTom Persky氏は2022年、実際に航空業界は依然として最大の顧客の1つだと述べた。\n\n もっと地上に近い場所では、1980年に開通したサンフランシスコのMuni Metroのライトレールがある。この路線では毎朝、職員が自動列車制御システムをフロッピーディスクで起動しない限り、運行が始まらない。なぜなら、ハードドライブがなく、不安定すぎて電源を入れたままにしておけないため、毎朝ディスクを挿入して電車を走らせる必要があるからだ。しかし、最終的には別のシステムに置き換えられることになる。現在のところ、最新の置き換えプロジェクトは2033年4月に完了する予定だ。\n\n フロッピードライブは、CTスキャナーや超音波装置などの医療機器でも生き続けている。米軍の核ミサイル基地で、運用コンポーネントの調整用システムの一部として、8インチフロッピーディスクが2019年まで使われていたことはよく知られている（悪評が立っているというべきか）。もっと楽しい用途としては、Chuck E. Cheeseのアニマトロニクスのフィギュアがある（8歳の誕生日パーティーで見ただろうか）。そう、これを起動するのもフロッピーディスクだ。\n\n もちろん、ミュージシャンのEspen Kraftのように、古いシンセサイザーやサンプラーでフロッピーディスクを使用してサウンドを読み込み、音楽を作っている人もいる。Kraftだけでなく、他のコレクターやレトロコンピューター愛好家も、フロッピーディスクの使用や取引を今日まで続けている。\n\n なぜいつまでも使われ続けるのだろうか。Persky氏はNPRにこう語った。「極めて安定性が高く、非常によく理解されており、ハッキングの可能性があまりなく、ごく少量のデータに関しては信じられないほど素晴らしい仕事をする」\n\n 確かに、それも理由の1つだろう。しかし、もう1つの理由は技術的負債だ。フロッピーが使われているマシンの中には、非常に高価なものもある。マシンが稼働し続けていて、古いフロッピーが消耗したときに新しいフロッピーを見つけて交換できる限り、マシンの入れ替えにお金を出したいとは誰も思わないだろう。もっと極端なケースでは、古いハードウェアの交換用の機械類が手に入らないことがある。\n\n 誰もが最終的には古いマシンを買い替えなければならなくなるだろう。しかし、自分がこの世を去る頃に、どこかの誰かがまだフロッピードライブを本番システムで使用していたとしても、筆者は少しも驚かないだろう。\n\nこの記事は海外Red Ventures発の記事を朝日インタラクティブが日本向けに編集したものです。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219378-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/475954dcffc65c77aa55ff5da4ba069f545b0db7/images/000']
AIは既存データセンターで動かせない--デルのCTOに聞く方策（ZDNET Japan）,https://news.yahoo.co.jp/articles/346a1becbb786ded8461dd4f3849d1cbe3016a96,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219459-zdnet-000-2-view.jpg?exp=10800,2024-06-04T06:00:00+09:00,2024-06-04T10:17:48+09:00,ZDNET Japan,zdnet,ZDNET Japan,3779,\nAIは既存データセンターで動かせない--デルのCTOに聞く方策の画像\nDell Technologiesは、同社の年次イベント「Dell Technologies World 2024」で、AI時代に向けた戦略を明確に示した。中核は、イベントで発表した「Dell AI Factory」で、NVIDIAの技術を利用する「Dell AI Factory with NVIDIA」とは分けている。グローバル最高技術責任者（CTO）のJohn Roose氏に、Dell AI Factoryなどの施策を聞いた。\n\n――Dell AI Factoryを発表しました。AI向けインフラの技術スタックといいますが、開発の背景を教えてください。\n\n われわれは、エンタープライズに注力しています。企業がAIを導入する場合、サードパーティーの製品を購入するだけでは、AIプロジェクトの成功を望めません。ターンキーのAIソリューションは存在しません。なぜなら、AIシステムとは、AIのモデルと企業が保有するデータの組み合わせだからです。自社のデータは、あくまで自社のものであり、システムはオーダーメイドになります。\n\n Dell AI Factoryを構築した背景は、スタックの一部を標準化することで、顧客がAIシステムを構築する作業を簡素化できると考えたからです。例えば、コンピュート、ストレージ、ネットワークをどのように構築して統合し、電力や冷却をどうするのかといったベースを、われわれは助けることができます。つまり、AI Factoryはソリューションを丸ごと導入するのではなく、望んでいる成果に合わせて組み合わせるものと言えます。\n\n このようにわれわれは、50％なり70％なりを標準化して、組み立てることができますが、重要なことは、最終的に（データを保有する）顧客が完成させなければならない点です。\n\n 逆に言えば、顧客はAI Factoryを利用せず、製品をバラバラにそろえてAIシステムを構築することができます。しかし、AI Factoryを利用することで、短期間に導入できます。これはAI Factoryがもたらす最大の価値です。\n\n――2023年のイベントでDell AI Factory with NVIDIAの前身になる「Project Helix」を発表しました。この1年間にどのような進化や変化があり、Dell AI Factory with NVIDIAとDell AI Factoryになったのでしょうか。\n\n Project Helixの背景には、顧客にとって（AIに必要な）全てのパーツを組み合わせることが大変な作業になるという仮説がありました。NVIDIAには先行したソフトウェア技術、ハードウェア技術があり、提携してスタックを構築しようと考えました。\n\n 当時は、既製の言語モデルを再学習したり調整したりしたチャットボットぐらいしか、ユースケースを想定していませんでした。ちょうどProject Helixを発表する頃に、RAG（Retrieval Augmented Generation：拡張検索生成）が登場し、その後も次々と新しい技術が出てきています。\n\n この1年で学んだことをまとめると、まず自分自身のモデルを訓練する必要はなく、RAGを使えば、既製のモデルに自社のデータを加えることができます。また、GPUのロードマップが加速しており、以前はNVIDIAの「H100」がほぼ独占していましたが、AMDの「MI300X」やIntelの「Gaudi 3」、NVIDIAでも「H200」「Grace Hopper」などが発表されました。そこで、われわれのシステムも多様なアクセラレーターに対応するよう変更しました。AI Factoryは、アクセラレーターレベルでオープンになっています。\nネットワークでは、Infinibandのみを考えていましたが、Ethernetも強力であることが分かりました。ここでも顧客に選択肢を提供します。\n\n Project Helixの思想そのものは変わっていませんが、ほぼ全てのレイヤーで多様化し、顧客は、自社に最適なものを選択できるようになりました。Dellはオープン性を信じており、AI Factoryでもそれを実践します。\n\n――AIがオンプレミスの分野に与える影響をどのように見ていますか。\n\n AIのインフラは、これまでのインフラとは全く異なります。既存の環境でもAIを少しできるかもしれませんが、AIシステムをしっかり動かしていくのであれば、データセンターを再設計する必要があります。\n\n この10年ほど顧客と話をしていて、新しいデータセンターを構築するという話は出てきませんでした。誰も関心を持っていなかったですし、その必要もありませんでした。既存のデータセンターがあり、新たにキャパシティーが必要なら、コロケーションを利用したりパブリッククラウドを利用すればいい、というのが去年までの話です。\n\n しかしAIでは、インフラを保有する必要があります。パブリッククラウドでAIをするには高価であり、リスクも伴います。\n\n――CIOやCTOなどは、そのことをどのぐらい理解しているのでしょうか。\n\n 私見ですが、あまり理解は進んでいないでしょう。動きの速い分野なので当然です。\n\n AIのインパクトに近いものにインターネットがありますが、インターネットの普及には20年以上を要しました。生成AIは、2022年11月の「ChatGPT」の公開から数カ月で実に数億人がアクセスしたと言われています。\n\n われわれも迅速に動かなければなりません。Dellは、1年前とは全く異なる企業になりました。顧客がAIを活用するために、まずわれわれが変わらなければならないからです。\n\n Dellは、リファレンスアーキテクチャーを多数提供しており、顧客も迅速に学んでいます。現在、AIプロジェクトがないという企業であっても、データサイエンスチームやデータ担当者はいます。AIは新しいかもしれませんが、データはこの10年、ずっとその重要性が言われてきていますから、全くゼロからのスタートということではありません。\n\n なお、2023年に日本を訪問した際、複数の大手企業の最高デジタル責任者にお会いしました。まだ運用には入っていないものの、どの企業にもAIプロジェクトがありました。\n\n――クラウドのハイパースケーラーが「AIエージェント」として、簡単にAIを組み込んだアプリやサービスを構築できるサービスを用意する動きがあります。AI Factoryの差別化は何でしょうか。\n\n ハイパースケーラーでAIエージェントを作成すると、そのハイパースケーラーのクラウドインフラ上で実行する必要があります。AI Factoryでは、自分たちのところにデータを置くことができます。\n\n われわれの顧客には、Google Cloudの「TensorFlow」を使ってモデルとアーキテクチャーを開発し、オンプレミスで動かすケースが多いですね。これは、TensorFlowがオープンだからであり、素晴らしいことだと思います。\n\n Dellは、マルチクラウドが今後の姿だと考えており、ハイパースケーラーとも良好な関係を構築しています。ハイパースケーラーの環境は、大規模なトレーニングには適しているでしょう。しかし、AIアプリケーションの実行やデータの保存場所としては、適していないのです。\n\n――AIの時代、進化がさらに加速しています。CIOとしての優先事項を教えてください。\n\n 実は、5年前に「MIPS」や「IOPS」で測定される世界のITキャパシティーのほとんどが、従来のアプリケーションやユーザーではなく、AIに使われる時代が来るという予想を出しました。それに向けて「AIファースト」のアーキテクチャーが必要になるという予想です。\n\n その予想の下で、2023年の今ごろまでは、戦略を立ててAIの時代にDellがどのようなポジションで関わっていくのかを考えていました。その通りになりましたし、Dellとして準備を進め5年が経過しました。そこで、2024年は優先順位が変わったのです。\n\n 現在はCTOがやるべきこととして、戦略のリスク軽減に集中しています。AIの世界には不確実性があり、全てが明確ではありせん。「AI PC」のソフトウェアエコシステムも明確ではなく、そこを解明していきます。先ほど「エージェント」という言葉がありましたが、「エージェント」が何を指すのでしょうか。まだ、定義がしっかり定まっていません。\n\n このようなことから、継続して戦略の策定を手伝いますが、フォーカスをリスクの回避に移しています。また、急に新しいものが登場して驚くことがないよう、量子やデジタルツイン、分散型台帳アーキテクチャなどの新しい技術にも時間を費やしています。\n\n（取材協力：デル・テクノロジーズ）,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219459-zdnet-000-2-view.jpg?exp=10800'],['https://news.yahoo.co.jp/articles/346a1becbb786ded8461dd4f3849d1cbe3016a96/images/000']
われわれのゴールは「より良いネットワークを作る」ことではない--Extreme Networks（ZDNET Japan）,https://news.yahoo.co.jp/articles/d462741ceff1f0e267f0adabc6b1cad55f5fcafc,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219590-zdnet-000-1-view.jpg?exp=10800,2024-06-04T07:00:00+09:00,2024-06-04T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,4809,\nわれわれのゴールは「より良いネットワークを作る」ことではない--Extreme Networksの画像\n2024年3月に最高経営責任者（CEO）による事業戦略説明会を開催したExtreme Networksだが、4月には技術開発面をリードするChief Technology ＆ Product Officer and General Manager of SubscriptionのNabil Bukhari氏が来日し、インタビューに応じた。Bukhari氏は同社の技術開発戦略について、最近のAI技術の急速な進化やネットワーク業界が直面する変化などを踏まえて明快に語った。\n\n Bukhari氏はまず、同社のパーパス（社会的意義）について「顧客が物事を行うためのより良い方法を見つけ出す手助けをする」と説明し、「それによって社会全体により良いインパクト／変化を与えることを目指している」と語った。同氏はこうしたパーパスを掲げる背景には、「われわれはテクノロジー企業ではあるが、人間性にフォーカスしている企業でもある」という考えがあるとしている。\n\n 次にBukhar氏は、現在の企業が直面する課題についての同社の認識を語った。同氏は「全てのものをつなぐ」「リソースの制約」「優れたユーザー体験」の3点を課題として挙げ、Extreme Networksはこれらの解決に取り組むとしている。\n\n まず大前提として、「今や世界の全ての企業は『接続された企業（Connected Business）』となっている」という認識がある。ネットワーク接続は今や企業活動や人々の生活において当たり前のものとなっており、だからこそ企業はより高度なネットワーク接続を実現する必要がある。\n\n Bukhar氏は「人もアプリケーションもデバイスもIoTも、全てを相互接続する究極的な接続性の実現は、世界のあらゆる企業が最優先で取り組む直近のゴールとなっている」と指摘し、「企業が使えるリソースは同じではない。資金や時間、技術力や人材といった企業が有するリソースの範囲内でテクノロジーを導入しなくてはいけない」とした。\n\n 同氏は「われわれは、あらゆるものを相互接続するテクノロジーを開発し、それがユーザーのリソースの範囲内で利用可能にすることで、考え得る限り最高の体験を提供する。われわれの製品ポートフォリオはこうしたビジョンに基づいて構築されているのだ」と語った。\n\n 続いてBukhar氏は、現状の製品ポートフォリオについて簡単に紹介した。まず、広範なネットワーキング製品群については「Wi-Fi製品群、有線ネットワーク製品群、SD-WANソリューションなど、あらゆる種類のソリューションを網羅しており、テレコム企業の大規模ネットワークでも、データセンターやキャンパスネットワーク、支店や遠隔拠点のネットワークなど、あらゆるニーズに対応できる」という。加えて、「単に接続するだけでは充分とはいえず、リソース効率にも配慮する必要がある。そのため、『Extreme Cloud』ポートフォリオも追加している」という。\n\n これらのクラウドアプリケーション群を活用することで、ユーザー企業は運用する全ポートフォリオを一元管理・分析し、トラブルシューティングを行える。また、このアプリケーションはパブリッククラウドだけでなく、プライベートクラウドやオンプレミスのデータセンターなど、さまざまな環境で運用可能だとしている。\n\n 「こうした取り組みを行っているのはネットワークベンダーの中でもわれわれだけだと自負しているが、ユーザーがどのような環境で運用するとしても、同じアプリケーションを同じライセンス条件のもと同じ体験を提供できる。これは、競合他社に比べて大きな優位点だ」とBukhar氏は話す。この背後にある考え方として、同氏は「複雑性はリスクをもたらす。むしろ、複雑性はリスクそのものだと言っても過言ではない」と指摘し、複雑性を排除して製品ポートフォリオを構築しているとした。\n\n 最高技術責任者（CTO）としての立場からの企業全体の方向性を聞いたのに続き、以後は個々の技術的なテーマについてBukhar氏の考えを聞いた。\n--クラウドアプリケーションをオンプレミスで運用する場合、どのような実行環境が必要なのか。ユーザーの環境にクラウドのソフトウェアスタックが一通りそろっている必要があるのか、あるいは仮想アプライアンスのような形で利用可能なのか。\n\n まず、仮想アプライアンスは古いテクノロジーであり、当社ではもう使っていない。われわれのクラウドアプリケーションはクラウドネイティブで、「Google Cloud Platform」「Amazon Web Services」「Microsoft Azure」といった環境で動作しているが、動作環境を構築したのは当社であり、同じ環境をユーザーにも提供できる。イメージとしては「AWS Outposts」のようなものだと考えてもらえればよいが、数台のサーバー群に必要なインフラ環境を丸ごと構築してユーザーが希望する環境に設置できる。\n\n われわれ自身がクラウドスタックを丸ごと構築したからできることであり、ネットワークベンダーで同じことをしている競合はないはずだ。現在はオーダーを受けてから1時間以内にクラウド上でもオンプレミス向けでも環境を用意できる体制となっている。日本でも利用可能であり、既に国内の大手の医療機関で導入された実績がある。\n\n 日本では大地震などの自然災害が発生するリスクがあることから、万一の際にネットワーク接続がダウンして病院の機能に影響が及ぶことを避けるため、必要な全ての機能をオンプレミスでそろえて外部接続に依存せずに運用を継続できるようにしたいという意図がある。\n\n--AIについてはどのような取り組みを行っているのか。\n\n 生成AIをプラットフォームに組み込むという点に関しては、当社ももちろん実行している。しかし、多くの企業がAIOps（AIによる運用支援）に注力しているのに対し、われわれはAIOpsに限定せず、より広範な活用を考える必要があると認識している。AIユースケースには大きく3つのフェーズがあると私は考えている。最初のフェーズは「Augmentation」（増強／拡張）だ。例えば、人間が行う業務をAIがより迅速に／高品質に行えるよう手助けしてくれることがある。\n\n 現在は第2フェーズに入っており、従来は人間が行っていた幾つかの業務をAIが完遂（Replacement）できるようになっている。そして最後の段階は「Creation」（創出）だ。この段階の重要性について考えている人はまだ少ないようだが、AIがこれまで存在しなかった新しいものを生み出していく段階だ。\n\n 多くの企業が現在取り組んでいるAIOpsは、Augmentationのユースケースだ。ネットワーク管理を自動化したり、異常検知の精度を高めたり、トラブルシューティングを効率化したりできるのがAugmentationフェーズのユースケースである。コストや時間を減らせるが、劇的な削減にはつながらないので、より大幅な削減を実現したいならReplacementのフェーズに期待することになるだろう。Replacementのフェーズではリスクの削減も可能になる。Creationのフェーズでは、利益の創出が期待できる。\n\n 当社はAIプラットフォームをわれわれのパートナー企業に提供し、その上に新たなAIサービスを構築することで新たな収益源を作り出してほしいと考えている。われわれは、AIOpsよりも広範な領域を見据えている。\n\n さらに言えばAIOpsは差別化要素にはなり得ないので、AIOpsに注力するのではなく完全なAIプラットフォームを構築しているのだ。典型的なAIOpsの取り組みでは、提供企業は外部の大規模言語モデル（LLM）やビッグモデルにさほど多くない量のデータを渡して出力を得る単純なAIアプリケーションの形を採っているが、当社のAIプラットフォームは全てのデバイスからのリアルタイムデータやテレメトリーデータを収集しており、この膨大なデータをさまざまなAIモデルに渡して活用できる。\n\n AIでは、データセットが大きくなればなるほど、得られる価値もさらに大きくなるため、われわれのAIプラットフォームは単純なAIOpsユースケースを上回るはずだ。\n--ネットワーキング企業各社は有線ネットワークからクラウド型Wi-Fiを経て、次はより高度なデータ活用やオブザーバビリティの提供などの分野で競争するようになってきたと見ている。競合がSplunkを買収するというニュースもあったが、こうした市場の動きに対してExtreme Networksはどのような技術戦略をもって対抗していくのか。\n\n Splunkの人々については私もよく知っていて敬意を持っているが、それでもあえて言わせてもらうなら、Splunkは今やちょっと古い技術だろう。アラートや通知を多量に収集してデータセンターもしくはクラウドで稼働する巨大なアプリケーションに送信して分析する、というやり方はこの先の未来のシステムの形とは異なるはずだ。未来は「データのある所にアプリケーションを持ち出す」という形になると考えている。\n\n 多くのデータはエッジで生成される。例えば、病院や工場、油田やガス田、空港などがある。そして新たなテクノロジー群がこうした環境にAIモデルを持ち込んで、エッジ環境でローカルにAI演算を行うようになるだろう。これをエッジAIと呼んでいるが、未来はエッジAIにあると考えている。当社が構築するAIプラットフォームは、まさにこのエッジAIを実現することになる。このアプローチにより、われわれは既存の巨大アプリケーションに比べてより迅速で反応の速いAIアプリケーションを構築できる。\n\n AIの活用例として自動運転車などを考えてみると、クラウドやデータセンターにデータを送信して結果が返ってくるのを待つ形では実現できないのは明らかだ。こうした場合、「インテリジェンス」はエッジ側に存在していなくてはならない。われわれはここに投資しており、われわれのテクノロジーはエッジでのAI活用／意志決定を可能にする。\n\n--ここまでの話から、Extreme Networksが目指していることは従来ネットワークベンダーの事業領域と考えられていた範囲を超えたより広範なもののようだと感じる。「顧客が物事を行うためのより良い方法を見つけ出す手助けをする」と言っていたが、このより良い方法は一般的なネットワークベンダーの事業領域に限定されるものではないと考えてよいか。\n\n その通りだ。現在、あらゆる企業は接続されている。ネットワークは当社のあらゆる活動の中核に位置している。企業、社会、個人生活、携帯電話／スマートフォン、SNS、仕事、電子メール、オンラインショッピング――何もかもである。\n\n ネットワーキングを進化させ、ネットワーキングの領域でイノベーションを起こすことでコネクティビティーが進化し、その結果社会全体のあらゆる領域が革新されるだろう。われわれの目指すゴールは単に『より良いネットワークを作る』ことではなく、「ユーザーがやりたいことが何であれ、それを実現するためのより良い方法を実現する」ことであり、当社のミッションは単なるネットワークにとどまらない広範なものなのだ。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240604-35219590-zdnet-000-1-view.jpg?exp=10800'],['https://news.yahoo.co.jp/articles/d462741ceff1f0e267f0adabc6b1cad55f5fcafc/images/000']
