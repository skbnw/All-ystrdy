headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
池上彰「AI時代に必要な真実を見抜く“読解力”」誤った情報に惑わされないために（Yahoo!ニュース オリジナル Voice）,https://news.yahoo.co.jp/articles/776670fce7eec325c3d53dd5352b6f17ed6d6e75,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240202-00010000-ynewstalk-000-2-thumb.jpg?exp=10800,2024-02-02T10:00:01+09:00,2024-02-02T11:05:50+09:00,Yahoo!ニュース オリジナル Voice,ynewstalk,Yahoo!ニュース オリジナル Voice,4253,\nテレビや新聞、雑誌など各メディアで活躍し、さまざまな大学で教鞭も執る、フリージャーナリストの池上彰さん。取材活動の中や教育現場でChatGPTをはじめとするAIの進歩や可能性を感じることも多いという。「すでにAIは、われわれの身近なところで活躍している」と語る池上さんに、AIを活用する際に気を付けるべきこと、AIから得られる学びについて、話を聞いた。（聞き手：荻上チキ／TBSラジオ／Yahoo!ニュース Voice）\nChatGPTにレポートを書かせる学生も。池上彰が感じる身近なAIの進歩\nAIとの付き合い方について語る池上彰さん\n――池上さんは、生成AIのChatGPTをはじめとした、AIの飛躍的な進歩についてはどう見ていますか。 \n\n池上彰： ChatGPTのように文字ベースで誰でも簡単に使えるAIの登場によって、AIをより身近に感じられるようになりましたよね。特に、テキストや画像などのコンテンツを作り出すことができる生成AIはすでにさまざまな場面で活躍しています。テクノロジーはどんどん進歩していきますね。 \n\n先日ChatGPTに「AIと私たちはどう付き合ったらいいんでしょうか？」って聞いてみたんですよ。そうしたら「AIに頼りすぎないことです」っていう返事でした。おっしゃる通りです、と思いましたね。私たち人間が自らそういうことを言わなければいけないのに、AIにそう言われてしまうのは、なんだか忸怩（じくじ）たるものがありますね。 \n\n――池上さんは教員として大学の教壇に立つ機会もあるそうですが、教育現場でのAIの使われ方について思うことはありますか。 \n\n池上彰： 私の場合は、試験のときには教室でその場で手書きしてもらっていますが、最近は学生がChatGPTにレポートを書かせる、といったケースもよく聞くようになりました。 \n\n 一方で、東京工業大学の同僚の先生で、ChatGPTを授業に取り入れている方もいます。たとえば、ChatGPTであるひとつの事柄を調べる際に、学生たちに「それぞれ別の質問を考えて、ChatGPTに聞いてみましょう」と指示するんです。そして、出てきた答えを照らし合わせて、質問の仕方によってこんなに回答が違ってくる、ということを学ぶんだそうです。そういう形でChatGPTを使うことにまず慣れさせるという取り組みをしている人もいます。\n文字起こしはAIでいい。記者にしかできない仕事に注力せよ\n――ジャーナリストの立場から、池上さんはどのようにAIを活用できると考えていますか。 \n\n池上彰： 総理大臣や官房長官の記者会見をテレビで見ていて、記者たちがみんな手元のパソコンで発言内容を一字一句打ち込んでいるのに本当にイライラするんですよね。「おいおい、そんなのはAIに任せりゃいいじゃないか」、っていつも思うんです。最近のAIは精度も高くて、見事に文字起こしをしてくれますからね。 \n\n 現場で文字起こしをするのではなく、会見の時に総理大臣や官房長官がどんな表情をしていたのかをもっと注視すべきです。「あの時こういう顔をしたのはなぜだろうか」「あとでまた本人に直接聞いてみよう」とか。そこで感覚をつかんで、原稿を書いていく。それをやるのが現場にいる記者の仕事だと思うんです。 \n\n ――取材でAIを活用する際はどんなことに注意すべきだと思いますか。 \n\n 池上彰： われわれジャーナリストが取材記事を書くときには、複数の情報源から確認を取るのが鉄則です。そのときに気を付けなければいけないのは、情報の出どころをしっかりと確認できているか、ということ。情報源が複数あるように見えても、各情報源をさらにたどっていくと、大元の情報源が1つしかないケースはよくあります。それに気づかず、複数の情報源から確認したからと勘違いして記事を書いてしまうと、誤った情報を世の中に伝えてしまうことになります。 \n\n ChatGPTを使う際にも、同じことに気を付けなければいけません。たとえば、ChatGPTに質問して出てきた回答を、さらにインターネットで検索したとします。そこでChatGPTの回答と同じ内容が出てくると、これは正しい情報だと信じてしまう可能性があるんですよね。でも、ChatGPTもネット上の同じページを参照して、答えているかもしれないわけです。 \n\nさらにいうと、生成AIを使う際には「もっともらしい嘘（ハルシネーション）」が生成されることがあるのも覚えておかなければなりません。以前、「池上彰ってどんな人物？」とChatGPTに聞いたら、私はTBSに入社して、そのあと日経新聞にも入社したことになっていたんですよ（※実際は元NHK記者）。聞くたびに、出身地や出身大学が違ってたり、年齢が違っていたり。でも、まるで事実かのような書きぶりなので、知らない人が見たら信じてしまうかもしれない。 \n\n人間でもそういう人がいますよね。自信たっぷりに知ったかぶりするけど、よくよく聞いてみると間違ったことを言っているような人。これは気を付けないといけない。いまはまだChatGPTも発展途上だからこういうことが起きてしまうんだとは思いますが、AIが言うことがすべて正しいわけではないというのは、頭に留めておいたほうがいいですね。\nAI時代だからこそ必要な“読解力”\n――AIによるコンテンツも登場しているいまの時代、さまざまな情報を浴び続けるユーザーにとっては、どんな注意が必要でしょうか。 \n\n池上彰： どれだけ常識を持っているかということはありますよね。例えば政治家のフェイク動画で、なにかを言ってるのを見て、「この人の日頃の言動でこんなことはないだろう」ってこれを判断できる。それぐらいの常識は持っておいてほしいなっていう風に思います。 \n\n「あ、ここは煽ってるな」っていうことが分かるような、まさにその読解力が問われてくるのかなって思います。伝統的な、経験や訓練を積んだジャーナリストが書く原稿って、見事な文章やハッとするようなものはあるんだけど、人の心をうんと煽るような、「バズらせよう」ということは絶対しないはずなんですよね。だから、「あ、ここバズらせようとしてるな」「過激なことあえて言ってるな」っていうコンテンツを目にしたら「ちょっと待てよ」と。 \n\n「これはほんとなんだろうか」、あるいは「意図的に金儲けのためにやっているのかな」っていうことを読み解く、判断するという、そういう新たないまの時代だからこその読解力というのが、問われるようになったのかなと思いますね。\nAIに「誰かを傷つけない会話法」を学ぶこともできる\n――ChatGPTのように、AIが世の中に浸透していく中で、印象に残っていることはありますか。 \n\n 池上彰： ある経済雑誌の編集後記に、女性の編集者が書いていた文章が印象的でした。彼女は夫と共働きで、お子さんが入院してしまったそうなんです。本当に心配で、でも気軽に相談できる相手もいなかったから、ChatGPTに「どうしたらいいでしょうか」って聞いてみたんだそうですね。そうしたら「それは心配ですね」って返ってきたらしいんですよ。彼女の文章は「うちの旦那はこんなに優しい言葉をかけてくれない」というオチでしたね。 \n\n ChatGPTは絶対ヘイトにしないんですよ。以前知り合いの編集者が、「阪神タイガースファンはどのように見られていますか」ってChatGPTに質問したそうなんです。そうしたら、「私はステレオタイプな答え方はいたしません。ただし、熱心な野球ファンであることは知られています」って答えが返ってきたそうです。それって、阪神タイガースファンはこうだよね、という答えを相手は期待しているんだろうと分かったうえで、配慮した答えを出してきたのかなって思いましたけどね。 \n\n そういう風に、誰かを傷つけない会話法をAIから学ぶこともできるんです。こういったAI活用のいろいろな道を探っていきたいですね。\n\n ――池上さんは今後AIをどのように活用していけば良いと考えていますか。 \n\n 池上彰： ChatGPTはある時点までの学習データを元に回答を生成しているので、直近の出来事までは調べられません。そういう限界があることを知った上で使うべきですね。 \n\n そして、AIは過去にあった出来事を調べるには非常に有効なツールですが、その情報を人間がどう活かしていくかがもっとも重要だと思います。過去のことを調べる能力は、人間よりもAIのほうがはるかに高い。でも、AIは未来のことは語れないわけですよね。それは結局、人間がやるしかないんだろうなと思います。 \n\n AIやChatGPTのことはよく分からないと思っている人でも、まず話しかけてみる。答えが返ってきたらそのまま信じるのではなくて、その答えについてさらに質問を重ねる、ということをやってみるんです。何か1つ聞いて答えが出てきたら、この部分の典拠（てんきょ） は何ですか、と問いただす。このやりとりを続けていくと、そのうち「すみません、分かりません」とか「間違えました」ってChatGPTが謝るんですよ。出された答えを鵜呑みにするんじゃなくて、この過程を経ることが大事なのかなと。 \n\n やりとりを続けているうちに、本当に人間と会話をしているような気分にもなってきますが、これがまた危険なんです。相手がAIなのか人間なのか、そこを見抜いていく力も養わないといけない。そのためにも、まずはちょっと触れてみるのがいいと思います。\n\n----- \n池上彰 \n1950年、長野県生まれ。ジャーナリスト。慶應義塾大学卒業後、1973年、NHKに入局。1989～1994年まで「首都圏ニュース」キャスター、1994～2005年まで「週刊こどもニュース」キャスターを務める。2005年にフリージャーナリストとして活動開始。東京工業大学、名城大学など複数の大学で教鞭を執るかたわら、執筆活動やテレビ出演など多方面で活躍する。 \n\n文：中村英里 \n\n（この動画記事は、TBSラジオ「荻上チキ・Session」とYahoo! JAPANが共同で制作しました）,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240202-00010000-ynewstalk-001-2-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/776670fce7eec325c3d53dd5352b6f17ed6d6e75/images/000']
