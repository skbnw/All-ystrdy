headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
不適切投稿を世界で4万人が監視　TikTokの「コンテンツモデレーター」の任務とは？（ITmedia マーケティング）,https://news.yahoo.co.jp/articles/3d450fdd7772223ea2cf148cdd935ef2c6680752,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240904-00000004-biz_it_mk-000-1-view.jpg?exp=10800,2024-09-04T07:00:12+09:00,2024-09-04T07:00:12+09:00,ITmedia マーケティング,biz_it_mk,ITmedia マーケティング,4262,\nTikTokはユーザーに害をもたらす恐れのあるコンテンツを弾く「コンテンツモデレーション」をどのように進めているのか\n世界150の国と地域で月間10億人以上のユーザーを抱えるTikTok。紹介された商品が拡散して爆発的に売れる「TikTok売れ」といった現象を巻き起こすなど、社会に大きなインパクトを与えるSNSプラットフォームだ。\n【画像】不適切投稿を監視する「コンテンツモデレーター」、仕事内容は？\n影響力が増すほどに、外部からは厳しい視線が注がれる。TikTokを運営する中国企業ByteDanceに対し、米国で事業の売却か同国でのTikTok利用禁止を迫る法律が成立したのは記憶に新しい。これは安全保障上のリスクなどが主な理由とされるが、フェイクニュースや人を傷つける悪意あるコンテンツのまん延など、影響力の強いSNSそのものへの不安も日に日に高まっている。\n\n 懸念を払拭するため、TikTokはコンテンツの健全性維持の努力とモデレーションの透明性アピールに専念している。2024年8月には、TikTokのシンガポール本社に各国の記者を招待し、TikTokの安全性を高める取り組みを紹介するイベントを開催した。\n\n ユーザーに害をもたらす恐れのあるコンテンツを事前に察知し、削除する「コンテンツモデレーション」（投稿の適正管理）はどのようにして行われているのか。ユーザーの好みを反映した投稿を提案するあまり、似たような動画ばかり表示される「フィルターバブル」を回避するために、どのような対策を取っているのか。同社の取り組みを報告する。\n\n シンガポールのビジネスの中心地、ラッフルズ・プレイス。幾重にも建ち並ぶ高層ビルの中に、ByteDanceのシンガポールオフィスはある。日本を含むアジアの各地域を束ねる主要拠点の一つだ。今回、同社はこのオフィスに、日本、シンガポール、韓国、マレーシア、ベトナム、タイといったアジア各国の記者を招待した。\n\n マーライオンをあしらったネオンライトの壁アートが目を引く。休憩スペースでは卓球に興じる従業員たちの姿も。勢いに乗る企業の、今風のクールなオフィスという印象だ。\nコンテンツモデレーターに課された重要な任務とは\n記者団が案内されたのは「透明性説明責任情報公開センター」（Transparency and Accountability Center 、以下TAC）。\n\n TACは、ユーザーの安全を守るためにTikTokが進めるコンテンツモデレーションの取り組みなどを体験的に理解できる施設で、各国のメディア関係者のほか、TikTokに出稿する広告主、政府関係者らが視察に訪れるという。同様の施設は米ロサンゼルスとワシントンDC、アイルランドの首都ダブリンにも設置。シンガポールのTACは2023年に完成した。\n\n 「われわれは世界中で1日あたり、約200万件の不適切なコンテンツを検知し、削除しています」（担当者）\n\n コンテンツモデレーションは、ユーザーに害をもたらす恐れのある投稿を、拡散される前に見つけ出して削除する作業だ。多くのユーザーを抱えるSNSプラットフォーマーにとって、大きな責任を伴う業務だ。\n\n TikTokには、こうした業務を担うコンテンツモデレーター（プラットフォームの安心安全に関わるプロフェッショナル）が世界中に4万人以上存在する。独自に策定したコミュニティガイドラインに沿い、犯罪行為やヘイトスピーチ、いじめ、ジェンダーに基づく暴力などポリシーに違反する投稿を削除していく。24時間365日、PCとにらめっこするハードな作業だ。\n\n 当然ながら、有人のコンテンツモデレートだけで対処するわけではない。人がチェックする前に、AIによるシステムが最初の監視を担う。投稿の適切性が疑わしければ、有人のチェックに回される。機械と人間の2段階で監視を働かせているわけだ。\n\n 例えば、刃物などの危険な道具を手にしている人物が投稿された動画に写っていた場合、機械学習を済ませたシステムが危険性の有無を判断する。\n\n 刃物が写る動画全てが削除対象となるわけではない。はさみで紙を切っているような動画であれば、危険性があるとは判断されない。一方で、はさみを人に振りかざしているようなシーンが写る動画であれば、危険性があると判断され弾かれる。投稿された情報の文脈を読み取りながら、弾くか否かが判断される。\n\n TikTokによると、2024年1～3月の期間に削除された動画の総数は約1億6700万件に上る。これは、公開された動画投稿数の0.9%に相当するという。\n\n また1日あたり削除される約200万件の投稿のうち、77%は人間のモデレーターがチェックするまでもなく、システムによって自動的に弾かれる。「これこそわれわれが取り組む作業スピードの速さを表しています」と担当者は胸を張る。\nモデレーターの心的負荷にどう対応？\nTACには、コンテンツモデレーターを体験できるスペースがある。記者も実際に体験してみた。\n\n 専用のPC画面に、自転車に乗った男が店頭から商品らしきものを奪って逃げ去るような光景が映し出されている。この投稿は、TikTokのコミュニティガイドラインに反しているのか。反しているとすればどのポリシーに反しているのか――。画面上に提示された3つのポリシーのうち、当てはまりそうな「犯罪行為」にチェックを付けて判定ボタンを押す。次のページで、ポリシーに反するポイントが詳しく解説された。\n\n とはいえ、コンテンツモデレーターが遭遇する投稿は、このように判断しやすいものばかりではない。中には白黒がはっきりしないものもある。モデレーターが作業する画面上には、動画を繰り返し確認できるように一時停止・再生のキーフレームが備わるほか、投稿者の情報、フォロワー数、高評価数、シェア数などのデータも併せて表示される。モデレーターはこれらの情報を総合的に確認しながら、投稿が適切かどうかを判断していく。\n\n さらに、地域によって文化的・法的背景もさまざまに異なるため、ある地域でNGとされた投稿が、別の地域では問題ないと判断されるケースもある。世界に4万人存在するTikTokのコンテンツモデレーターは、70以上の言語をカバーし、それぞれの地域の文化的、法的な背景に精通した担当者が、投稿が適切かどうか見極めていく。\n\n 「言葉は常に進化し、AIだけでは不適切だと捉えきれない投稿も出てきます。だからこそわれわれは有人のモデレーターを必要とするのです」（担当者）\n\n 不適切な投稿のチェックは、心理的な負荷が伴う作業でもある。担当者は「コンテンツモデレーターがしっかりと休息を確保するためのウェルビーイングツールを備え、カウンセラーが現場でサポートできる体制を取っている」と説明。また、コンテンツモデレーターが、毎日、毎時間、同じ種類のコンテンツにさらされないような仕組みを構築していると話した。\n「フィルターバブル」どう避ける？\nTikTokに限らず、さまざまなSNSに共通するのが、画面をスクロールすれば、ユーザーの好みを反映した動画が次々と現れる仕組みだ。ユーザーが直接、好みを伝えたわけではないのに、興味のある投稿が提示される。自分を知られ過ぎていると感じ、不安になるユーザーもいるかもしれない。\n\n TikTokによると、ユーザーの好みを反映した動画は、多くの要因に基づいて決められる。例えば、ユーザーが動画に押した「いいね」や「シェア」、アカウントのフォロー、コメント投稿、作成したコンテンツなど。さらには動画のキャプション、サウンド、ハッシュタグなどといった情報も加味される。こうしてユーザーごとに最適化されたフィードは、一つとして同じものは存在しないという。\n\n 一方で、好みが最適化されたフィードには落とし穴も存在する。似たような情報や視点の投稿ばかりに囲まれてしまう「フィルターバブル」の問題だ。フィットネスやダイエットに関心のあるユーザーが、その投稿ばかり見続ければ、自身の体型を気にし、過度なダイエットに走る恐れもある。これはユーザーにとって健康的とはいえない。\n\n 「こうした状態を避けるために、私たちが取る対策は非常にシンプルです。いくつかの動画を削除し、異なるものに置き換えることで、隣接する複数の動画の類似度スコアを60％未満に抑えるのです」（担当者）\n\n そのほか、TikTokではユーザーが見たくない動画があれば、長押しして「興味がない」をタップできる機能や、最適化されたおすすめフィードをリセットできる選択肢も用意している。\n未成年ユーザーのプライバシー保護\n最後に担当者が「われわれが最も重視する優先事項」だと強調したのは、若者のプライバシー保護だ。TikTokアカウントを作成できるのは13歳以上という年齢制限を設け、ダイレクトメッセージを利用できるのは16歳以上に限定している。\n\n これらのルールに違反した場合、アカウントの停止など強制的な措置を講じると担当者は説明した。\n\n この説明があった翌日の8月2日、TikTokが13歳未満のユーザーの個人データを違法に取得していたとして、米司法省がByteDanceを「児童オンラインプライバシー保護法（COPPA）」違反で提訴したというニュースが報じられた。\n\n 司法省の発表によれば、TikTokは2019年以降、親の同意なしに、13歳未満のユーザーがTikTokアカウントを作成し、他者とショート動画やメッセージを作成、共有することを故意に許可していたなどとしている。\n\n 米メディアによると、TikTok側は「これらの申し立ての多くは、事実に反する、あるいはすでに対処済みの過去の出来事や慣行に関するものであり、当社は同意できない」と反論している。\n\n TikTokの影響拡大を阻止する包囲網は着実に拡大しており、TikTok側には引き続き、困難な局面が続く。それでも今は安全性と透明性への取り組みを粛々と続けることで、個々のユーザーレベルでの不安を少しでも取り除こうとしているようだ。\nITmedia マーケティング,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240904-00000004-biz_it_mk-000-1-view.jpg?exp=10800'],"['https://news.yahoo.co.jp/articles/3d450fdd7772223ea2cf148cdd935ef2c6680752/images/000', 'https://image.itmedia.co.jp/l/im/mm/articles/2408/13/l_th_tiktok03.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240904-004&utm_term=biz_it_mk-sci&utm_content=img']"
