headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「生成AI」はセキュリティをどう脅かすのか？　大手5社の脅威予測から探る（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/534949a4e891df978cb20bd8730aacda8b0901c0,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240115-00000070-zdn_ep-000-1-view.jpg?exp=10800,2024-01-15T15:03:00+09:00,2024-01-15T15:03:00+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,4579,\n（写真：ITmedia エンタープライズ）\n生成AI（人工知能）は2023年に続いて2024年も話題の中心になりそうだ。ただ、メリットだけでなくリスクもしっかりと見据え、対処する必要がある。そうした観点から、セキュリティベンダーは生成AIのリスクをどう見ているのか。大手各社が発表した2024年の脅威予測から、生成AIをはじめとしたAIに関する内容を取り上げて探っていく。\nAIの脅威について注視せよ（出典：Trellixの発表資料）\n懸念される「ディープフェイク」の拡大\nまず、トレンドマイクロは「生成AIの悪用によるインフルエンスオペレーションが拡大する」として、次のような見方を示している。\n\n 「AI分野でさまざまな進歩が見られる中、特に生成AIはなりすましや情報窃取において攻撃者の強力なツールにもなっている。ビジネスメール詐欺やスピアフィッシングなどのソーシャルエンジニアリング手法を用いて、デジタルと現実の境界をあいまいにさせる。ディープフェイクの手口としては、多くのAI駆動ツールが洗練され、リアルタイムで本物に酷似した音声や映像の偽装表現が可能になりつつある中、特に音声クローニングにおいて近い将来、詐欺での悪用が増えると予測している。そしてこの場合、AIにより相手の音声を模倣するには、特定の個人から多くの音声ソースを集める必要があるため、特定のターゲットに絞った脅威になってくるだろう」\n\n さらに同社は「AIブームはすでに政治にも影響を及ぼしている。ニュージーランドと米国でAI生成の画像が政治広告に使われていることが、それを証明している。特に米国や台湾では、2024年の国民選挙に向けて、AIが政治的な誤情報の増加に寄与すると予想されている。SNSなどを活用して世論を操作するインフルエンスオペレーションの拡大が懸念される。AI技術の利用が容易になる中、このように特定の標的を狙い、説得力のある詐欺の手口が2024年にはより一層拡大・活発化してくるだろう」とコメントしている。\n\n 2024年1月13日に実施された台湾総統選では、予測されていた通りディープフェイクが数多く出回った。世界の動向に大きく影響する2024年11月実施予定の米国大統領選も「ディープフェイク合戦」になるのではないかと危ぶまれている。生成AIがサイバーとリアルの世界を融合させた新たな脅威をもたらしつつある。\n\n これに対してVeeam Softwareは「AIが激変するのは2024年ではない」として、次のように見ている。\n\n 「ブロックチェーンやWeb3に関する話題は過去何年も見てきており、生成AIにも同じことがいえる。2023年はAIに関する多くの話題が飛び出したが、大規模言語モデル（LLM）は10年近く前から存在している。画期的なユースケースの登場や広い範囲での普及は、向こう10年程度はまだ見込めないだろう。一方で、生成AIはマーケティングなど、個人の生産性に最も大きな影響を与えるだろう。2024年は、社内プロセス向けのユースケースとお客さま向けのメリットといった外部プロセスのためのユースケースが主な焦点となると予想している。そしてもちろん、われわれはその違いを認識しながら生成AIを活用する必要がある」\n\n Veeam Softwareの予測は他社とは少しばかり異なっており、「ブームが過熱しすぎている。冷静になろう」と訴える意図とも受け取れる。ただし、生成AIについては2024年から具体的なユースケースが出てくるのに伴って、その中身の違いをしっかり捉える必要があると発信している。\n\n Trellixは「悪質なLLMが開発される」として、次のような見方を示している。\n\n 「近年のAIの進歩により、人間のようなテキストを生成できるLLMが登場している。LLMは積極的な応用に向けた技術的な可能性を示している一方で、そのデュアルユースな性質が悪用に対する脆弱（ぜいじゃく）性をもたらしている。特に、サイバー犯罪者が大規模攻撃にLLMを悪用する可能性は重大な懸念事項だ」\n\n 同社は「主要なLLMは、一貫したテキスト生成、複雑なクエリへの回答、問題解決、コーディングなど、多岐にわたる自然言語タスクにおいて類いまれな能力を発揮している。これらの進化したLLMの利用が容易になったことで、サイバー犯罪者にとって新しい時代の幕開けとなっている。以前のAIシステムと異なり、現代のLLMはハッカーにとって強力かつ費用効果の高いツールであり、広範囲の専門知識や多大な時間、リソースを要求しない。この利点はサイバー犯罪者にも明らかだ」としている。\n\n 生成AIはサイバー犯罪者にとって格好の武器になるとの警鐘だ。「LLMの悪用」を完全に食い止めることはできるのか。生成AI活用の根本的な問題だけに注視する必要がある。\n企業にとって深刻なAIのガバナンス欠如\nTrellixはもう一つ、「ソーシャルエンジニアリング詐欺のためのAI生成音声」について、次のように予測している。\n\n 「AIが生成した音声を使った詐欺の増加は、個人と組織に重大なリスクをもたらす懸念すべき傾向で、2024年も増加すると予想される。これらの詐欺にはソーシャルエンジニアリングの手口が使われることが多く、詐欺師は心理操作のテクニックを使って個人情報の開示や金融取引の実行など、個人に特定の行動をとらせる。AIが生成する音声はこの中で重要な役割を果たし、被害者に信頼と緊急性を植え付け、心理操作に対してより脆弱にさせる」\n\n 最近の技術革新により、AIが生成する音声の質は大幅に向上した。このことについて同社は「人間の話し方やニュアンスを忠実に模倣できるようになり、本物と偽物の声を区別することがますます難しくなっている。さらに、AI音声生成ツールの入手のしやすさと手頃な価格により、普及が進んでいる。技術的な専門知識を持たない個人でも、これらのツールを使って説得力のある人工音声を簡単に作成でき、詐欺師に力を与えている」と警鐘を鳴らす。\n\n また、拡張性ついても、「詐欺師はAIが生成した音声を活用して、詐欺行為を自動化し、拡大させることができる。パーソナライズされた音声メッセージや通話で、多数の潜在的な被害者を同時にターゲットにすることができ、そのリーチと効果を高めることができる。AIが生成した音声をリアルタイムで検出することは、特にこの技術に精通していない個人にとっては重要な課題だ。AI音声の信ぴょう性が増しているため、被害者が本物と詐欺のコミュニケーションを区別することが難しくなっている。さらに、このような詐欺は言語の壁に制限されないため、詐欺師はさまざまな地域や言語的背景を持つ被害者をターゲットにできる」と指摘する。\n\n 上記はソーシャルエンジニアリング詐欺の怖さをより具体的に示している。「詐欺」という言葉を強調しているのが印象的だ。\n\n 一方、CrowdStrikeは「見えないAIが組織に新たなリスクをもたらす」として、次のようにみている。同社の具体的な説明から核心部分を紹介する。\n\n 「2024年には脅威アクターの関心がAIシステムに向かうと予想している。組織が承認するAIの脆弱性や、従業員による未承認AIツールの使用によって組織内に“死角”が生まれることから、AIシステムが組織を狙う際の新たな脅威ベクトルとして浮上するだろう」\n\n 「2023年はAIの導入および活用が劇的に進んだ。その一方で、AI導入時におけるセキュリティチームの脅威モデルに対する理解度はいまだ初心者レベルだ。従業員が無断で持ち込む非承認AIツールの追跡も追い付いていない状況にある。こうした新しいテクノロジーは“死角”を産みやすく、脅威アクターに企業ネットワークへの侵入や機密データ窃取のチャンスを与えてしまう可能性がある」\n\n 「ここで重要なのは、セキュリティチームが従業員によるAIツールの無断使用を放置してしまうと、企業はデータ保護上の新たなリスクへの対応を余儀なくされるという点だ。社内データをAIツールに入力すると、使用したAIツールの脆弱性が脅威アクターに悪用されてデータを窃取されるリスクがあるだけではない。AIシステムのトレーニングプロトコルによってデータが漏えいし、不正グループに共有される恐れもある」\n\n 「2024年は多くの組織が社内に目を向け、公式チャンネルと非公式チャンネルの両方を活用してAIがすでに導入されている部署を確認するとともに、リスク状況を評価し、自社のリスクと費用を最小限に抑えながら最大の効果をもたらす、安全かつ監査可能なAI利用に向けた戦略的ガイドラインを策定する年になるだろう」\n\n CrowdStrikeはAIのガバナンスの欠如に対して上記のような警鐘を鳴らした。ガバナンスは企業がAIを活用する上でのリスクマネジメントにおいて最も重要だと言っていい。\n\n 最後に、セキュリティベンダーとしても大手のCisco Systemsによる「2024年に予測されるテクノロジー動向」のメッセージを紹介しておこう。\n\n 「当社は、AIは人間の意思決定を拡充するものであり、完全に置き換わるものではないと考えている。AIは未来の触媒、そしてキャンバスとして発展している。すでに家や車、オフィス、そしてポケットの中にもAIは入り込んでいる。瞬く間に驚異的な進歩を遂げたAIだが、メリットとリスクのバランスを取ることも重要だ」\n\n 「人間とAIシステム、そしてそこで活用されるツール間の信頼の確保は基本であり、譲歩の余地はない。つまり、データの透明性と責任の新たな枠組みにより、AIに何ができ何ができないかを明確にし、どのように中断が発生し得るかを人々や企業が知り、AIを実現する、あるいはAIによって実現される新たな仕事に求められるスキルを習得し、肝心な人間に最も資するコラボレーションの新たな形を示す必要がある」\n\n 人間はAIをどう使っていけばよいのか。それは取りも直さず、人間とAIはどこが違うのか。つまり、人間とは何かを突き詰めていくことだ。この哲学的議論を今だからこそ、もっとしっかりやるべきだ。でなければ、人間はAIの使い方を誤るような気がしてならない。\n\n○著者紹介：ジャーナリスト 松岡 功\n\nフリージャーナリストとして「ビジネス」「マネジメント」「IT／デジタル」の3分野をテーマに、複数のメディアで多様な見方を提供する記事を執筆している。電波新聞社、日刊工業新聞社などで記者およびITビジネス系月刊誌編集長を歴任後、フリーに。主な著書に『サン・マイクロシステムズの戦略』（日刊工業新聞社、共著）、『新企業集団・NECグループ』（日本実業出版社）、『NTTドコモ リアルタイム・マネジメントへの挑戦』（日刊工業新聞社、共著）など。1957年8月生まれ、大阪府出身\nITmedia エンタープライズ,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240115-00000070-zdn_ep-000-1-view.jpg?exp=10800'],"['https://news.yahoo.co.jp/articles/534949a4e891df978cb20bd8730aacda8b0901c0/images/000', 'https://image.itmedia.co.jp/l/im/enterprise/articles/2401/15/l_kz_wk240115_01.jpg#utm_source=yahoo_v3&utm_medium=feed&utm_campaign=20240115-070&utm_term=zdn_ep-sci&utm_content=img']"
