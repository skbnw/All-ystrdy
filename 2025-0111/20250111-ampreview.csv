headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIモデルのワンクリック実装が可能に　SambaNovaとHugging FaceによるAI導入簡素化の取り組み最前線（AMP［アンプ］）,https://news.yahoo.co.jp/articles/ae40c010b52d45ee2f86e7d6c074f959eec8259f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250111-00010000-ampreview-000-1-view.jpg?exp=10800,2025-01-11T06:00:34+09:00,2025-01-11T06:00:34+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,2799,"SambaNovaとHugging Faceの取り組み
AIモデルのワンクリック実装が可能に
大規模言語モデル（LLM）の多様化に伴い、クローズドソース、オープンソースを含め選択肢は大幅に増えている。しかし、とりわけオープンソースの実装には時間とコストがかかっているのが現状で、多くの企業では実装が簡単なクローズドソースモデルを選択する傾向にある。
大規模言語モデル／企業の市場シェアの変化（Menlo Venturesより） https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/
シリコンバレーのVC、Menlo Venturesが米国企業を対象に実施した調査はこの状況を如実に示している。

左記は、2023年と2024年におけるAIモデルの市場シェアの変化を示したもの。クローズドソースモデルを展開するOpenAIがシェアを下げつつもトップを維持。また、Anthropicはシェア12％から24％に拡大、グーグルも7％から12％にシェアを広げた。これに対し、オープンソースを展開するメタは前年から変化しておらず、また同じく主にオープンソースモデルの開発を進めるフランスのMistralは6％から5％にシェアを下げている。クローズドソースモデルが優位となっているのは明白だろう。

こうした中、SambaNova SystemsとHugging FaceがワンクリックでオープンソースモデルベースのチャットAIを実装できる仕組みをリリースし注目を集めている。

従来、AIチャットボットの実装には、APIやドキュメントの理解、デプロイメントプロトコルなど、広範な技術知識が必要とされてきた。多くの企業にとって、この技術的な障壁がAI導入を足踏みする要因となっている。しかし、この新しいシステムでは、わずか3行のPythonコードと「Deploy to Hugging Face」ボタンのクリックだけで、本格的なAIチャットボットを数分で構築できるようになる。

テキストだけでなく、画像も処理できる高性能なマルチモーダルモデルも選択可能となっており、ユースケースの可能性は大きく広がる。たとえば、Llama 3.2-11B-Vision-Instructモデルなどが選択可能で、SambaNovaの強みである高速処理も実現している。また、自社展開する場合、GPUなど強力なハードウェアを要する4,050億パラメータモデル、Llama 3.2 405Bをハードウェアの心配なしに高速展開できるのも魅力の1つだ。
実際の使い方：Gradioの場合
SambaNova CloudのAPI取得ページ https://cloud.sambanova.ai/apis
SambaNovaとHugging Faceによる新しい統合サービスは、AI導入プロセスを大幅に短縮しており、非開発者でも扱えるほど簡易なものだ。以下でその使い方を解説したい。

まずSambaNova Cloud APIのウェブサイトでAPIトークンを取得する。以下ページの「Generate New API Key」ボタンをクリックするとAPIトークンが生成される。
「Deploy into HuggingFace」ボタンのクリック後に表示されるHuggingFaceの設定ページ
その後、右側に表示されているコードを実行することで、チャットインターフェースを立ち上げられるというシンプルさだ。

コードの種類は「Curl」「Python」「Gradio」の3種類が用意されている。最も簡易なのは、Gradioだろう。コード欄の横に表示されているオレンジ色の「Deploy into HuggingFace」ボタンをクリックし、HuggingFaceの設定ページで必要な情報を入力するだけでデプロイが完了する。

※Gradioとは、数行のPythonコードでAIモデルをウェブアプリケーション化できるオープンソースライブラリ。2021年にHuggingFaceに買収されて以来、同プラットフォームへの統合が進められてきた。機械学習エンジニアが特別なウェブ開発の知識を持たなくても、AIモデルのウェブアプリケーション化を可能にするのがGradioの強みとなる。
APIキー入力画面
ポップアップ画面では、先程生成したAPIキーを入力してエンターキーを押す。
チャットインターフェース
設定がうまくいけば、チャットインターフェースが表示されるので、通常のチャットアプリケーションと同様に使うことができる。
実際の使い方：Pythonの場合
コード
Pythonによる実装も非常に簡単だ。Pythonを使う場合、2つのアプローチが選択できる。1つはOpenAIパッケージを使うアプローチ、もう1つはGradioパッケージを使うアプローチとなる。

まずOpenAIのPythonパッケージを使うアプローチの場合、ローカルマシンに作成した任意のプロジェクトフォルダにてPythonパッケージコマンドにより、OpenAIパッケージをインストールする。

pip sintall install openai

その後、プロジェクトフォルダ内にPythonファイルを作成し、以下のコードを挿入する。あとは、このファイルを実行するだけ。非常にシンプルだ。
コード
もう1つのGradioのPythonパッケージを使う場合、まずプロジェクトフォルダ内で、コマンドによりGradioのPythonパッケージをインストールする。※同パッケージは現在、Python3.10に対応しているが、その他のバージョンではエラーが出るため注意が必要だ。

pip install sambanova_gradio

パッケージインストール後、任意のPythonファイルを作成し、コードを入力。
ローカルホストURL
このファイルを実行すると、ローカルホストURLが表示されるので、それをウェブブラウザに貼り付ける。（この場合、http://127.0.0.1:7860/）
APIキーの入力画面
その後、APIキーの入力画面が表示されるので、先程生成したAPIキーを入力し、エンターキーを押す。
チャットインターフェース
すると、チャットインターフェースが表示される。これで実装完了となる。
選択可能なモデル
現在、SambaNova Cloud APIでは、左記のモデルが選択できる。おそらく今後も選択肢は増えるものと思われる。

この仕組みにより、開発者はAI実装にかかる問題ではなく、より本質的な問題に注力できるようになることが期待される。
文：細谷元（Livit）",[],[]
