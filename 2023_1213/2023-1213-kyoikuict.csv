headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
アルゴリズムの沼にはまらないために・・・今こそ必要なメディア情報リテラシー（教育とICT Online）,https://news.yahoo.co.jp/articles/593fbe1c57c4a0cc8eb6552d9e0c96915d43a9ed,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20231213-00010001-kyoikuict-000-1-view.jpg?exp=10800,2023-12-13T07:20:19+09:00,2023-12-13T07:20:19+09:00,教育とICT Online,kyoikuict,教育とICT Online,1546,\nSNS上のつながりを視覚的に表すシミュレーションモデル\n「社会人向けに講演会や研修をすると、Google検索の表示順が人によって違うことを知らない人も多く、アルゴリズムがあまり意識されていないと感じる。学校現場も同様で、先生が知らないと生徒に伝わらない」と話すのは、スマートニュース メディア研究所 所長の山脇岳志氏。ネットサービスには、アルゴリズムと呼ばれるさまざまな仕掛けがある。\n【表】知っておくべきネットのアルゴリズムとその影響\nそれが端的に表れるのが、「おすすめ」として表示されるコンテンツだ。例えば、ニュースサイトで記事を閲読し続けると、いつの間にか自分が読みたくなる話題ばかりが並ぶようになる。「YouTube」や「Netflix」などの動画視聴サービス、「Amazon」のような通販サイト、「TikTok」や「Facebook」といったSNSは、いずれもこうしたレコメンドアルゴリズムを採用している。\n利用者の行動を分析している\nアルゴリズムとは、ある問題を解決するための手順や方法のこと。レコメンドアルゴリズムは、利用者の行動履歴を分析して興味・関心を推測し、より好みに合ったコンテンツや商品を推薦する仕組みだ。\n\n ネットサービス上における個人の行動を反映するため、推薦されるコンテンツは人によって異なる。ニュースサイトに並ぶ記事のラインアップは、アクセスする人によって全く違うのだ。多くの人が最も頻繁に使うであろうGoogleの検索結果もパーソナライズされることがある。\n\n ネットサービスが一見親切な機能を提供しているのは、もちろんビジネスのため。より多くの商品やコンテンツを購入してもらうためだけではない。利用者がネットサービス上に滞在する時間を伸ばし、ページ閲覧数を増やせば、より多くの広告を表示できて収益が上がる。\nネットのアルゴリズムを知らない\n山脇氏の証言を裏付けるように、総務省の調査を見ると、「検索結果やSNS等で表示される情報がパーソナライズされていること」を知っている人は44.7%にとどまる。米国と比べて半分しかいない。\n\n 同じ調査で、「SNS等で自分の考え方に近い意見や情報が表示されやすいこと」を知っている人はさらに少なく、4割に満たない。これは「フィルターバブル」に対する認識を聞いている。前述のレコメンドアルゴリズムによって、自分の興味・関心があるコンテンツばかり受け取り続けると、それ以外の情報に接することがなくなる。これがフィルターバブルとして問題視されている。\n\n 同様に「エコーチェンバー」が持つ負の作用も指摘されている。自分と同じような意見や関心を持つ人が集まってやり取りを続けると、自分に同意する人が多かったり、よく似た意見が返ってきたりして、特定の思想・信条が強まっていく現象だ。\nアルゴリズムが分断を加速\n昔から「類は友を呼ぶ」という言葉はあるが、SNSなどのネットメディアは「自分たちの考えを問い直すよりも強化するだけの情報を選択することを容易にした」（坂本氏）。その結果として、ある集団において思想や行動が過激化したり、偏向・偏見が強まったりするといわれる。\n\n 似た者同士が集まるということは、自分たちの考えと合わない人たちを排斥する行動にもつながる。SNSがエコーチェンバーを増幅し、分断を加速することは、数々の研究で明らかになっている。この問題を解決する妙案は見つかっていないが、まずはネットを使う全ての人がアルゴリズムについて理解することが第一歩だろう。\n\n初出：2023年10月11日発行「日経パソコン 教育とICT No.26」\n文：江口 悦弘＝日経パソコン,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20231213-00010001-kyoikuict-000-1-view.jpg?exp=10800'],"['https://news.yahoo.co.jp/articles/593fbe1c57c4a0cc8eb6552d9e0c96915d43a9ed/images/000', 'https://project.nikkeibp.co.jp/pc/atcl/19/06/21/00003/112800503/?SS=imgview&FD=-653719251']"
子供たちを脅かすフェイクの進化とまん延（教育とICT Online）,https://news.yahoo.co.jp/articles/9c7ae88f7dc809473aefeb0cfd559801e0d657a8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20231213-00010000-kyoikuict-000-1-view.jpg?exp=10800,2023-12-13T07:11:54+09:00,2023-12-13T07:11:54+09:00,教育とICT Online,kyoikuict,教育とICT Online,3991,\n図1 左上はAIで生成した“ 存在しない人”。精細で見分けがつかない。上は、どちらかがAIで生成した画像だが分かるだろうか\n生成AI（Generative AI）の進化はすさまじく、誰もが簡単な指示を出すだけで驚くほど精緻な画像を作れるようになった（図1）。かつて、AIで画像を生成するには機械学習やプログラミングなどの専門的なスキルが必要だった。ところが、2021年から「Stable Diffusion」「Midjourney」「DALL-E」という画像生成AIが次々に公開され、今は誰でも好きな画像を作り出せる（図2）。\n【図解】AIがディープフェイクを見破る\nフェイク画像は作り放題\n図2 例えば、こんな写真と見出しをセットで目にしたら、思わずシェアしてしまうことはあり得る。いずれの写真も数十秒で生成できる\nAIを駆使した創造的な活動が盛んになる一方で、フェイクニュースに悪用される懸念も広まった。実際、2022年に発生した台風による大雨の際、生成AIで作られた洪水被害の写真が、静岡県の状況と偽って拡散された。\n\n 図2の画像は、いずれもたった1行の指示（プロンプト）と数十秒の待ち時間だけで作れた。これらに目を引く見出しを付けて、SNSなどに投稿したらどうなるだろうか。たとえ冗談だとしても、ぱっと見ただけでシェアする人がいれば、偽情報がネット上に拡散してしまう恐れがある。特に、メディア情報リテラシーを身に付けていない子供や若年層は、偽・誤情報の拡散に加担する恐れがある。本特集の冒頭で国際大学GLOCOMの山口氏が指摘した「AIの進化によるフェイクの大衆化」が社会に不安の影を落とす。\n顔を乗っ取るディープフェイク\n写真のような静止画以上に深刻な影響を与える恐れがある技術がディープフェイクだ。フェイススワップ（Face Swap）とも呼ばれることから分かるように、映像に写っている人物の顔を別人にすり替える。近年のハリウッド映画ではしばしば使われる技法だが、今はプロではない一般人でもディープフェイクを作れるようになっている。\n\n ディープフェイクは、単に顔を差し替えるだけではない。リップシンクといって発話と唇の動きを同期できるので、政治家が問題発言をするといった偽動画を作成できる。それどころか、表情や顔の向きまで意のままに操れる。図1下のように、乗っ取る側の人間の表情をリアルタイムで反映でき、話すことはもちろん、笑ったり怒ったりもできる。これにより、例えば「厳粛な場面でニヤニヤしている不謹慎な有名人」のような映像をでっち上げることが可能だ。\n\n 専門家の研究によると、ディープフェイクで作られたニュースキャスターが偽の番組に出演し、政治的プロパガンダやフェイクニュースを流す活動が確認されている。\n\n 最近は、人の声もディープフェイク・ボイスという手法で、そっくりにまねることができる。顔をすり替えても声が違えば嘘と分かるが、声まで同じなら信じない方が変だ。声のすり替えでは、別人になりすました詐欺事件や、声によるユーザー認証を突破した事例が報告されている。\n\n 海外ではセレブと呼ばれる有名女優やモデルがフェイクの標的にされやすい。ディープフェイクでは実際にある映像の顔をすり替えるが、実在の人物を使って完全に架空の画像を作り出すこともできる。\n生成AIでフェイクが増える懸念\n顔をすり替えられた有名人が、その人の声で語る映像を見て、自分はだまされないと断言できる人は少ないだろう。それが子供であればなおさらだ。しかし、そうした偽物の映像、写真、音声はインターネット上にあふれ、子供たちが触れることは十分にあり得る。\n\n そこへ追い打ちをかけるように、「ChatGPT」に代表されるテキスト生成AIが登場し、ますます偽情報が増えたり、フィッシング詐欺などのセキュリティリスクが高まったりすると懸念されている。これまで金銭目的のフェイクニュースは人力で作られていたが、生成AIを使えば効率良く量産できる。多言語対応なので、1つのフェイクニュースを世界中にばらまくのも簡単だ。\n\n 拡散については、さらに恐ろしいこともある。「ディープフェイクの衝撃」などの著書がある東京工業大学環境・社会理工学院 准教授の笹原和俊氏によると、生成AIが登場し偽情報が高度化するだけでなく、ボット＊1が自律的にそれを拡散する様子が見られるという。フェイクのパンデミックが発生しているのだ。\n\n＊1 ボットの名称は「ロボット」に由来し、タスクを自動実行するプログラムのことを指す\nAIにはAIで対抗する\nでは、こうした偽画像やディープフェイクを見破る方法はあるのだろうか。残念ながら答えはノーだ。当初、AI が生成した写真には特有の“AIくささ”があった。例えば、光の当たり方が不自然、指を正しく描写できない、写り込む文字が間違っている、瞳孔の形状が不規則といったポイントに着目して判別できた。ところが、現在はそうした弱点を克服し、人の目では偽物と判別できないレベルに達している。\n\n そこで注目されているのが、AIが生成した画像・映像を見破る技術だ。例えば、インテルは映像から顔の血流を推測し、本物の人間かAIが生成した映像なのか判定する手法を発表した。このほかにも、企業や研究機関が多様な方法を開発しているが、それぞれに得手不得手があり、決定的な対抗手段にはなっていない。\n\n 国立情報学研究所（NII）教授で、シンセティックメディア国際研究センター長を務める越前功氏は、「AIにはAIで対抗するしかない」と強調する。越前氏が中心となって研究開発してきたディープフェイクを見破る技術は、NIIが「SYNTHETIQ VISION:Synthetic video detector」という基盤技術として発表した。こうした技術がSNSや動画投稿サイトなどのプラットフォームに組み込まれれば、「この動画はAIで生成された可能性がある」と利用者に警告できるだろう。\n\n 別の方向から偽画像に対抗する動きもある。アドビ、ソニー、キヤノンなどが参加する標準化団体は、写真や画像の来歴を明らかにする「コンテンツ認証イニシアチブ」という取り組みを進める。写真を撮った段階で、「いつ、どのように撮影されたか」を画像データに記録し、それ以降、画像を加工・編集すると、そのたびに「誰が、どのように変更したのか」を追記していく。情報は画像データに埋め込まれ、Webサイトなどで公開されてからも、画像の来歴をたどれる仕組みだ。写真を改ざんしたり、虚偽の説明を添えたりしても、来歴を調べれば嘘がばれる。これからは、こうした情報を調べる方法も知っておく必要が出てくるだろう。\nファクトチェックは有効だが\nここまで偽の画像や映像について詳しく見てきたが、フェイクニュースはさまざまな形で拡散される。その内容も、完全なねつ造から、間違い、陰謀論、広告、プロパガンダなど多岐にわたる。単に間違えている場合や陰謀論のような個人の見解は、テクノロジーだけでは問題を解決できない。\n\n 事実関係の誤りについては、ファクトチェック（真偽判定）という手法がある。日本ではあまり広がっていないが、日本ファクトチェックセンター（JFC）などの組織が活動している。例えばJFCは、福島第一原発の処理水に関する複数の言説についてファクトチェックを実施し、記事として公開している。\n\n ファクトチェックは有意義だが限界もある。まず、膨大な数の偽・誤情報を全てチェックするのは到底不可能だ。誤りを正したとしても、「正しい情報よりも偽・誤情報の方が速く広く拡散する」ことが知られている。手間を掛けてファクトチェックしても、それが人々に届かなければ効果は限定的だ。\n立ち止まって考える\nフェイクニュースをはじめとするさまざまな情報に接する際、子供でも大人でも共通して役立つのはメディア情報リテラシーだ。国際大学GLOCOMの調査「わが国における偽・誤情報の実態の把握と社会的対処の検討」では、「『メディアリテラシー』『情報リテラシー（読解力）』が高いと、偽・誤情報を誤っていると気づく傾向が顕著に見られた。特に『メディアリテラシー』の影響が大きい」と報告している。\n\n 国語教科書収録「想像力のスイッチを入れよう」の筆者で、多くのメディアリテラシー教育を実践してきた下村健一氏は、「即断せずに止まって続報を待つという習慣を身に付けることが大事」と教えている。同氏は、「今は情報に触れた瞬間に判断する人が多い。まず立ち止まって考え、真偽が分からなくても次の情報を待ち、ほかの人の意見を聞くことで、偽・誤情報を拡散してしまうことを防げる」と説く。\n\n その実践として下村氏は、メディアの情報に接した際に「そうかな チェック」を推奨している（図8）。「そうかな」は、4つの行動の頭文字から取っている。前述の「即断するな」のほかに、バイアス（先入観、偏見）を自覚する「偏るな」や、情報は切り取られていることを意識する「中だけ見るな」などがある。\n\n 法政大学の坂本氏は、「だいじかなチェック」を提唱する。メディアの情報は事実関係だけでなく、誰が何のために発信したのかを、批判的に考えることが欠かせない。いずれのチェック手法も、メディアリテラシーのエッセンスが入っている。児童・生徒はもちろん、教員や保護者などの大人も励行したい。\n\n初出：2023年10月11日発行「日経パソコン 教育とICT No.26」\n文：江口 悦弘＝日経パソコン,"['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20231213-00010000-kyoikuict-000-1-view.jpg?exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20231213-00010000-kyoikuict-001-1-view.jpg?exp=10800']","['https://news.yahoo.co.jp/articles/9c7ae88f7dc809473aefeb0cfd559801e0d657a8/images/000', 'https://project.nikkeibp.co.jp/pc/atcl/19/06/21/00003/112800502/?SS=imgview&FD=-650948688', 'https://news.yahoo.co.jp/articles/9c7ae88f7dc809473aefeb0cfd559801e0d657a8/images/001']"
