headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
バルブ製造のTVE、発電所のメンテナンスを「KANNA」で効率化--1日2時間の残業削減（ZDNET Japan）,https://news.yahoo.co.jp/articles/81f493e95795935b4fd6e56961e1c73aade262d6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228813-zdnet-000-1-view.jpg?exp=10800,2025-01-29T17:06:00+09:00,2025-01-29T17:06:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,792,"バルブ製造のTVE、発電所のメンテナンスを「KANNA」で効率化--1日2時間の残業削減の画像
バルブや鋳鋼製品の製造・販売を手掛けるTVEは、アルダグラムが提供する現場DXサービス「KANNA（カンナ）」を導入した。従業員の残業時間が1日2時間ほど削減されたという。1月29日にアルダグラムが発表した。

　KANNAは、現場での作業に従事することが多い非デスクワーカー向けのプロジェクト管理アプリケーション。国内外で5万社が利用しているという。

　火力・原子力などの発電プラントの設計からメンテナンスまでを手掛けるTVEでは、メンテナンス時に、写真を含め報告資料を提出する必要があり、一度に数千枚の写真を撮影するケースもあるという。これまでは、メンテナンス箇所をデジタルカメラで撮影、記録し、事務所に移動してから撮影データをPCに取り込み、メンテナンス箇所ごとにフォルダーを作成。必要な写真データを選別し、記録する作業が必要だったという。

　しかし、対応する現場数の増加や、建設業における時間外労働の上限規制の開始に伴い、業務の効率化が求められていたとのこと。加えて、撮り忘れによる再撮影の手間や、デジタルカメラの破損・劣化に加え、SDカードの紛失などの懸念に対処できる仕組みが求められていた。

　KANNA導入後は、スマートフォンで撮影し、その場で写真整理をする形に変更。KANNA内に指定のフォルダを作成し、写真を管理したことで、写真の撮り忘れを瞬時に確認でき、再撮影などの手間が解消されたとのこと。これにより、作業後に事務所へ戻る移動と、事務業務の時間が不要となり、従業員の残業時間は1日約2時間削減したという。

　今後は写真管理にとどまらず、現場のペーパーレス化を推進する「KANNAレポート」を活用して、現場で作業記録の入力を完結する仕組みを実証していく予定だ。",[],[]
バックアップ／リカバリーの柔軟性や使いやすさ向上に注力--アークサーブが戦略説明（ZDNET Japan）,https://news.yahoo.co.jp/articles/997411cc0a7c5e6c27e891bf198016ba2b3a6271,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228812-zdnet-000-1-view.jpg?exp=10800,2025-01-29T16:33:00+09:00,2025-01-29T16:33:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1208,"バックアップ／リカバリーの柔軟性や使いやすさ向上に注力--アークサーブが戦略説明の画像
Arcserveは1月29日、事業戦略説明会を開催し、最高経営責任者（CEO）のChris Babel氏がビジネスの状況や今後の戦略などを発表した。ランサムウェアなどの脅威が高まり続けている状況を踏まえ、企業データの保護と柔軟性や使いやすさを向上させるバックアップ／リカバリーの提供に注力していくと語った。

　2023年に就任したBabel氏は、顧客やパートナーらとの対話を重ねる中で、セキュリティ脅威への対策と、デジタルトランスフォーメーション（DX）の推進が大きなテーマだと指摘。「ランサムウェアの脅威が続き、さらに加速して、あらゆる企業が標的となっている。他方で、データやAIの活用によりビジネスの競争優位性の獲得にも努力している。脅威に対応してセキュリティ強化に取り組み、サードパーティーなどの支援も活用しながらIT環境の運用管理性の向上などにも努めているが難しくなり、コストも増大している」などと述べた。

　こうした中で同社は、バックアップ／リカバリーとセキュリティのソリューション拡充を推進し、オンプレミスやクラウドなど多様な環境への対応、データ重複排除技術などを駆使した運用コストの節減、事業継続性も含めた顧客におけるガバナンスやコンプライアンス、ポリシーの支援にも当たってきたとする。

　製品戦略では、2024年においてポートフォリオの合理化や既存製品の強化などを実施。ただ、イミュータブル（不変）バックアップストレージの「Arcserve OneXafe」で半導体部品の調達が難航することになり、やむを得ず同製品の提供を終了する事態もあったという。

　このため2025年を加速の1年と位置付ける。2024年11月にリリースした統合型バックアップ／リカバリー製品の最新版「Arcserve Unified Data Protection（UDP） 10」の拡大を皮切りに、第1四半期以降にArcserve OneXafeの後継となるイミュータブルバックアップの新製品の開発・提供を推進。管理コンソールの改良による操作性の向上、アプライアンス／クラウド／テープなどの各種バックアップ手段を適材適所で容易に活用できる柔軟性の強化などにも取り組むとした。

　AIの活用に向けた開発も推進。バックアップ対象データの異常検知や対応手段の提供、バックアップ／リカバリーの運用効率化の支援などにAIを適用していく考えで、現在はこれらの概念実証（PoC）を行っているという。

　また、パートナーチャネルを中心としている製品の販売、提供の改善にも取り組み、パートナーや顧客のコスト節減に寄与する施策の検討も進める。同社が強みとする中堅・中小企業市場に加え、大企業顧客の獲得に向けたセールス体制なども検討していくとした。",[],[]
建設DX推進の障壁は「ノウハウ不足」だけではない--Arentが調査（ZDNET Japan）,https://news.yahoo.co.jp/articles/a8fb1f68254fbee07b96bc1a98dd8250ddca70b4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228804-zdnet-000-1-view.jpg?exp=10800,2025-01-29T15:13:00+09:00,2025-01-29T15:13:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1324,"建設DX推進の障壁は「ノウハウ不足」だけではない--Arentが調査の画像
建設業界のデジタルトランスフォーメーション（DX）を推進するArentは1月28日、建設業界におけるDXの実態に関するアンケートを実施し、その結果を発表した。実施企業の約5割がDXは初期段階にとどまっているという。

　アンケートは、2024年7～12月にArentが登壇したセミナーや展示会で実施。299件の有効回答が得られた。

　「DXの実施状況」については、回答者の約56.5％が「実施中」と回答し、全体の半数以上を占めた。一方、「実施済み」と回答した企業は2.7％にとどまり、DX推進が進行中であることが分かる。「検討中・計画中」の回答は15.8％で、今後、DX導入の動きが加速する可能性が高いと示した。

　「DX実施の目的」の問いに対し最も多かった回答は、「コスト削減・業務効率化」で、全体の39.2％。「顧客や市場の変化への対応」（16.8％）、「データ分析」（13.6％）と続き、効率化が目的であることは明確になっている。前回の調査では「コスト削減・業務効率化」が30％であり、約9.2ポイント上昇した一方、「顧客や市場の変化への対応」は前回の19％から今回は16.8％に減少している。

　「DX推進の内容について」、最も多く実施されている取り組みは「ビルディングインフォメーションモデリング（BIM）活用」（38.2％）。次いで「新しいシステム／ツールの導入」（26.5％）、「AI活用」（21.9％）と続く。一方、「老朽化した既存システムの切り替え」（9.4％）、「外部への委託」（4.0％）となり、デジタルツールや技術の導入が進む一方で、外部リソースへの依存は比較的低いようだ。

　「DX推進における障壁」について尋ねると、「人材不足」で18.9％の回答があり、最大の障壁になっている。続いて「技術的な課題」（15.7％）、「ノウハウがない」（14.3％）と、技術と知識面の課題も挙げられている。「組織文化」は12.3％で、変革に対する内部の抵抗が推進の妨げになっているという。

　「社内で利用しているシステムへの課題感」は、「データが整理されていない」が23.2％で最も多く、「データ連携が困難」（21.6％）、「技術や性能に限界がある」（12.8％）となった。これらの結果から、データ管理と連携の改善が重要であることが分かる。

　「DX人材について」は、「DX人材不足」と回答した企業は83.1％と非常に高い割合を占めた。一方で、社内に十分なDX人材がいると回答した企業は8.4％にとどまり、外部から人材を採用している企業も同様に8.4％となった。内部育成と外部採用の両方で課題がある状況のようだ。

　今回の調査を経てArentでは、DX推進においては現場と組織の連携が不可欠であり、人材の育成と確保が成功の鍵を握る。データ連携や技術的課題の解決は、DXの効果を最大限に引き出すための重要な要素だとした。加えて、社内システムの課題に関しては、データの管理や連携を改善することが業務効率化への出発点であることが示唆されると分析している。",[],[]
ソニーG、十時氏が社長CEOに就任--4月1日付で新経営体制へ（ZDNET Japan）,https://news.yahoo.co.jp/articles/1a2d35ae20508ad4a84076a3986ac5adf7a99165,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228787-zdnet-000-2-view.jpg?exp=10800,2025-01-29T11:30:00+09:00,2025-01-29T11:49:27+09:00,ZDNET Japan,zdnet,ZDNET Japan,616,"ソニーG、十時氏が社長CEOに就任--4月1日付で新経営体制への画像
ソニーグループは1月29日、4月1日付で、現 取締役 代表執行役 社長 COO（最高執行責任者） 兼 CFO（最高財務責任者）の十時裕樹氏が代表執行役 社長 CEO（最高経営責任者）に就任すると発表した。現取締役 代表執行役 会長 CEOである吉田憲一郎氏は取締役 代表執行役 会長になる。

　今回の人事は、1月29日に開催した取締役会において全会一致で決議したもの。4月1日付けで、グループ全体の経営を担う役割・各事業経営責任者の明確化を目的とした経営体制を変更し、主要事業の最高経営責任者を「ビジネス CEO」、グループ経営全体を統括するCEOを補佐し広範な本社機能を担う者を「チーフオフィサー」、グループ本社機能の担当役員を「執行役員コーポレートエグゼクティブ」にすると発表した。

　チーフオフィサーとして、最高戦略責任者（CSO）に御供俊元氏（現職）、最高デジタル責任者（CDO）に小寺剛氏（現職）、 最高人材活用責任者（CPO）に井藤安博氏（新職）、CFOに陶琳氏（新任）が就任する。なお、技術領域では、北野宏明氏がチーフテクノロジーフェローに就く。

　併せて、ソニーセミコンダクタソリューションズの取締役会長には清水照士氏（現上席事業役員）が就任し、安部和志氏は執行役 専務を退任。松岡直美氏は執行役員を退任し、新たにソニー銀行 副社長に就く。",[],[]
サッポロホールディングス、グループ共通データ基盤の本格運用を開始（ZDNET Japan）,https://news.yahoo.co.jp/articles/326c4b468ea28172e09b8579ed1632d24f296786,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228782-zdnet-000-1-view.jpg?exp=10800,2025-01-29T11:06:00+09:00,2025-01-29T11:06:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,514,"サッポロホールディングス、グループ共通データ基盤の本格運用を開始の画像
サッポロホールディングスは1月27日、同社グループ共通のデータ基盤「SAPPORO DATA FACTORY」の本格運用を開始すると発表した。グループ社員が酒類、食品・飲料、飲食店の各事業でのデータや気象情報などのオープンデータを利用できるようになる。

　同社は、現行の中期経営計画（2026年まで）でデジタルトランスフォーメーションの成果創出を位置付ける。その取り組みの一環としてSAPPORO DATA FACTORYを構築した。同基盤は「Qlik Talend Cloud」「Snowflake」「Microsoft Fabric（Power BI）」などで構成される。

　同社はクラウドサービスなどの組み合わせにより、「投資負担増幅や運用複雑化のリスクを解決し、さらにはデータ基盤の構築および利用、活用時のデータへのアクセスについて相乗的な効率化を実現する」と説明。同基盤では、ステークホルダーに関わるデータ、酒類事業や食品・飲料事業の出荷データ、飲食店事業の飲食動態データ、オープンデータを社員が容易かつ安全に利用できるようにしていくという。",[],[]
DeepSeek、新しい画像生成AIモデル「Janus-Pro」を発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/639905bc4a708b073d09363db2ce249309608a21,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228774-zdnet-000-1-view.jpg?exp=10800,2025-01-29T09:55:00+09:00,2025-01-29T09:55:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1514,"DeepSeek、新しい画像生成AIモデル「Janus-Pro」を発表の画像
中国発の人工知能（AI）スタートアップであるDeepSeekの勢いは、今しばらく衰えることがなさそうだ。

　DeepSeekはAppleの「App Store」で最も多くダウンロードされた無料アプリの座を「ChatGPT」から奪ったが、その直後の米国時間1月27日、テキストから画像を生成できるマルチモーダルAIモデル「Janus-Pro」をリリースした。DeepSeekの主力モデルである「DeepSeek-R1」と同じく、Janus-ProもMITライセンスの下でオープンソース化されており（商業利用が可能）、「HuggingFace」や「GitHub」からダウンロードできる。

　R1をリリースしたときと同様、DeepSeekは2つのバージョンのJanus-Proをリリースした。そのパラメーター数は10億および70億だ。DeepSeekは独自テストの結果を公開し、パラメーター数の多い「Janus-Pro-7B」は、「GenEval」と「DPG-Bench」のベンチマークで、Stability AIの「Stable Diffusion」やOpenAIの「DALL-E」など、定評ある画像生成モデルを上回ったと主張している。

　また、このモデルは「自己回帰フレームワーク」を使用しており、統合モデルを「凌駕する」ものだと述べている。

　Janus-Proは、2024年にリリースされた最初の「Janus」をベースに構築されており、画像の生成と解析が可能だ。ただし、パラメーター数の少ない方のモデルは、解像度が384×384の画像の解析に制限されているのが欠点だ。

　とはいえ、Janus-Proの性能はそれでも競争力がある。米国のAI企業の製品と比べてDeepSeekのトレーニングコストが低いと報告されている点を考慮すれば、なおさらだ。DeepSeekは2024年12月に発表した研究論文で、「DeepSeek-V3」モデルの開発コストはわずか560万ドル（約8億7000万円）で、GoogleやOpenAIが主力モデルに費やしたコストに比べればごくわずかに過ぎないと主張していた。もっとも、この金額については、（研究開発費、データコスト、人的コストが除外されているため）不完全だとする指摘や信じがたいと疑問視する声も上がっている。

　一方、NVIDIAはCNBCの取材でこのモデルについて、「優れたAIの進歩」とまで述べている。DeepSeekが他にも次々と製品をリリースする中、このモデルファミリーの第一印象はさまざまだが、全体的にはポジティブなようだ。ただし、自分たちの手でJanus-Proと他の画像モデルを比較テストするユーザーが増えるにつれて、印象は変化するかもしれない。

　米ZDNETも、DeepSeekのアプローチが米国の競合各社よりエネルギー効率が高いという報告について調査している。もしこれが本当なら、AI業界やAI分野への投資にとって、さらに大きな転換点となるだろう。Janus-Proのリリースは、複数の大手AI企業が参画し、米Trump政権が宣伝している5000億ドル（約78兆円）規模のイニシアチブ「Stargate Project」のような計画に疑問を投げかけている。競争力のあるAIがあれば、このイニシアチブで提案されているほどのエネルギーや大規模データセンターが不要になる可能性があるからだ。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
Splunk担当幹部が語る、企業がオブザーバビリティを実践するには（ZDNET Japan）,https://news.yahoo.co.jp/articles/dd57fa9ea51c652641ca065be60e2bb2c9559481,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228675-zdnet-000-6-view.jpg?exp=10800,2025-01-29T07:00:00+09:00,2025-01-29T10:38:34+09:00,ZDNET Japan,zdnet,ZDNET Japan,2709,"Splunk オブザーバビリティ担当シニアバイスプレジデント兼ゼネラルマネージャーのPatrick Lin氏
Splunkでオブザーバビリティ担当シニアバイスプレジデント兼ゼネラルマネージャーを務めるPatrick Lin氏は、「Splunk Observability Cloud」「Splunk IT Service Intelligence（ITSI）」「AppDynamics」などの製品を統括している。オブザーバビリティ（可観測性）について、同氏に話を聞いた。

--Splunkでは、オブザーバビリティをどのように考えているのか？

　Splunkはセキュリティとログ管理のITベンダーとして広く知られているが、その本来の目的は現在で言うところのオブザーバビリティにある。

　Splunkが2003年に設立された際、創業者たちは開発したアプリケーションのトラブルシューティングを迅速化することを目指してスタートした。当時はアプリケーションの状態を把握し、いつ注意を払うべきかを理解し、問題を解決するためにデータと分析が必要とされていた。

　そうした問題自体は変わっていないが、環境はこの20年間で非常に複雑になっている。現在では、スタック内のさまざまなレイヤーを見て状況を理解する必要があり、その数は非常に多くなっている。これらの異なるレイヤーから情報を取り出し、それらを相関させて問題を特定し、根本的に修正する能力がオブザーバビリティだ。

　Splunkの観点では、オブザーバビリティとは、開発者やエンジニアリングチームが管理するアプリケーションやシステムの回復力を確保するためのプラクティスだと考えている。顧客と協力して問題を解決し、ベストプラクティスをアドバイスしてきたこれまでの経験そのものが、われわれの提供価値の一つとなっている。

--オブザーバビリティを実践するにはどうすればいいか？

　まず、ログやメトリクス、トレースの収集など、顧客が理解する必要があるさまざまな事柄について、データを取得できるようにすることだ。

　次の段階としては、データからアクションの優先順位を付けられるようにすることである。なぜなら、そのデータに基づいてアラートを作成し、ユーザーやビジネスに影響を与える重要なデータに集中できるようにするためだ。そのためには通常、顧客側である程度の作業が必要になる。

　次のステップは、トラブルシューティングをさらにスピードアップするために、既に持っているデータを繰り返し使えるようにすることだ。これにより、より多くの洞察を得ることができるようになる。具体的には、アプリケーションやサービスを運用している場合、顧客の属性やイベントの種類に関するメタデータやタグなどの追加情報をデータに付け加えることが必要になるかもしれない。

　最も先進的な顧客は、組織全体でプラクティスを確立し、できる限り標準化する方法を考える。そして多くの場合、それが最終段階となる。初期段階では、個々のチームがこれらのツールを導入することに特に意欲的な場合がある。しかし、オブザーバビリティの目的は、できるだけ早く根本原因を突き止めることだ。そのためには、多くのチームが参加する必要がある。

　実際、多くのチームが参加するほど有利になる。つまりこの段階では、全てのチームにセーフティーネットを提供し、最低限の観察可能なレベルを確保することで、全体的なトラブルシューティングに参加しやすくすることが目標になる。

--Cisco SystemsとSplunkの統合について教えてほしい。

　まず明確にしておきたいこととして、われわれはAppDynamics（Ciscoが2017年に買収したアプリケーション性能管理製品）への投資を続けており、統合によって同製品を廃止する予定はないということだ。

　AppDynamicsが製品ポートフォリオにもたらす価値には幾つかの点がある。まず、AppDynamicsは3層型アプリケーションで威力を発揮するソリューションである。つまり、より伝統的なアプリケーションアーキテクチャーに適している。Splunkの顧客全般がこれらの機能を利用できるようにするつもりだ。

　AppDynamicsのもう一つの特徴は、オンプレミスのデプロイメントオプションを提供していることだ。つまり、オンプレミスで完全なオブザーバビリティソリューションを提供できる。

　さらに、AppDynamicsにはデータベースのモニタリングやアプリケーションセキュリティ関連の機能など、Splunk Observability Cloudに追加できる機能がある。具体的には、「Cisco Secure Application」がその一例だ。

　最後にもう一つ、CiscoはAppDynamicsだけでなくオブザーバビリティ全般にも多くの投資をしてきたということがある。Ciscoが投資した多くの機能は、Splunkのオブザーバビリティ製品に追加されることになる。

--Splunkのオブザーバビリティ製品の差別化ポイントは？

　最初のポイントは、可視性の広さについて。次に、問題解決までの時間、そして提供されるソリューションのコストと価値についてだ。

　可視化に関しては、特に2つの点が重要になる。1つ目は、所有しているネットワークだけでなく、所有していないネットワークも可視化できることだ。もう1つは、アプリケーションの近代化において、顧客の環境に関係なく対応できることだ。3層アーキテクチャーの従来型アプリケーションだろうと、クラウドネイティブのマイクロサービスアプリケーションだろうと、われわれは非常に優れた洞察を提供できる。

　問題解決にかかる時間は、問題を検知する時間、問題の場所を特定する時間、そして問題を発見してから根本的な原因を解決する時間に分けられる。「Splunk APM」の「Tag Spotlight」機能は、トラブルシューティングを迅速化するのに役立てられる。

　また、顧客が持ち込むデータ量は劇的に増え続けている。Splunkはここ数年、顧客がデータをどのように階層化するかを理解するための支援に力を入れてきた。

　例えば、念のために取っておくデータは長期間保存するが、すぐにアクセスする必要はない。一方、非常に価値が高く、数秒以内にアラートを出す必要があるデータもある。Splunkはそのようなデータを効率的に管理する方法を提供している。",[],[]
CCCMKホールディングス、「Snowflake」でデータ基盤を刷新（ZDNET Japan）,https://news.yahoo.co.jp/articles/bd07113f4fd6e0d0dbfa74de67dc54b9e7cf6245,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228736-zdnet-000-1-view.jpg?exp=10800,2025-01-29T07:00:00+09:00,2025-01-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2300,"CCCMKホールディングス IT戦略本部本部長の松井太郎氏
Snowflakeは1月27日、報道機関向け説明会を開き、カルチュア・コンビニエンス・クラブ（CCC）傘下のCCCMKホールディングスによるデータ基盤の事例を紹介した。

　説明会に登壇したCCCMKホールディングス IT戦略本部本部長の松井太郎氏によると、「TSUTAYA」や「蔦屋書店」などを展開するCCCと傘下のグループ各社では、顧客の信頼を第一に、プライバシー保護を徹底した上で、データの価値を最大限に活用し、より良いサービス体験の創出に取り組んでいる。「Snowflake」の導入によって、同社グループのプライバシー保護への取り組みは一層強化され、データ活用も加速しているという。

　CCCMKホールディングスは、データベースマーケティングを通じて生活者へのライフスタイル提案を行う事業会社。約1.54億人の会員が利用する「Vポイント」のマーケティング・ソリューション事業やアライアンス事業を手掛ける。Vポイントの現在のアクティブユニークユーザー数は8600万人に達し、「国内最大規模のポイントサービス」（松井氏）である。

　CCCグループでは、CCCMKを起点にグループ各社で段階的にSnowflakeを導入し、各社の分析環境を刷新してきた。グループ間や提携会社間のデータシェアリングだけでなく業界横断のデータプラットフォームも提供する。

　松井氏は「データそのものがビジネスの根幹」だといい、同社におけるデータ基盤の課題として、（1）分散したデータベースとパフォーマンスの課題、（2）データ活用高度化によるワークロードの増加、（3）データ活用の民主化の促進――の3点を挙げた。

　（1）では、分散したデータベースとコスト増大により、パフォーマンス低下が深刻化し、負荷分散やクラウド移行だけでは解決不可能な状況にあった。（2）については、加盟企業の増加や分析業務の高度化によってワークロードは年々増加し、月初や繁忙期にはクエリーの遅延や待機が発生するなど業務にも支障が出る状態だった。

　（3）は、非エンジニア／アナリストを含めた全社員にビジネスインテリジェンス（BI）アカウントを提供していたが、負荷対策のためにデータベースからファイルを抽出し、BIに連携する中間作業が発生していた。

　こうした課題を解決するため、CCCMKホールディングスでは新たなデータ基盤のビジョンとして「シングルソース」「マルチワークロード」「デリバリーイージー」を定め、データベースを統合しつつ、リソース競合を解消できるシングルソースアーキテクチャー、ヘビークエリーやBIのライトクエリー、機械学習など多様なワークロード、新規事業やコラボレーションを加速できる柔軟なデータ機能の実現を目指した。

　Snowflake導入による効果としては、データクエリーの速度が従来比で50％以上向上したほか、月初などのクエリー繁忙期もスケーラブルに拡張することで、クエリー遅延がゼロになった。また、BIとの親和性や目的に応じたリソース提供により、迅速な意思決定にも寄与している。

　加えて、必要なリソース消費に応じたコスト管理が可能になり、クエリーパフォーマンスの向上と合わせ、インフラコストは60％に削減された。データを活用した新規サービスを立ち上げた際も即時に分析リソースを提供できるようになった。

　「Oracle Exadata」「Azure Synapse Analytics」「Vertica」に分散したデータベースをSnowflakeに統合することでデータサイロを解消し、データ更新のリードタイムも向上した。システム構成が集約され、エンジニアの保守作業やスキル育成も最適化された。

　プライバシー要件を満たすアクセスコントロール管理は、運用負荷が非常に高かったが、Snowflakeの機能を活用し、プライバシー保護を強化。また、それらの運用業務を効率良く安全に運用できるようになった。

　Snowflake導入による効果は、「コスト効率とパフォーマンス向上だけにとどまらない」と松井氏は強調した。

　2024年6月には「Streamlit In Snowflake」を用いて、アナリスト部門でアプリ開発が始まった。Python初心者も多い中、週次の勉強会を通じてスキルを向上させ、Snowflakeの支援を受けながら、複数の業務アプリをリリースしている。「新しいアーキテクチャーに触れることで、チャレンジ精神が高まり、スキルアップだけでなく、業務の効率化や高度化を生み出している」（松井氏）

　データシェアリングの取り組みでは、グループ内だけでなく、業務提携した三井住友カードとの間でも、安全で革新的なデータ連携を実現している。「Microsoft Azure」と「Amazon Web Services」のクロスクラウド環境でデータを共有し、Snowflakeであればテーブルのシェアのみで開発期間の短縮だけはなく、関わる人員や運用業務も大幅に削減できるという。

　松井氏は今後の展望として、「顧客価値の追求」「グループシナジーの最大化」「新規事業の促進」「コラボレーションの拡大」を挙げている。その上で、データ活用を最大化し、より良いサービスの提供を目指すとし、「CCCグループはSnowflakeを活用し、今まで以上にデータを安全にお預かりし、さらなるデータ活用による新たな価値創造への挑戦を続けていく」と述べた。",[],[]
オープンソースAIの新たな定義--「重み」を中心に据える「Open Weight Definition」（ZDNET Japan）,https://news.yahoo.co.jp/articles/ff9335a4f250be03264e0f7b56950f89fe73945b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228724-zdnet-000-1-view.jpg?exp=10800,2025-01-29T07:00:00+09:00,2025-01-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3184,"提供：ZDNET
オープンソースと人工知能（AI）の開発者やリーダーの考えは、オープンソースAIが重要であるという点で一致している。Open Source Initiative（OSI）が「オープンソースAIの定義」（OSAID）の策定に最善を尽くしているにもかかわらず、OSAIDに何を含めて、何を除外すべきかに関しては、まだ大きな見解の相違が存在する。こうした意見の相違から、新たに結成されたOpen Source Alliance（OSA）は、OSAIDに対する独自の解釈である「Open Weight Definition」（OWD）を発表した。

　OWDは、クローズドソースAIとオープンソースAIの整合性のバランスをとる新しい枠組みだ。OSAによると、AIテクノロジーの急速な発展によって生じる複雑さと課題に対処するために設計されたという。AIモデル、特に大規模言語モデル（LLM）において「オープンソース」を構成する要素の明確な基準を設けることを目指している。

　重み（Weight）はAIの基本的な構成要素だ。生データに基づいて、AIプログラムのさまざまなレイヤーのノード間の接続に関連する数値であり、機械学習の訓練プロセス中に決定される。具体的には、OWDには以下のものが含まれる。

モデルの重みのアクセシビリティー：モデルの重みを開発者や研究者が利用できるようにすることに重点を置く定義

データセットの情報：訓練データへのフルアクセスは要求しないが、データセットの内容や収集方法に関する詳細な情報の必要性を強調する定義

アーキテクチャーの透明性：改善と変更を容易にするために、モデルアーキテクチャーに関する情報の開示を奨励する枠組み

　OpenUKの最高経営責任者（CEO）であるAmanda Brock氏は、OWDを支持すると述べた。「OSAは、現在競合している複数の組織のさらなる関与を促し、世界的な協力関係を改善するために運営されている。オープンウェイトを定義するアプローチの共有という第一歩は、AIの分解や、データ、重み、モデルなど、分解されているが重要な構成要素のオープン性の度合いを定義するという取り組みに合致している。確かに、小規模なグループが目的にそぐわない定義を策定するよりも、現実的で実行可能であるように思える」

　最後のコメントは、Brock氏が反対するOSIのOSAIDに言及したものだ。実際に、OSAはオープンソースAIの問題を取り上げて、OSIに代わる存在になろうとしている。OSAの創設者であるSam Johnston氏は、1月のプレスリリースで次のように述べた。「データによって『オープンソースの定義』（OSD）の限界がテストされた。OSDのオープン性については証明されたが、ソースコードコンポーネントを超えた完全性には欠ける」。Johnston氏は、OSDにOWDを追加することで、「Open Source 2.0」を生み出したい考えだ。

　OSAIDが2024年10月に公開されたといっても、「OSIは定義の『取り組みを始めたばかりの段階』にある」とBrock氏は述べた。「これは、『オープンソースAI』を定義しようとするアプローチが間違っていることを示しているように思える。むしろ、このような分解されたアプローチで課題に取り組んで、訓練データなど、基礎となる『テクノロジー』や、オープンであることの意味を検討するべきだ。オープンソースとは、決まりを定義するものではなく、定義すべきでもない。データなどのテクノロジーの『ソース』を誰もがあらゆる目的で使用できるようにするものだ」

　Brock氏は次のように結論づけた。「この現実と正確さを、リスクと責任の評価において理解しなければならない。したがって、OSAによるオープンウェイトの定義の発表は、今のところ歓迎すべきことだ」
OWDの発表を受けて、OSIのエグゼクティブディレクターのStefano Maffulli氏は次のように語った。「コミュニティーが標準と定義を構築する。The Linux Foundationのコミュニティーはすでに、『Model Openness Framework』でオープンウェイトの定義を策定した」

　オープンウェイトの標準化に取り組んでいるのは、The Linux Foundationだけではない。オープンソース分野の著名な弁護士であるHeather Meeker氏もこの標準化に取り組んできた。Meeker氏は次のように記している。「AIの分野には、対処すべき根本的な誤解が存在する。それは、オープンソースソフトウェアライセンスの原則をニューラルネットの重み（Neural Net Weight：NNW）に直接適用できるという思い込みだ。この誤解は、ソフトウェアソースコードとNNWという2つの異なる人工物を混同することから生じている」

　同氏は次のように続けた。「NNWは別物だ。人工ニューラルネットワークが学習した『知識』を表すものであり、大きな数字の行列として保存されることが多い。ソースコードと違って、人間が読むこともデバッグすることもできない。オープンソースの基本的な自由、すなわちソフトウェアの実行、研究、再配布、改変の自由を、NNWに簡単に当てはめることはできない。NNWの実行と配布は可能だが、研究と改変は容易ではなく、機能的に不可能な場合もある」

　Meeker氏が提案したオープンソーススタイルのライセンス「Open Weights Permissive License」の下で、NWWを共有することはできる。しかし、同氏は次のように指摘する。「この定義で重点を置いているのは、オープン性の本来の考え方や、フリーソフトウェアとオープンソースに関する『第零の自由』の本来の目標を維持することだ」

　Maffulli氏は次のように語った。「OSIは、AIのユーザーが実際に何をするかを観察している。The Linux Foundationの取り組みと同様に、OSIの定義はコミュニティーによって、コミュニティーとともに開発されている。これは最初のオープンソースの定義でも同じだった。その開発を支えたのは、20年以上にわたってソフトウェアの構築とリリースに取り組んできたフリーソフトウェアコミュニティーだ。AIでもそれと同じことを行った。つまり、コミュニティーがオープンソースAIを定義するプロセスを主導してきた」

　Meeker氏はインタビューで次のように付け加えた。「さまざまな定義の取り組み（OSIのOSAID、私が2022年に最初に公開したThe Open Weights Definition、そして今回の新しい定義）が1つにまとまることを願っている。しかし、残念ながら、どの定義もオープンソースの定義のような事実上の標準にはなりそうもない。さまざまな規制の枠組み、プライバシー規制、高度に集中した市場で慣行を確立しているベンダーが、それらの定義に暗い影を落としている」

　つまりこの議論は、オープンソースAIとは正確にどのようなものなのかを、まだ議論している段階ということだ。確かに、AIプログラムやデータをオープンソースだと言うだけで実際にそうなるわけではない（これはMetaが「Llama」でやったことだ）という点では、オープンソースのリーダーたちの意見は一致するだろう。しかし、オープンソースAIの定義に関して合意が形成されるのは、まだまだ先のことになりそうだ。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
大塚商会とNEC、オンプレミスで生成AIを利用するためのシステムを発売（ZDNET Japan）,https://news.yahoo.co.jp/articles/b5c507fe3f2217f9e5e9016207e0d7c8b3dba418,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228753-zdnet-000-1-view.jpg?exp=10800,2025-01-29T06:30:00+09:00,2025-01-29T06:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,436,"大塚商会とNEC、オンプレミスで生成AIを利用するためのシステムを発売の画像
大塚商会とNECは、企業のオンプレミス環境で生成AIを利用するためのシステムとサービスをセットにした新製品「美琴 powered by cotomi」を4月23日から提供すると発表した。外部ネットワークとの接続がないセキュアな社内環境で機微情報を含むオフィス文書などの作成や要約、社内情報の検索やナレッジ管理などが行えるという。

　新製品は、NECが開発する生成AI基盤「cotomi」（コトミ）と設置が容易なタワー型筐体を採用する「Generative AI Server」をセットにし、ソフトウェアやサービスを組み合わせて提供する。cotomiは高い日本語性能が特徴で、大塚商会は同社内で培ったAIの活用のノウハウを有する。

　両社の販売目標は300社で、今後大塚商会は専門用語やガイドライン、知見などの業界・業種ごとのデータにも対応する業種特化型生成AIサービスの提供を予定している。",[],[]
HPE、VMware代替基盤とAI基盤を2月に国内発売--日本に最適化（ZDNET Japan）,https://news.yahoo.co.jp/articles/577ed74992c9eca194e82c9bc251f1c2f27edf83,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250129-35228750-zdnet-000-1-view.jpg?exp=10800,2025-01-29T06:00:00+09:00,2025-01-29T06:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3015,"HPE、VMware代替基盤とAI基盤を2月に国内発売--日本に最適化の画像
日本ヒューレット・パッカード（HPE）は1月28日、VMware環境からの移行に対応する仮想化基盤製品「HPE VM Essentials」と、ハイブリッド型のAI基盤製品「HPE Private Cloud AI」を2月に国内で発売すると発表した。出荷開始は、HPE VM Essentialsを2月末、HPE Private Cloud AIを4月としている。

　2つの新製品は、2024年の同社の年次イベント「HPE Discover」で発表されたもの。日本での提供がグローバルでの発表から遅くなったことについて執行役員 ハイブリッドソリューションズ事業統括本部長の吉岡智司氏は、「HPE VM Essentialsは、HPE Private Cloud AIのエンジンとしても組み込んでおり、両製品をきちんとそろえて日本市場で提供できるようにした」と説明した。

　同氏は、HPEが長らくオンプレミス／クラウドのハイブリッドモデルによるITインフラの提供に取り組み続けているとした上で、「特にAIは、完全にハイブリッドモデルのワークロードになる」と言及。また、BroadcomによるVMwareの買収に伴い、旧来の各種仮想化製品が「VMware Cloud Foundation」に統合され、ライセンスなども大きく変更されたことで、ユーザー企業の中には別の環境への変更を検討する動きも見られた。

　吉岡氏の説明では、VMwareからの変更を検討する顧客に対応するというHPE VM Essentialsと、それを中核に組み込むHPE Private Cloud AIの提供の足並みをそろえることで、国内企業における仮想化基盤のリプレースやオンプレミス／クラウド環境でAI基盤を開発・運用したいとする需要に対応する考えだ。

　AI基盤について吉岡氏は、クラウドのハイパースケーラ―各社の基盤サービスの利用が注目を集める中で、企業や組織の重要なデータが意図せずクラウド側に渡ってしまう懸念などがあると指摘。複数のグローバル調査の結果を引用し、AIを本格的に利用する上で企業や組織の半数以上がクラウドを活用しつつ、機密性の高いデータはオンプレミスやプライベートクラウドで利用する意向にあり、今後はこうしたハイブリッドモデルが加速していくと予想した。

　HPE VM Essentialsは、HPEが2024年8月に買収したMorpheusの技術を用い、KVMベースのハイパーバイザー「HPE VM Essentials Hypervisor」と「VMware vSphere」の統合運用管理を可能にする製品。ソフトウェアのみで構成する「HPE VM Essentials Standalone」、HPE VM Essentials Standaloneと同社のサーバーやストレージなどのハードウェアを組み合わせた事前検証済み構成モデルの「HPE VM Essentials Embedded HPE Private Cloud Business Edition」、クラウドサービス環境の運用管理やフルマネジードサービスなどもセットにしている「HPE VM Essentials Embedded HPE Private Cloud Enterprise Edition」の3種類をラインアップする。HPE VM Essentials Embeddedの2種類は、グローバルでは2025年春頃以降に順次提供するという。

　HPE VM Essentialsについてハイブリッドソリューションズ事業統括本部 GreenLakeソリューションビジネス本部 ビジネス開発部長の小川大地氏は、「日本の顧客にとって必要十分とされる標準機能と価格で提供する」と説明。同氏によると、ソフトウェアのHPE VM Essentials Standaloneは、同社が2023年まで国内で販売し、約8割の顧客が購入していたという「VMware vSphere Standard」ライセンスでの機能や価格と同等にするとのこと。

　実勢価格などは、販売経路や購入する製品構成などによって大きく異なるとしつつ、VMware vSphere Standardで数十万円台、HPE VM Essentials Embedded HPE Private Cloud Business Editionで数百万円台、HPE VM Essentials Embedded HPE Private Cloud Enterprise Editionで数千万円台になる見込みとしている。

　HPE VM Essentialsのソフトウェアでは、VMware環境からの移行（VMware vSphereからHPE VM Essentials Hypervisorへ変換）するためのツールを無償で搭載する。ただし、実行にはシステム停止を必須とするため、無停止で実行可能な有償の「HPE Zetro」も併せて用意するとした。また、Morpheusのクラウドコスト管理機能なども今後提供していくという。

　もう一方のHPE Private Cloud AIは、HPEとNVIDIAが協業に基づいて共同開発したソリューション。HPEおよびNVIDIAのサーバー、GPU、ネットワーク、ストレージのハードウェアと、ソフトウェアとして「NVIDIA AI Enterprise」および「HPE AI Essentials」を搭載する。AIモデルのためのデータプリパレーション（準備）、モデル学習とカスタマイズ、推論実行、データエンジニアリング、分析と可視化、データサイエンスに必要なソフトウェアと必要十分な性能を提供するハードウェア群で構成されている。

　ハイブリッドソリューションズ事業統括本部 GreenLakeソリューションビジネス本部 ビジネス開発部 シニアカテゴリーマネージャーの寺倉貴浩氏は、「HPE Private Cloud AIは、概念実証（PoC）ではなく本番利用のための製品」と明快に述べ、吉岡氏が指摘したユーザーの状況を踏まえて、クラウドの利便性とオンプレミスの制御性の両立させたソリューションになると強調した。

　特にHPEの観点では、システム基盤の管理（インフラリソースやセキュリティなど）、AI基盤の管理（GPUリソースやデータソース、機械学習、パイプラインなど）、AI開発（データパイプライン、データ加工、アクセラレーター、ノートブック）の3種類のユーザータイプ別に運用管理環境を提供することが特徴だという。

　AI環境の提供には、エコシステムの拡充やエンジニア人材の育成、中長期的なコストの最適化にも取り組んでいるとし、エコシステムではグローバルパートナーに加えて、国内で2024年11月にSCSKとの協業を発表。ユーザーの多様なユースケース開発を支援する「Unleash AIパートナープログラム」も展開する。コスト面では、従量課金などを選択できる「HPE GreenLake」や「HPE Financial Services」などを活用できるとした。",[],[]
