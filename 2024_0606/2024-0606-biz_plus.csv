headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
シンギュラリティは2045年より前に？NRI・Google Cloud語る生成AI（ビジネス＋IT）,https://news.yahoo.co.jp/articles/a807a32b9eda606915028dbdd759e1d87f222b17,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00140128-biz_plus-000-1-view.jpg?exp=10800,2024-06-06T06:10:05+09:00,2024-06-06T06:10:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,3130,"\nGoogle Cloud AI事業本部 執行役 事業本部長 橋口 剛氏\n生成AIの活用が急速に進み、身近なテキスト、画像、音楽などの生成からビジネスプロセスの革新まで、幅広い分野で利用されている。具体的に生成AIは企業において、どのように活用されているのだろうか。その活用事例と今後の展望について、NRI AIコンサルティング部 シニアコンサルタント 橘 優太朗氏、NRIデジタル エキスパートデータサイエンティスト 松崎 陽子氏、Google Cloud AI事業本部 執行役 事業本部長 橋口 剛氏が語った。\n本記事は2024年4月24日-26日に開催された「Japan IT Week 春」の講演内容をもとに再構成したものです\n生成AIブームの現在地\n1ページ目を1分でまとめた動画\n\n\n\n 1950年代から始まる人工知能の発展は、2020年代に入り第4次ブームを迎えている。\n\n それぞれの年代を振り返ると、1950年以降の第1次ブームでは、人工知能が登場。人間が決めたルールに従い、人間と同様のタスクを遂行した。1980年以降の第2次ブームでは、人が定義した特徴から機械が結果を判別・予測する機械学習、2010年以降の第3次ブームでは、機械が特徴を定義し判別・予測する深層学習が登場した。\n\n「2020年以降の第4次ブームでは、機械が独自のアウトプットを生成する生成AIが台頭しています。生成AIは汎用（はんよう）性が極めて高いため、市場からの支持率・期待値が高いです」（橘氏）\nモルガンスタンレー、大和証券…企業における生成AI導入状況\n日本企業における生成AIの導入状況は、特に大企業を中心に活用が進んでおり、大企業における導入率は25%に達している。将来的な導入割合は、RPAと同等レベルとなる見込みだという。\n\n 生成AIを利用することで、非構造化データの有効活用や業務の自動化、効率化が見込まれる。社内データの大半は画像・文章等の非構造化データであり、活用価値は極めて大きい。\n\n また、平均で現状業務の25％が自動化・効率化の対象となる。生成AI活用のインパクトが特に大きい業種はソフトウエアエンジニア、マーケティング、営業の3種。実際、企業が生成AIを活用することで、生産性は平均40%向上するというデータもある。\n\n 実際の企業の導入事例は以下のとおりさまざまだ。\n\n\n・モルガンスタンレー：GPT-4を活用したファイナンシャルアドバイザー向けQAチャットボットの開発。\n・大和証券：音声データから要約を生成するAI「Speech2Summary」の開発。\n・メルセデス・ベンツ：GitHub Copilotを導入し、ソフトウェア開発の品質向上。\n・伊藤園：「お～いお茶 カテキン緑茶」のパッケージリニューアルデザインに生成AIを活用。\n・Toyota Research Institute：工学的制約を考慮した車両デザインツールの開発。\n・NRI：1万人アンケートの集計・分析・示唆抽出ツールの開発。\n\n 今後1～2年で業務に生成AIが自然に溶け込んでいないと他社に劣後するという。この波に乗り遅れてはいけないだろう。\n\n 生成AIモデルの1つであるClaude3がIQテストで人間の平均値であるスコア100を超えたという報告もあり、いわゆる""シンギュラリティ""の到来がこれまで想定されていた2045年より大幅に早く訪れる可能性がある点も注意だ。\n言語モデルを組み込んだアプリケーション開発の現在\n続いて、大規模言語モデル（LLM）を活用したアプリケーション開発の未来について見ていこう。\n\n LLMの技術は、試験的な段階から実用段階へと進化している。LLMは多岐にわたる知識を持ち、さまざまな質問に応答できる特性を持つ。しかし、その知識は英語中心の学習データに限定されるため、日本固有の知識に弱い上、最新の情報を反映できない。\n\n「また、ハルシネーション（誤った情報の生成）というもっともらしい誤りを生成してしまう現象も起こりえます。LLMが得意とする部分を理解し、どのような指示だしをするとうまくいくかを考えることが重要です」（松崎氏）\n\n\n さらに、ルールの整備がされていないまま社員が勝手にLLMを使うことで、機密状況の流出につながりかねない。機密情報の流出を防ぐための対策が必要だろう。\n未来の同僚、「エージェントAI」\nLLMの実用的な事例も増えてきている。たとえば、ELYZA（イライザ）では日本語特化の独自AI、ELYZA Brainにより、一部求人原稿の作成業務の30％効率化を実現した。\n\n また、大規模モデルを活用した高度なアプリケーションである、エージェントAIが登場している。エージェントAIは、ユーザーの要望に添って自律的に判断し応答する。Toolとよばれる機能により、テキストによる応答だけでなく関数を実行するなどのアクションをともなう応答が可能だ。\n\n 従来のLLMは、人からの作業指示を受けて指示を理解し、作業結果を出力していた。一方、エージェントAIは、作業指示を理解し、ほかのプログラムへの指示に変換することができるところが大きく違う。また、ローカルLLMに関しては、技術ノウハウが蓄積され、活用コストが低下しているため、自社固有の課題解決に役立てることが可能になってきている。\n\n「将来的にはエージェントAIに指示をだすのではなく、一緒に働く関係になるでしょう」（松崎氏）\nGoogleによる生成AIの革新\n最後にGoogleによる生成AIの革新について見ていこう。橋口氏によると、生成AIは、市場において7兆ドル（約100兆円）の経済インパクトを持つと見積もられるという。\n\n「これは、生産性の向上や新しい価値の創出によるもので、特にカスタマーサービスチャットボットやソフトウェア開発の効率化においてその効果が顕著です。実際に、カスタマーサービスチャットボットの分野では、生成AIの使用が全体の70%を占めています」（橋口氏）\n\n\n その中で、Googleは、生成AIの分野におけるイノベーションの先駆者として、膨大なデータを効率的に学習させる技術や、文脈理解、会話生成などをリードしている。特に、Transformerモデル（2017年）、BERT（2018年）、LaMDA（2020年）、そして最新のGemini（2023年）など、一連の技術革新を通じて、生成AIの能力を大幅に拡張している。\n\n 特に、最新のGeminiはマルチモーダル対応の会話型AIサービスであり、さまざまなフォーマット間での変換を可能にする。1時間の長尺動画から重要なポイントのみを抽出し、要約を生成することもできる。\n\n Google CloudのAI戦略の強みは、AI技術の深い造詣、セキュリティとプライバシーの確保、そして企業向けにフルスタックのソリューションを提供することにある。エンタープライズ向けのVertex AIは、生成AIを活用したエージェント構築のための基盤として、30以上のモデルを即座に利用可能にするなど、開発者にとって強力な支援を提供する。\n\n「生成AIに関連する知的財産（IP）や著作権の問題に対しても、Googleは包括的な対応策を提供し、企業が安心して技術を活用できる環境を整えています」（橋口氏）\n執筆：ビジネス＋IT編集部 玉田萌、撮影：濱谷幸江",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00140128-biz_plus-000-1-view.jpg?pri=l&w=640&h=426&exp=10800'],['https://news.yahoo.co.jp/articles/a807a32b9eda606915028dbdd759e1d87f222b17/images/000']
銀行による「経営改善提案」が激変、金融庁のおススメ「業況管理AI」とは？（ビジネス＋IT）,https://news.yahoo.co.jp/articles/d435017b221c795117390939b9fc2696e20d837d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00139931-biz_plus-000-1-view.jpg?exp=10800,2024-06-06T06:30:05+09:00,2024-06-06T06:30:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,3457,\nAIが中小企業に経営改善プレッシャーをかける日が来る？（後ほど詳しく解説します）\n中小企業に対する経営改善のサポートは銀行が担う重要な役割の1つですが、金融機関の人手不足が深刻化する中、融資先の業況管理をAIが肩代わりする方法の研究が進められています。業績悪化の兆候がみられる企業を早期に発見したり、現場経験の少ない若手職員でも問題点を発見したりできるAIツールとはどんなものか？ 金融庁が実施した「業況管理AI」に関する委託研究の成果と展望、課題について解説します。\n【詳細な図や写真】「中小・地域金融機関向けの総合的な監督指針」等の一部改正（案）（出典：金融庁「中小・地域金融機関向けの総合的な監督指針」等の一部改正（案）の公表について）\n金融庁が地銀に中小企業の異変の「早期発見」を促す理由\n新型コロナ禍下で始まった実質無利子・無担保融資（ゼロゼロ融資）の返済本格化、原材料・エネルギー価格などの高騰や円安、人手不足の影響などにより、依然として中小企業は厳しい経営環境に置かれています。\n\n そんな中、地域産業や事業者を下支えする金融機関の役割、責任も大きくなっています。地銀、第二地銀などが地域経済の回復・成長に貢献する役割を果たすよう、国は2024年6月に「中小・地域金融機関向けの総合的な監督指針」を改正。顧客企業の実情に応じた経営改善支援や事業再生支援などを先延ばしすることなく実施するよう改めて求めました。\n\n\n 同時に改正指針では、物価上昇や価格転嫁の遅れが企業の財務状況に影響を及ぼし、取り返しのつかない状態になる前に、顧客企業の状況変化の兆候を早期に発見、対応するよう促しています。\n\n ただ、「早期発見・早期対応」とはいっても、そもそも人手不足が指摘される金融業界では、融資先のピンチを先回りして防ぐ取り組みには手が回り切らないのも実情です。\n\n こうした問題意識を背景として、金融庁は2022年4月からAIなど活用し、経営改善支援が必要な先を早期に発見し、現場職員の業務を支援する仕組みについて調査を進めてきました。\n金融庁のおススメ「業況管理AI」とは？\nあずさ監査法人における委託調査の結果は、「AIやICT技術を活用した経営改善支援の効率化に向けた調査・研究報告書」としてまとめられ、2023年3月に公表されました。報告書のポイントをみていきましょう。\n\n 開発した新たなAIモデルは、融資先の財務情報と外部環境データをインプット（入力）すると、経営改善の支援が必要な企業を優先順位付けし、企業とスムーズに商談が進むように業況に関するサマリーを出力します。\n\n AIモデルにインプットするデータには、対象となる企業の属性データ（業種、従業員数など）や財務データ（財務諸表など）のほかに、外部環境データがカギを握ります。\n\n 今回の調査では、新型コロナウイルス下における企業の信用力や業績の変化を検知することを想定。以下のように、企業の信用力や業績との関連があることが推察されるマクロ経済情報や、新型コロナウイルスの影響を強く受けた業種に関するデータを外部環境データとして採用しています。\n\n\n＜AIモデル開発に用いた主な外部環境データ＞\n・マーケット関連データ……為替レート、無担保コールO/Nレート、国債利回り、TOPIX、日経225、東証REIT指数、Dow Jones Total、Stock Market Index\n・経済関連データ……GDP成長率、業況判断DI、景気動向指数、中小企業売上見通しDI、発電実績、エネルギー消費量、入港船舶の総トン数、公共機関からの受注工事額など\n・金融関連データ……貸出約定平均金利、総貸出平残、マネタリーベース、マネーストック、倒産件数、倒産負債総額\n・物価・地価関連データ……消費者物価指数、消費者態度指数、企業物価指数、企業向けサービス価格指数、WTI原油価格、地価\n・労働・人口関連データ……完全失業率、労働力人口、常用雇用指数、新規求人数、有効求人倍率、将来推計人口、住民基本台帳人口\n\n\n また、業種別にセグメンテーションを行う際には、業種特有の外部環境を考慮する必要があることから、次のとおり業種ごとに外部環境データの絞り込みを実施しました。\n\n\n＜業種別に用いた外部環境データ＞\n・製造業に使用する外部環境データ……鉱工業在庫指数、鉱工業出荷指数、製造工業生産能力指数、機械受注額（製造業）、業況判断指数（製造業）\n・卸売業に使用する外部環境データ……商業販売額、第3次産業活動指数、貨物輸送量、機械受注額（非製造業）、業況判断指数（非製造業）\n・宿泊業・飲食サービス業に使用する外部環境データ……訪日外客数、定員稼働率、実宿泊数、旅客輸送量、第3次産業活動指数、機械受注額（非製造業）、業況判断指数（非製造業）\n\n\n これらの外部環境データと、企業単位の属性データや財務データをAIモデルに読み込ませることで、1年以内に業績が悪化する可能性を「経営改善支援スコア」として数値化。そのスコアリングによって、担当者が直接認識していない場合であっても、経営改善支援の必要性が高いと考えられる先を可視化し、訪問の優先順位づけができるということです。\n\n また、仮に経営改善支援スコアはそこまで低くない場合であっても、原油価格上昇や為替レートなど特定の要因の影響度についてもスコア化することで、潜在的なリスクについても把握できる仕組みになっています。\n業況をAIで可視化、その表現方法\n原油価格や為替、金利など外部環境における変化が業績に及ぼす影響は、業態ごと、企業ごとに異なります。潜在的なリスクを含め、業況の展望を正確に予想することに広範な知識と経験、センスが求められますが、金融機関の人手不足が深刻化する中、すべての融資先の業況を把握しつづけることは難しいのが実情です。\n\n そこでこの業績悪化を予測するAIモデルスコアでは、必ずしも知識、経験が十分ではない若手職員にもわかりやすいよう、財務・外部環境別に要因を算出した上で、できるだけ直感的、視覚的に理解できる機能を盛り込みました。具体的には、次の機能を帳票の中に盛り込んでいます。\n\n\n\n・（1）冒頭に業況サマリーをコメントと業況天気図によって表現\n・（2）AIモデルスコアに寄与した要因を、財務、外部環境別に算出。同業種・同規模の企業と比べて、スコアが悪い要因がどこにあるのかの分析\n・（3）分析対象企業の業種に関する主要な外部環境変数のトレンドを確認し、当該企業の業界が置かれている外部要因を特定\n・（4）財務変数、外部環境変数のうち、AIモデルスコアを大きく向上させる変数を、向上させるために必要な変化の幅とともに算出\n\n\n\n 以下が企業ごとの業績予想を可視化した画面です。\n\n このようにAIモデルスコアを活用することで、多数の取引先を抱える金融機関の担当者でも業績悪化の可能性が高い先のリストを簡単に抽出し、訪問の優先順位付けを行えるようになることが期待されています。\nAIモデルで融資を判断するリスク\n今回のAIモデルは、一義的には融資の手前のプロセスを自動化するためのものです。とはいえAIによる支援の優先順位づけは、結果的にその後の融資判断にも影響を与える可能性が否めません。\n\n AIによる融資判断においては、不当な差別的扱いや誤解が増幅される懸念があります。報告書を取りまとめる過程で開かれた研究会でも、専門家から「数字が独り歩きするのは怖い」といった意見が挙がりました。また、スコアリングの妥当性や精度をいかに担保するかなどの課題も指摘されました。\n\n 実際にAIモデルを利用する場合、経営支援を受ける中小企業側からしてみれば、金融機関から受けるサポートにAIがどれだけ関わっているかは見えにくく、問題が気づかれないまま放置される事態も予想されます。\n\n 金融機関側においては、新たなシステムを適切に利用するため、AIの利用に伴う差別増幅などのリスクや、AIを利用する事業者としての責任の範囲について事前にしっかりと確認しておくことが求められそうです。\n執筆：堀尾大悟、執筆：金融ジャーナリスト 川辺 和将,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00139931-biz_plus-000-1-view.jpg?pri=l&w=640&h=297&exp=10800'],"['https://news.yahoo.co.jp/articles/d435017b221c795117390939b9fc2696e20d837d/images/000', 'https://www.sbbit.jp/article/fj/139931#image177631']"
金利上昇で日銀「債務超過」でも…問題ナシと言える？間違えてはいけない問題の本質（ビジネス＋IT）,https://news.yahoo.co.jp/articles/2c82049dce56a44cd3b1db5112db3c4ebd3dca8e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00141664-biz_plus-000-1-view.jpg?exp=10800,2024-06-06T07:00:05+09:00,2024-06-06T07:00:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,3193,"\n長期金利の上昇により日銀の財務体質悪化を懸念する声が上がっているが、それは問題の本質ではない（Photo：Muhammad Alimaki/Shutterstock.com）\n日本の長期金利がとうとう1％を超えた。市場の一部からは国債価格の下落によって日銀の財務体質の悪化を懸念する声が上がっている。たしかに金利が上昇すると日銀の財務は悪化するが、評価損の増大そのものは大きな問題ではなくなっている。\n【詳細な図や写真】債券市場では国債を売る動きが活発となっており、長期金利がジワジワと上昇しており、1％を超えている（Photo/Shutterstock.com）\n想定外の円安が状況を変えた\nこのところ債券市場では国債を売る動きが活発になっており、長期金利が上昇している（国債の価格が下がると金利は上昇し、国債の価格が上がると金利は下がるという関係が成立する）。金利が上昇しているのは、日銀が国債の金利を低く抑えるイールドカーブ・コントロール（YCC）と呼ばれる政策を今年3月に撤廃し、長期金利について市場に任せる方針を明確にしたからである。\n\n 本来、中央銀行というのは長期金利についてはコントロールの対象とせず、あくまで金融機関とのやり取りに関連する短期金利をコントロールすることをその責務としてきた。だが異次元の緩和策を実施するにあたっては、長期金利の制御が必須となり、国債の買い入れ額を調整することで意図的に長期金利を低く抑えるYCCと呼ばれる政策を導入し、それに伴って長期金利は長くゼロ近傍に張り付いていたままとなっていた。\n\n 日本経済は物価上昇が進んでおり、金利の動向を市場に任せれば、長期金利が上昇することはほぼ確実と言える。しかしながら、現時点の物価上昇率であれば、金利が短期間で急騰する可能性は低く、日銀としても、すぐに長期金利は上がらないという算段だったに違いない。\n\n だが、こうした状況を想定外の円安が変えつつある。\n\n 外国為替市場では急ピッチで円安が進んでいる。政府が2度の為替介入を実施したこともあり、1ドル＝160円手前で何とか押しとどめられているものの、今後も円安は進みやすい状況が続く。\n\n 円安が進むと輸入物価の上昇を通じて国内のインフレが激しくなるので、国内市場にとっては物価上昇圧力となる。長期金利は最終的には物価見通しと連動して動くことから、円安と物価上昇が進むという見立てが強くなれば、長期金利の上昇幅も大きくならざるを得ない。\n\n こうした状況から債券市場では国債を売る動きが活発となっており、長期金利がジワジワと上昇。とうとう1％を超えた。もともと日銀は秋の金融政策決定会合でゼロ金利を解除し、長期金利のさらなる上昇について一定程度容認し、金融正常化への道筋をつけるとともに、円安に対する防波堤にするつもりであった。\n簿価会計か時価会計なのは些末な問題に過ぎない\nだが、日銀の意図とは裏腹に、ゼロ金利解除前に長期金利は上昇を始めてしまった。これは何を意味しているのかというと、日銀の行動が市場を変えるのではなく、市場が先に動き、日銀の決断を逆に市場が促すという、いわゆる催促相場になっている可能性が高い。\n\n 日銀は秋にゼロ金利を解除する予定だったが、一部ではそれを前倒しするとの見方も出てきている。こうした状況になると、仮に利上げの前倒しが行われなかった場合、市場の失望を誘い、さらに国債の金利が上がって、より大規模な利上げが求められるという、日銀にとって好ましくないスパイラルに陥る可能性も出てきている。\n\n 市場の一部からは、金利の上昇に伴って日銀が保有する国債の価格が下がり、日銀の財務体質を悪化させているとの指摘が出ている。\n\n 国債の価格が下がれば、600兆円の国債を保有している日銀にとって理論上、巨額の含み損が発生する。日銀は現時点における国債の評価損は9兆4,337億円であるとしている。2024年3月期における日銀の純資産は約5.8兆円、債券の損失引当金は約7.0兆円なので、今のところ、損失額はこれらを足し合わせた自己資本を下回っている。だが、さらに金利が上がって債券価格が下落した場合には、日銀が実質的債務超過に陥る可能性は否定できない。\n\n だが筆者は、日銀の債務超過転落がすぐに深刻な問題を引き起こすとは考えていない。それは一部の論者が指摘するように日銀が簿価会計だからというテクニカルな理由ではない。\n\n 時価会計、簿価会計は財務諸表に記載する際の単なるルールの問題であって、時価会計であろうが簿価会計であろうが、市場は常に実勢価格で資産を評価する。したがって、簿価会計であることそのものがリスク回避の理由にはならない（これは財務会計の基礎知識がある人なら当然の認識である）。\n日銀「債務超過」でも…本当に問題ナシなのか？\nでは、なぜ日銀の財務は現時点では大丈夫なのかというと、政府の信用を背景に持つ日銀の信用度は一般的な民間企業とは比較にならないからである。\n\n 日銀は金利の上昇で巨額の含み損を抱えるが、日銀当座預金や日銀券の担保となっている資産勘定の多くは国債である。つまり国債が、日本円（あるいは日銀）の信用を担保しているという図式であり、政府の信用が失墜しない限り、多少債務超過であったとしても、「日本円に価値なし」として円を手放す人はそれほど多くないだろう。\n\n だが逆に言えば、日銀の信用が政府によって担保されている以上、政府の国債発行が過剰であり、返済能力に疑問符が付いた時点で、政府、日銀もろとも信用失墜を引き起こす。\n\n この手の話をすると、日本政府のCDS（クレジット・デフォルト・スワップ）の価格が低く推移しているので問題ないとの意見が必ずと言って良いほど出てくるのだが、これは完全に論点がズレている。日銀はいくらでも日本円を発行できるので、日銀が国債を引き受けている限り、政府の支払いが止まることはない。したがって、理屈上、日本政府はデフォルトなどするはずがない（デフォルトというのはあくまで支払いや返済が滞ったことを指す）。だが日本円の信用が下がれば、円安が加速するのはほぼ確実である。\n政府のデフォルトは重要じゃない？問題の本質とは？\n問題はデフォルトではなく、日本円の信用が低下し、際限のない円安が進むことである。\n\n 現在、為替市場では想定外とも言える円安が進んでいる。直接的な理由は日米の金利差だが、それだけでここまでの円安になるはずがない（実際、円安が始まった当初は、ほとんどの専門家が、1ドル＝120円は超えないと強く主張していた。150円を超える円安を当初から予想していたのは、筆者ら数名しかいなかったはずだ）。\n\n 一般的な予想を超えて円安になっている理由は、日銀による国債の過剰引き受けによって「日本円そのものの価値が棄損している」と多くの投資家が認識し始めたからである。\n\n 私たち国民がもっとも懸念すべきなのは、日本円の価値がどれだけ下がるのかであって、デフォルト云々といった政府の事務手続きについてではない。1ドル＝100円から150円に下がっただけで、これだけ生活が苦しくなった現実を考えれば、この影響がいかに深刻なのかは説明するまでもないだろう。\n\n 政府が国債を大量発行し、日銀が過剰にそれを引き受けているという現実は、すでに私たちの生活に相当な悪影響を及ぼしている。この問題の深刻さを考えた場合、日銀の実質的債務超過など大した話ではない。政府・日銀はできるだけ早く、正常化の道筋について市場に示す必要があるだろう。\n執筆：経済評論家 加谷 珪一",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00141664-biz_plus-000-1-view.jpg?pri=l&w=640&h=426&exp=10800'],"['https://news.yahoo.co.jp/articles/2c82049dce56a44cd3b1db5112db3c4ebd3dca8e/images/000', 'https://www.sbbit.jp/article/fj/141664#image178757']"
小規模言語モデル（SLM）とは？ マイクロソフトPhi-3やグーグルGammaは何を競うのか？（ビジネス＋IT）,https://news.yahoo.co.jp/articles/5e2b11307b27e9363bae3597f60b2e1af1bee0a8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00141119-biz_plus-000-1-view.jpg?exp=10800,2024-06-06T07:10:05+09:00,2024-06-06T07:10:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,4816,\n大規模言語モデル（LLM）だけでなく小規模言語モデル（SLM）も競争が激化（出典：グーグル）\n大規模言語モデル（LLM）の躍進と同様に、パラメータ数が少なく、コンパクトで効率的、高い適応性を備える小規模言語モデル（SLM：Small Language Model）の開発も進んでいる。マイクロソフトの「Phi-3」、グーグルの「Gemma」「Gemini 1.5 Flash」などに加え、スタートアップも多数、SLM開発に乗り出している。日本企業もNTTの「tsuzumi」、NEC「cotomi」などが（SLMとはうたわないながらも）小型・特化型に取り組んでおり、開発競争は激化の様相だ。SLMとは何か、SLMはLLMと何が違うのか。小規模言語モデルの開発状況を探ってみたい。\n小規模言語モデル（SLM）とは何か？メリットは？\n1ページ目を1分でまとめた動画\n\n\n\n 生成AI領域における言語モデルは今、いくつかの方向で開発が進められている。\n\n その1つは「大規模言語モデル（LLM）」の開発。大規模言語モデルは、生成AIの代名詞的な存在で、文字どおりサイズ（パラメータ数）が大きなモデルを指す。最近の例でいえば、GPT-4oやClaude 3 Opusなどが代表格といえるだろう。パラメータ数は公開されていないが、非常に大規模なモデルといわれており、パフォーマンスもかなり高いものとなっている。\n\n もう1つが、大規模言語モデルに比べ規模が小さな言語モデル（Small Language Model＝SLM）の開発だ。SLMとは、LLMよりもパラメータ数が少なく、よりコンパクトで効率的なAIモデルのことを指す。一般的にLLMが数百億から数千億のパラメータを有するのに対し、SLMは数億から数十億程度のパラメータで構成される。\n\n LLMは、テキストや画像、音声、動画など幅広いコンテンツを生成でき、さまざまなタスクに対応することが可能。対してSLMは、LLMほど多様なタスクはこなせないものの、特定の用途に特化させることで効率的に機能する。\n\n またSLMは、LLMに比べて計算リソースの消費を抑えつつ、高いパフォーマンスを発揮することが可能だ。用途に合わせてカスタマイズしやすく、オンプレミス環境での運用にも適しているとされる。\n\n SLMが注目される理由の1つに、LLMの開発・運用にかかる高コスト問題がある。LLMの学習には膨大なデータと計算リソース、長い時間を要するため、開発・運用だけでなく、利用するにも多大なコストが発生する。\n\n たとえば、LLMの開発には数千～数万台のGPUが用いられるが、SLMでは、100台ほどのGPUで開発されたケースや、軽量版は1GPU、超軽量版はCPUで高速に推論できると主張するケースもあり、コスト面でのメリットは大きい。\n\n さらにSLMは、少ないデータで学習可能で、プライバシーとセキュリティの向上につながる可能性もあるとされている。\n\n LLM間の性能差は急速に縮小しており、特定のタスクではトップモデル同士の差は最小傾向にある。Mixtral 8x7BやLlama 2-70Bなどの比較的小規模のモデルが、推論や多肢選択問題で大型モデルを上回る結果を示すなど、モデルのサイズが性能を決定する唯一の要因ではないことを示唆する事例が増えているのもSLMが注目される理由だ。\nNTTやNECも事実上のSLMをリリース\n昨年末ごろから海外勢の動きが活発化してきたが、日本国内でも（LLMをうたいつつも事実上のSLM開発の）取り組みが進んでいる。\n\n NTTは2024年3月、70億と6億の2種類のパラメータを持つ「tsuzumi」の提供を開始。NECも2024年4月末、130億のパラメータを持つ「cotomi」シリーズをリリースした。\n\n これらはLLMをうたいつつも軽量を強みとするSLMであり、ユーザー企業が自社で保有するオンプレミス環境での利用を想定し、機密情報の漏えいリスクを抑えつつ、効率的に生成AIを活用できるソリューションとして期待されている。\n\n HuggingFaceのクレム・ドゥラングCEOは、ユースケースの99％がSLMで対応可能であり、2024年はSLMの年になると予測するなど、国内外でさまざまなSLMが登場する見込みだ。\nSLM開発、マイクロソフトやグーグルらの動向とは\nSLM開発は、マイクロソフト、グーグル、アップルなどのテック大手に加え、スタートアップが多数参入する領域であり、2023年末ごろから開発競争激化の兆候が出ていた。2023年12月、グーグルがNanoモデルを含むGeminiシリーズを発表。5月20日にはGeminiファミリーの新しい軽量モデル「Gemini 1.5 Flash」を新たにリリースし、次世代オープンモデル「Gemma 2」なども投入している。\n\n さらにはマイクロソフトがPhi-3（38億パラメータ）を、Mistral AIがMixtral 8x7bやMistral-7Bをそれぞれリリースした。\n\n アップルもLLMの小型化において水面下で動いている。同社は2023年12月、「LLM in a flash」という論文を発表。iPhoneやMacBookといったメモリ制約のあるデバイスでLLMを動作させる手法が提案されている。\n\n モデルの一部をDRAMに、残りをフラッシュメモリに分散して格納し、必要に応じてDRAMとフラッシュメモリ間でモデルの重みを動的に入れ替えるというアプローチだ。これにより、メモリ使用量を大幅に減らしつつ、推論の遅延を最小限に抑えることができるという。\n\n さらにアップルは、それに先立ち、推論の計算量を最大3倍削減できるLLMアーキテクチャに関する論文も公開していた。オフラインでも高速かつ高品質のパフォーマンスを発揮するAI、これがアップルの生成AI戦略の要になっているとも言われる\n\n スタートアップの動きも活発化している。シリコンバレー拠点のH2O AIは2月29日にスマホやラップトップなど小型デバイス向けの超小規模言語モデル「Danube 1.8B」をリリースした。Danube 1.8Bは18億のパラメータを持ち、同規模のモデルと同等、あるいはそれを上回る性能を発揮したという。\n\n H2OのCEOによれば、Danube 1.8Bは「スマートフォンなどの小型デバイスで利用できるポータブルなLLM」。特にモバイル・オフラインアプリケーション向けに設計されており、小型かつ低コストのモバイルデバイスの普及に伴い、需要も高まることが予想されるという。\n\n 同じくシリコンバレーを本拠とするZyphraもSLM開発競争に参入した。同社は2024年4月16日、モバイルデバイスで動作する新しいSLM「Zamba」を発表。Zambaは、推論のコストを大幅に低減しつつ、モバイルデバイスへのAI統合を目指す、70億パラメータの小型ハイブリッドモデルだ。\n\n Zyphraのクリティック・プタラートCEOは、モバイルデバイスで動作するパーソナルAIの構築がZyphraの基本的なミッションだと語る。大手企業のAIはクラウドで一元管理された単一のモデルであるため、信頼を得にくい面があるという。対してZambaのようなSLMであれば、メモリ、パーソナライズ、ユーザーへの適応などにおいて優位性があると主張する。\n\n 同モデルのトレーニング期間は30日（128台のH100GPU）と非常に短いが、ベンチマークテストでは、LLaMA 1、LLaMA 2 7B、OLMo-7Bなどの他のオープンソースモデルを上回る性能を示している。\nグーグルが取り組む「Gemma」とは？\nグーグルも、SLMの開発に力を入れている企業の1つだ。同社は2024年2月、Geminiと同じアプローチを用いて構築された軽量の最先端オープンモデル「Gemma」を発表した。\n\n 6月には「Gemma 2」を発表。Gemmaには当初2種類あり、1つが20億パラメータのGemma 2B、もう1つは70億パラメータのGemma 7Bだったが、Gemma 2ではGemma 27Bが含まれた。このモデルはサイズの2倍を超える一部のモデルよりもパフォーマンスが優れていると主張する。\n\n いずれも、Google CloudのAIサービス「Vertex AI」のGPUや単一のTPUホスト上で効率的に動作するという。\n\n\n ただしLlama3 8Bが登場したことで、小規模言語モデルのリーダーボードはまた大きく変動したことには留意が必要だ。\n\n\n パラメータ数を抑えつつ、どこまで大型モデルに近いパフォーマンスを達成できるのか、現在も試行錯誤が続く。\n\n なお、グーグルは2024年4月11日に「RecurrentGemma」に関する研究結果を明らかにしていた。\n\n GPTモデルなどの主要大規模言語モデルは、Transformerというアーキテクチャのもと開発されている。Transformerは入力データ全体を一度に処理するため、大量のメモリと計算リソースを必要とするのが特徴で、これが大量のGPUが必要な理由となっている。\n\n これに対しRecurrentGemmaでは、Transformer以前の伝統的なリカレントニューラルネットワーク（RNN）の設計思想を取り入れることで、メモリと処理能力にかかる負荷を大幅に削減することに成功したという。RNNは、新しい入力データを処理する際、前の入力データの情報を保持する「隠れ状態」を持つのが特徴で、データを逐次的に処理するため、メモリ使用量を抑えられるアプローチだ。\n\n RecurrentGemmaのテクニカルレポートでは、Gemma 2B（20億パラメータ）とRecurrentGemma 2B（20億パラメータ）の比較がなされている。Gemma 2Bは3兆トークンのデータでトレーニングされている一方、RecurrentGemma 2Bは2兆トークンでトレーニングされた。トレーニング時のデータ量が多い方が、精度は上がることが予想されるが、RecurrentGemma 2Bはトレーニングデータが2/3の量であるにもかかわらず、Gemma 2Bとほぼ同じパフォーマンスを発揮することが確認された。つまり、より少ないデータで効率的に学習できるモデルであることが示されているのだ。\n\n また推論速度でもRecurrentGemmaの優位性が確認された。推論（出力）の際、トークン数にかかわらず、RecurrentGemmaは、Gemmaの2倍以上のスピードを達成したという。Gemmaがすでに他モデルに比べかなり速い推論速度を実現している点を鑑みると、RecurrentGemmaによるさらなる高速化は特筆に値する。\n\n 一方、NVIDIAのBlackwellはじめ、ハードウェアの進化も激しい中、SLMでなくとも、「大は小を兼ねる」とばかりにLLMに注目が集まっているのも事実だ。これに対してマイクロソフトなどはPhi-3をエッジ（PC端末）での活用を模索しているようにも見える。\n\n HuggingFaceのドゥラングCEOが予想したように、2024年は小規模モデルの年となるのか。メタ、グーグル、マイクロソフトなどの大手、そして日本企業の動向も含めて、今後の展開が気になるところだ。\n執筆：細谷 元,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240606-00141119-biz_plus-000-1-view.jpg?pri=l&w=640&h=266&exp=10800'],['https://news.yahoo.co.jp/articles/5e2b11307b27e9363bae3597f60b2e1af1bee0a8/images/000']
