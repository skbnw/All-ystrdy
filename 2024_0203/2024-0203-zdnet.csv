headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「ChatGPT」のGPTって何？--OpenAI言語モデルの違いをまとめて知る（ZDNET Japan）,https://news.yahoo.co.jp/articles/e1eb1ee7cf1ff357f83731d2aac3b06c4834e9a2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240203-35214713-zdnet-000-1-view.jpg?exp=10800,2024-02-03T08:30:00+09:00,2024-02-03T08:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3667,\n「ChatGPT」のGPTって何？--OpenAI言語モデルの違いをまとめて知るの画像\nOpenAIがその名を知られるようになったのは、AIチャットボット「ChatGPT」のおかげだ。今では、誰もがChatGPTのことを知っている。Pew Research Centerが先頃実施した調査によると、米国成人の約60％がChatGPTに精通しているという。しかし、ChatGPTを支える大規模言語モデル（LLM）について、読者の皆さんはどれだけご存じだろうか。\n\nGPTは何の略なのか\n\n ChatGPTの名前の最後の3文字は、名称を覚えやすくするためのものではなく、「Generative Pre-trained Transformer」（GPT）を表している。GPTは、OpenAIによって開発された大規模言語モデルファミリーであり、深層学習を使用して、人間が話しているような会話のテキストを生成する。\n\n これらのGPTは、ユーザーのテキスト入力を理解して、会話形式の出力を生成する自然言語処理能力を備えることから、AIチャットボットで使用されている。\n\n OpenAIのChatGPTの標準版は、「GPT-3.5」を利用してチャットボットを実現している。しかし、「ChatGPT Plus」では、OpenAIの言語モデルシステムのより高度なバージョンである「GPT-4」が使われている。OpenAI以外の企業が開発したほかのチャットボットでも、GPT LLMは使用されている。GPT-4を利用する「Microsoft Copilot」もその1つだ。\n\nGPT-3.5とはどんなものなのか?\n\n GPT-3.5は「GPT-3」の改良版で、自然言語のプロンプトを理解して出力できるほか、コードを生成することも可能だ。公開当初からOpenAIのChatGPTの無料版に搭載されているので、おそらく最も広く使用されているGPTモデルだろう。2023年3月にGPT-4が発表されるまでは、最先端のAIモデルとして君臨していた。\n\nGPT-3.5は無料で利用できるのか\n\n GPT-3.5はChatGPTの無料版に搭載されているので、無料でアクセスできる。\n\n「GPT-3.5 Turbo」とはどんなものなのか\n\n GPT-3.5 Turboは、「GPT-3.5」ファミリーに含まれる、より洗練されたバージョンであり、開発者はOpenAIのAPIを通して有料で利用することができる。プロンプトのコンテキストをより正確に理解し、より高品質の出力を生成することが可能だ。\n\n GPT-3.5 Turboには、「gpt-3.5-turbo-1106」「gpt-3.5-turbo」「gpt-3.5-turbo-16k」などのモデルがある。それぞれの違いは、コンテキストウィンドウと小規模なアップデートだ。開発者は自分のニーズに最適なモデルを選択できる。\n\nGPT-4とはどんなものなのか\n\n ChatGPTが2022年11月末に一般公開されてからほぼ4カ月後の米国時間2023年3月14日、OpenAIはGPT-4を発表した。\n\n このLLMは、OpenAIがこれまで発表してきた言語モデルシステムの中で最も先進的なバージョンだ。前のバージョンであるGPT-3.5は、2022年11月に公開されて爆発的な人気を博したChatGPTチャットボットに搭載されていた。\n\nGPT-4は何ができるのか\n\n GPT-4は大規模マルチモーダルモデル（マルチモーダルという部分が特に重要）であるため、テキストと画像の両方の入力を受け入れて、人間のようなテキストを出力することができる。\n\n 例えば、問題シートがアップロードされた場合、GPT-4はそれをスキャンして、問題の答えを出力できる。アップロードされたグラフを読み取った後、提示されたデータに基づいて計算を実行することも可能だ。\n\n このモデルでは、知的能力もさらに向上している。下のグラフを見ると分かるように、一連の模擬ベンチマークテストでGPT-3.5を上回る成績を記録した。\n\nGPT-4はどこで利用できるのか\n\n 月額20ドルのChatGPT Plusのサブスクリプションを購入すれば、GPT-4にアクセスできる。実際に料金を支払う前に、ChatGPT Plusを使用する場合でも、GPT-4には3時間に40メッセージまでという制限があることを理解しておくべきだ。\nGPT-4に無料でアクセスする方法もある。それは、Microsoft Copilotを使用することだ。\n\nMicrosoft Copilotとはどんなものなのか\n\n Copilot（以前は「Bing Chat」と呼ばれていた）はMicrosoftのAIチャットボットで、OpenAIの最も先進的なLLMであるGPT-4を搭載する。Copilotの公式ウェブサイトや「Edge」ウェブブラウザー内からアクセスできる。\n\n Copilotの人気が高いのは、月額20ドルのサブスクリプション料金を支払わなくても、インターネットへのアクセス、マルチモーダルプロンプト、情報元のリンクなど、ChatGPT Plusと同じ機能の多くを利用できるからだ。\n\nChatGPTは現在、どのモデルを使用しているのか\n\n ChatGPTが搭載しているのは、テキストによる入力と出力しかサポートしないGPT-3.5だ。\n\nGPT-4とGPT-3.5はどこが違うのか\n\n 両者の主な違いは、マルチモーダルのGPT-4がテキストに加えて画像の入力にも対応しているのに対し、GPT-3.5はテキストの入力しか処理できないことだ。\n\n OpenAIによると、GPT-3.5とGPT-4の違いは、カジュアルな会話では「微細なもの」であるという。しかし、上記のベンチマークテストでの優れた成績を見ても分かるように、GPT-4は信頼性や創造性だけでなく、知性でもGPT-3.5を上回っている。\n\nGPT-4でも誤った答えを返すことはあるのか\n\n ある。GPT-4には、過去のGPTモデルと同様の問題が発生する傾向がある。OpenAIはGPT-4について、「完全に信頼できるものではない（「ハルシネーション」を起こして事実を誤認したり、誤った推論をしたりする）」とさえ述べている。\n\n そうした警告を発した一方で、OpenAIはGPT-4のハルシネーションについて、過去のモデルよりも発生頻度が少なくなったとも述べている。OpenAIによると、社内の敵対的事実評価で、GPT-4はGPT-3.5よりも40％高いスコアを記録したという。下のグラフは、各モデルのスコアを表している。\n\n「GPT-4 Turbo」とはどんなものなのか\n\n GPT-4 Turboは現時点で、OpenAIの最新のモデルである。OpenAIによると、「より高性能で、2023年4月までの学習データを備えており、128kのコンテキストウィンドウ（1回のプロンプトで300ページ分のテキストに相当）をサポートする」という。GPT-4よりも低料金で利用可能で、API経由でのみアクセスできる。\n\n このモデルのもう1つの目玉は、画像のテキスト化（「GPT-4 Turbo with Vision」と呼ばれる）をサポートできることだ。GPT-4 Turbo with Visionは、GPT-4にアクセス可能なすべての開発者が利用できる。OpenAIは先頃、同社のこれまでで最も先進的なモデルとなる待望のモデルについて最新情報を発表し、一般提供を数カ月以内に開始する予定であることを明かした。\n\nこれらのGPTでAPIは利用できるのか\n\n これらすべてのGPTでAPIを利用できる\n\nGPT-3.5 Turboでは、入力が1000トークンあたり0.0010ドル、出力が1000トークンあたり0.0020ドルで利用できる。しかし、OpenAIは、入力を1000トークンあたり0.0005ドル、出力を1000トークンあたり0.0015ドルに値下げすることを発表した。それぞれ50％と25％の値下げとなる。\nGPT-4は、入力が1000トークンあたり0.03ドル、出力が1000トークンあたり0.06ドルで利用できる。\nGPT-4 TurboはAPI経由でのみ利用可能で、最も広範な機能群を備えている。利用料金はGPT-4よりも低く設定されており、入力が1000トークンあたり0.01ドル、出力が1000トークンあたり0.03ドルとなっている。\n\nこの記事は海外Red Ventures発の記事を朝日インタラクティブが日本向けに編集したものです。,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240203-35214713-zdnet-000-1-view.jpg?pri=l&w=640&h=480&exp=10800'],['https://news.yahoo.co.jp/articles/e1eb1ee7cf1ff357f83731d2aac3b06c4834e9a2/images/000']
