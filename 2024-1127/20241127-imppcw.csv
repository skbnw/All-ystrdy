headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
サンワサプライ、大型ルーターも収納可能な収納ボックス（PC Watch）,https://news.yahoo.co.jp/articles/05f3f2dfff61cfbe51f4f8741f1b14ad0e7b2e40,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000133-imppcw-000-1-view.jpg?exp=10800,2024-11-27T16:47:35+09:00,2024-11-27T16:47:35+09:00,PC Watch,imppcw,PC Watch,339,"写真：PC Watch サンワサプライは、充電ステーションにもなる木製のルーター収納ボックス「200-CB007L」を発売した。価格は7,480円。 【画像】大型ルーターも収納可能 下段にルーターを、上段に電源タップを収納できる木製のボックス。天板を互い違いにすればスマートフォンスタンドとしても利用できる。ケーブルを底面に引っ掛けられる溝を備える。 大型無線ルーターなども収納可能なサイズで、内部のケーブルフックに余剰ケーブルをまとめられる。正面にはマグネット式の扉があり、 設置した電源タップのスイッチ操作やメンテナンスも容易に行なえる。 本体サイズは、500×145×450mm、 重量は4.12kg。カラーはダークブラウンとホワイトの2色。 PC Watch,稲津 定晃",[],[]
米国政府からIntelへの助成金が約1.2兆円に（PC Watch）,https://news.yahoo.co.jp/articles/0db58957560c8b60026c018b600efd53b2a70b91,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000123-imppcw-000-1-view.jpg?exp=10800,2024-11-27T15:58:21+09:00,2024-11-27T15:58:21+09:00,PC Watch,imppcw,PC Watch,406,"写真：PC Watch 米Intelは26日(現地時間)、米CHIPSおよび科学法に基づき、商務省から最大78億6,000万ドル(約1兆2,000億円)の助成金を受け取ることに合意したと発表した。 助成金はIntelの商用半導体製造プロジェクトの一環として、アリゾナ州、ニューメキシコ州、オハイオ州、オレゴン州の拠点において重要な半導体製造および先進パッケージングプロジェクトを推進するために使われる。 Intelはまた、1,000億ドルを超える投資の最大25%に相当する税控除を米国財務省に申請した。これにより、1万人以上の直接雇用、約2万人の建設関連雇用、5万人を超えるサプライヤー/サポートといった間接雇用を生み出す。 投資により、米国のサプライチェーンを強化するとともに、米国を拠点とする研究開発の促進、最先端半導体製造と技術力における米国のリーダーシップを確保するとしている。 PC Watch,劉 尭",[],[]
Club 3D、80Gbps/240W給電対応のUSB4 Version 2.0ケーブル（PC Watch）,https://news.yahoo.co.jp/articles/8ebbb9477c5c9139ab0e62041545d5f8d30b8404,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000118-imppcw-000-1-view.jpg?exp=10800,2024-11-27T15:27:35+09:00,2024-11-27T15:27:35+09:00,PC Watch,imppcw,PC Watch,330,"写真：PC Watch Click-Importは、Club 3Dの最大80Gbpsの転送速度と最大240Wの給電に対応するUSB4 Version 2.0ケーブル「CAC-1570」を発売した。実売価格は4,980円。 USB-IFの正規認証品で、最大80Gbpsのデータ転送に加え、8K/240Hzの映像伝送、240W(48V/5A)のUSB PD EPR(Extended Power Range)給電をサポートする。ニッケルメッキコネクタにより1万回以上の挿抜に耐え、シールド同軸ワイヤーでEMI保護を強化した。耐久性のあるハロゲンフリーのTPEジャケットはRoHSに準拠している。 ケーブル長は1.2m、重量は約45g。 PC Watch,稲津 定晃",[],[]
電子機器の天敵！の静電気を抑制する“導電チェア”（PC Watch）,https://news.yahoo.co.jp/articles/8b4c578651a7df73e2004f0fe1a0eb00804d0de2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000101-imppcw-000-1-view.jpg?exp=10800,2024-11-27T14:20:27+09:00,2024-11-27T14:20:27+09:00,PC Watch,imppcw,PC Watch,370,"写真：PC Watch サンワサプライは、作業者のアース経路を確保して静電気の発生を抑制する導電チェア「SNC-D33」を発売した。受注生産商品で、価格は9万7,680円。 【画像】使用イメージ 背もたれと座面に導電ビニールレザーを採用し、作業者のアース経路を確保することで、人体への静電気蓄積を最小限にする椅子。ステンレスフレークを含有したウレタン製双輪キャスターを採用し、導電性を高めている。座高はレバー1本で420mmから500mmの間で調整可能。背もたれにはロッキング機能付きで、リラックス姿勢をとりやすい。 電子部品製造工場、精密機器組立ライン、クリーンルームなど、静電気に敏感な作業環境での使用に最適としている。 本体サイズは570×570×785～865mm、重量は約12.2kg。色はブラック。 PC Watch,稲津 定晃",[],[]
サンワサプライ、高さや角度を自由に変えられるマイクアームスタンド（PC Watch）,https://news.yahoo.co.jp/articles/d5151c27625d9574a49ad337569b0a703651d111,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000095-imppcw-000-1-view.jpg?exp=10800,2024-11-27T13:55:29+09:00,2024-11-27T13:55:29+09:00,PC Watch,imppcw,PC Watch,489,"写真：PC Watch サンワサプライは、高さや角度を自由に調整できるマイクアームスタンド2製品を発売した。ロープロファイル対応の「100-MCST001」と、フレキシブルアームの「100-MCST002」を用意し、価格はそれぞれ7,480円、5,980円。 【画像】モニター下にアームを通すこともできる どちらもクランプまたはグロメットによる設置が可能なマイクアームスタンド。話しやすい位置にマイクの角度や高さを調整できる。3/8インチ、5/8インチ、1/4インチねじに対応するアダプタが付属し、さまざまなマイクの装着をサポートしている。アーム部にはケーブルカバーも備える。 100-MCST001は、モニター下など低い位置にもアームを通せるロープロファイル対応タイプ。本体サイズは約70×483～755×144～706mm、重量は約1.6kg。耐荷重は最大2kg。 100-MCST002は、モニター上からマイクを引き出すこともできるフレキシブルアームタイプ。本体サイズは約60×359×890mm、重量は約1.6kg。耐荷重は0.2～1kg。 PC Watch,宇都宮 充",[],[]
Teclast、14型ディスプレイ搭載のAndroidタブレット（PC Watch）,https://news.yahoo.co.jp/articles/abd0511b47c2948cf1897f6190c63663f8beb7bb,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000091-imppcw-000-1-view.jpg?exp=10800,2024-11-27T13:35:21+09:00,2024-11-27T13:35:21+09:00,PC Watch,imppcw,PC Watch,424,"写真：PC Watch Teclastは、14型IPSディスプレイを搭載したAndroidタブレット「T70」を発売した。価格は4万6,900円だが、Amazonではセールを実施しており、3万9,920円にて購入できる。 T70は、MediaTek Helio-G99を搭載した14型Androidタブレット。メモリは8GBを内蔵し、合計最大20GBの拡張メモリ機能も用意する。ストレージは256GBで、microSDカードスロットも備える。ディスプレイは1,920×1,200ドットIPSで、色やコントラストをインテリジェントに向上させる独自のカラー最適化技術T-Colour 4.0も装備する。 Widevine L1もサポートしており、動画配信サービスの視聴にも好適とする。カメラは背面が1,300万画素、前面が800万画素、OSはAndroid 14。 本体サイズは325×214×8.6mm、重量は960g。 PC Watch,宇都宮 充",[],[]
マウス、65W USB PDアダプタが付属する14型モバイルノート（PC Watch）,https://news.yahoo.co.jp/articles/fe7c02cdb2a2eddee174c64954726bc39d031380,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000081-imppcw-000-1-view.jpg?exp=10800,2024-11-27T12:39:28+09:00,2024-11-27T12:39:28+09:00,PC Watch,imppcw,PC Watch,1082,"写真：PC Watch マウスコンピューターは、65WのUSB PDアダプタが付属した14型ノートPC「mouse B4」を発売した。 「mouse F4」シリーズの後継にあたる製品。65W対応のUSB PD対応ACアダプタを添付し、従来のACアダプタと比較して約100gの軽量化を実現。アルミニウム製筐体を採用し、従来のオリーブブラック/シャンパンゴールドの2色展開からシルバー1色となった。また、オプションでUSB Type-C接続のドッキングステーションも用意した。 Webカメラにはシャッター機能を搭載し、セキュリティに配慮。キーボードにはCopilotをワンタッチで起動できるCopilotキーも装備する。さらに、CPUの強化により、静音モード時のCinebench R23スコアが約13%向上した(Core i7-1260P対Core i7-1355Uの比較)という。 機能面では性能を切り替えられる「Control Center」を備えるほか、「バッテリーマネージャー」アプリから、充電停止を50%/75%/100%の3段階に切り替え、バッテリの寿命を延長できる。 一例として「mouse B4-I5U01SR-A」は、CPUにCore i5-1335U、メモリ16GB、256GB NVMe SSD、1,920×1,200ドット表示対応14型液晶ディスプレイ、OSにWindows 11 Homeを搭載し、価格は12万9,800円。Office 2024搭載モデルは15万7,300円。メモリを32GBに強化したモデルは差額+1万円。 「mouse B4-I7U01SR-A」は、CPUにCore i7-1355U、メモリ16GB、500GB NVMe SSD、1,920×1,200ドット表示対応14型液晶ディスプレイ、OSにWindows 11 Homeを搭載し、価格は13万9,800円。Office 2024搭載モデルは16万7,300円。メモリ32GB/ストレージ1TBに強化したモデルは差額+3万円。 インターフェイスは共通で、USB 3.2 Gen 2 Type-C 1基、USB 3.2 Gen 1 2基、USB 2.0 1基、Wi-Fi 6E、Bluetooth 5、Gigabit Ethernet、200万画素/Windows Hello対応Webカメラ、音声入出力などを備える。 バッテリはリチウムポリマーで、駆動時間は約6時間。本体サイズは311×239.3×19.6mm、重量は約1.41kg。 PC Watch,劉 尭",[],[]
横揺れ軽減機構を備えたコンパクトなPCデスク（PC Watch）,https://news.yahoo.co.jp/articles/c463b52ea9708d1dbcc0dff33c5dce772ffa85ed,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000080-imppcw-000-1-view.jpg?exp=10800,2024-11-27T12:37:42+09:00,2024-11-27T12:37:42+09:00,PC Watch,imppcw,PC Watch,377,"写真：PC Watch ACROVEはSun Ruckブランドから、幅80cmとコンパクトなPCデスク「SR-OD74-WWD」および「SR-OD74-BK」を発売した。カラーは前者がホワイトウッド、後者がブラックで、価格はどちらも7,980円。Amazonでは12月6日までは発売記念キャンペーンでクーポンを配布しており、6,480円にて購入できる。 【画像】SR-OD74-BK 80×60cmの天板を備えたコンパクトなPCデスク。ビジネスやゲーム、作業台のほか、補助机としても活用できるとする。天板には汚れに強く耐久性に優れたメラミン樹脂を採用し、横揺れを軽減するバックフレームも装備。床面にあわせて微調整できるアジャスターも脚部に備える。 本体サイズは約80×60×70cm、重量は約8.7kg。耐荷重は約30kg。 PC Watch,宇都宮 充",[],[]
プロゲーミングチーム「Crazy Raccoon」のポテチが発売。描き起こしイラストステッカー付き（PC Watch）,https://news.yahoo.co.jp/articles/1f4a4b2993be4f690194a6b89c7621677dbbf350,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000064-imppcw-000-1-view.jpg?exp=10800,2024-11-27T11:50:43+09:00,2024-11-27T11:50:43+09:00,PC Watch,imppcw,PC Watch,415,"写真：PC Watch プロゲーミングチームCrazy Raccoonのポテトチップス「Crazy Raccoonチップス」が全国のファミリマートおよびCyber Goods Storeで販売開始された。チップスの内容量は23g。 【この記事に関する別の画像を見る】 Cyber Goods Storeは12袋入りボックスのみの販売で、価格は3,036円だが、現在在庫切れ。1ケース購入ごとに限定特典の缶バッジを1個プレゼントする。 チップスには、イラストレータlackさんが描き起こしたイラストのステッカーが1枚添付する。イラストは全38種類で、ノーマル32種、レア5種、シークレット1種類。 販売開始を記念し、12月3日まで公式X(旧Twitter)アカウントをフォローし、ハッシュタグ #CRチップスをつけて該当ポストを引用ポストすると 、抽選で3名にステッカーコンプリートセットをプレゼントする。 PC Watch,劉 尭",[],[]
TURTLE BEACH、長時間駆動対応の大容量バッテリ搭載ゲーミングマウス（PC Watch）,https://news.yahoo.co.jp/articles/8a88e333abcb3859e5cb600ab01b8a71e583a91d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000055-imppcw-000-1-view.jpg?exp=10800,2024-11-27T11:24:35+09:00,2024-11-27T11:24:35+09:00,PC Watch,imppcw,PC Watch,731,"写真：PC Watch SB C&Sは、VOYETRA TURTLE BEACHブランドのゲーミングマウス「Kone II Air」および「Kone II」を11月29日に発売する。価格はオープンプライスで、実売予想価格は前者が2万2,882円前後、後者が1万2,982円前後の見込み。 【画像】Kone II Air Kone II AirはBluetooth/2.4GHz無線/USB有線接続対応、Kone IIはUSB有線接続対応のモデル。いずれもさまざまな握り方に対応した人間工学デザインや、1億回のクリック寿命を実現したTITAN光学式スイッチを採用する。 ホイールはチルトやフリースピンスクロールに対応。また、本体に7基のボタンを装備し、指定のボタンを押下しながらのボタン/ホイール操作で機能が切り替わる「Easy-Shift［+］」機能により、最大21種類の機能を割り当てられる。 解像度が50～26,000dpiで、速度650IPS、加速度50G、リフトオフディスタンス調節をサポートする「Owl-Eyeセンサー」を採用。マルチゾーンのRGBライティングを備え、アプリ「Swarm II」で変更できる。ポーリングレートは1,000Hz。いずれも本体色はブラックとホワイトの2種類が用意される。 Kone II Airは大容量バッテリの搭載を特徴としており、Bluetooth接続時では最長350時間、2.4GHz無線接続時では最長130時間の駆動が可能。本体サイズは82.6×130.2×44.1mm、重量は110g。 Kone IIのケーブル長は1.8m。本体サイズは82.6×130.2×43.6mm、重量は90g。 PC Watch,劉 尭",[],[]
世の中がAIを受け入れられるようになるまで、レノボはどんなことを考えているのか（PC Watch）,https://news.yahoo.co.jp/articles/6909be9f528a88bdbd17a399c1777cd5a6d2854f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000022-imppcw-000-1-view.jpg?exp=10800,2024-11-27T06:16:35+09:00,2024-11-27T06:16:35+09:00,PC Watch,imppcw,PC Watch,2429,"写真：PC Watch レノボ・ジャパンは26日、都内で「Lenovo Tech World Japan 2024」と題したプライベートイベントを開催し、顧客やパートナー向けに同社の取り組みや戦略、最新ソリューションを紹介。イベントの冒頭で、レノボ・ジャパンの代表取締役社長 檜山太郎氏が基調講演を行ない、AIを取り巻く現状や同社の取り組みなどについて語った。 【画像】檜山太郎氏 檜山氏によれば、今の時代は既にAIの導入を検討する時代から、活用する時代へと変化していく中で、レノボは「Smarter AI for all」というスローガンを掲げ、あらゆるユーザーに対してAI技術を届けて活用してもらうことを目指しているという。 そのため、1,500億円にのぼるAI技術への投資を行なっており、グローバルにおいてAIのインフラストラクチャプライバイダーとして3位の地位を築いた。また、80以上のAIプラットフォームの用意、4カ所のイノベーションセンター、165以上のAIスタートアップ支援プログラムなど、AIに対してあらゆる手段でさまざまな投資を行なっている段階にある。 しかしながらこうした積極的な投資を行なっているAIは、すぐさま社会やユーザーに受け入れられるわけではない。檜山氏は、同じAI技術である自動車の自動運転について例を挙げた。 「自動運転ではレベル1からレベル5まで、段階的にAIを導入している。一番低いレベルはドライバーの運転支援からスタートし、やがては限定領域での自動運転、ドライバーありの自動運転、最終的にはドライバーなしの自動運転を実現する。こうして段階を踏むのは、ユーザー側の準備、提供する側の準備、そして法整備、保険制度などが段階的に展開されていくからだ。段階的な展開がなければ、ユーザーの信用を勝ち取れない」。 一方でコンピューティングにおけるAIレベルの分け方だが、現在実現している、特定業務支援の“レベル1～2”から、よりパーソナルなものになっていくことを目指し(レベル3)、その先に汎用的な知能(レベル5)があるのではないか、と位置づける。そしてこのパーソナル化こそが、コンピュータが登場して以来の大きな転換点だとも語る。というのも、これまでは「人がコンピュータを使いこなす必要があった」が、「AIがあらゆる環境で活用してもらうためにはコンピュータが人に寄り添う形に変わっていかなければならない」ためだとする。 レベル3に相当するAIのパーソナル化とはどんなものなのか。「たとえばAIが今日のスケジュールに応じて目覚ましを勝手にセットしてくれる。朝食を作っていると、夜中に来たメールが何通で、そのうち重要なものは何通、対応すべきメールは何通を提示してくれて、その対応すべきメールも、自分の代わりに文面を考えファイルで資料を揃えて、後はメールを送信するかどうかを尋ねてくるだけ……というような“パーソナルツイン(双子)”の実現ではないか」と檜山氏は想像している。 ただ、もちろんこうしたパーソナルツインの実現に賛成だとする意見もあれば、「それが今やってる仕事だ！」とユーザーが反発する意見があるかもしれない。しかし、実現すべきパーソナルツインの姿をユーザーの声とともに探っていくのが現段階のAI開発であり、ユーザーの信用を勝ち取れるAIの実現が、今後開発の焦点になっていくだろうと語った。 ■ では、現時点でレノボが提供できるAIとは？ レベル3に相当するパーソナル化されたAIとまでは行かないが、それに近いところとして、「AI Now」と呼ばれる独自のローカルAIソフトウェアを紹介した。これはチャットボットのような形で、ローカルのPCに入っているデータなどから、ユーザーが必要としている情報を抜き出すもの。AIとチャットをすることで、今日のスケジュールの概要や、資料作成に必要なデータの収集、そのデータのサマライズなどが行なえる。現時点では英語版のみで、日本国内での展開は未定とのことだが、ローカライズを行なう強い意志は伺えた。 また、AIの活用はローカルのPCだけでなく、エッジやクラウドといったインフラの整備も必要で、その際の電力消費や環境負荷も課題となっている。レノボとしては「Neptune」という2012年頃から開発している水冷技術をサーバーに用いることで、空冷の3.5倍もの冷却効率を実現。空冷と比較して冷却にかかる消費電力を4割ほど削減できるため、環境負荷を軽減できるとした。 さらに、デバイスを使った分だけ支払うDaaS(Device as a Service)の「TruScale」の展開や、サーバーからスマートフォンに至るまで、エンドツーエンドのソリューションを取り揃えている点も、他社に対するレノボの強みであると語った。 ところで、レノボではこうしたAI関連のソリューションを多数揃えているし、企業のCIO(最高情報責任者)からもAIについて認められつつあるが、株主らが求めているのはROI(投資利益率)の実証であり、これがAIの導入の障壁になるケースも多い。 そこでレノボでは「AIファストスタート」というプランを用意。これは、レノボがユーザーのデータを駆使してPoC(概念実証)の組み立てからわずか90日以内で本番で運用できるレベルにまでAIを作り、利益を上げることをできるようにするというもの。パートナーの既存のエコシステム(固有の機能を持つ、実証済み/テスト済みのAI)を駆使して実装することで迅速な実現を可能とした。 実際のAIファストスタートの例としては、SAPオフィスにおけるAIヒューマンの実現や、F1のストリーミング映像のAIによる高画質化/自動カメラ切り替えなどを挙げ、企業が“AIの旅”のどの段階にいても、レノボが迅速に支援できることをアピールした。 PC Watch,劉 尭",[],[]
M4 Max搭載「MacBook Pro 14」のメモリ128GBをLLMでほぼ使い切ってみた！（PC Watch）,https://news.yahoo.co.jp/articles/8fc73ffc7945dfe71f548de06392785c3600cd39,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20241127-00000021-imppcw-000-1-view.jpg?exp=10800,2024-11-27T06:15:19+09:00,2024-11-27T06:15:19+09:00,PC Watch,imppcw,PC Watch,8152,"写真：PC Watch 前回はM4 Max/ユニファイドメモリ128GB搭載MacBook Pro 14の製品紹介とベンチマークテスト中心だったが、今回は(まだ模索中だが)ユニファイドメモリ128GBの使い道を具体的に紹介したいと思う。 【画像】LLM RAM CALCULATOR。4bit / 24GBの場合、41.95B ■ Apple Siliconと生成AI画像について 本論へ入る前にXでもコメントがあったので、Apple Siliconと画像生成AIについて述べておこう。前編の最後触れているが、M4 Maxに限らずApple Siliconは画像生成AI(動画も)が苦手だ。 理由としては、GeForceのように高いクロックで回せない、ライブラリが最適化されていないなどいろいろ挙げられる。従ってMac上で生成AI画を高速化するには外付けGPU=dGPUを接続可能にするしか現状手がないものの、物理的に接続できても、ドライバを含めて、ソフトウェア的な環境が揃わないとうまく行かない。この辺りAppleはどう考えているのか聞きたいところだ。 とは言え、ローカルで生成AI画像環境作っても、筆者のようにろくなものしか出力しないので、同社が嫌がってるという話があるとかないとか(笑)。近々クラウドに思いっきり検閲ありの生成AI画像環境用意するから、それを使って……となるかも！？ いずれにしてもGeForce RTX 4090ですら8秒かかるFLUX.1 [dev]をMacで……というのは到底無理。どうしてもであればSDXLやStable Diffusion 3.5 Large Turboなど、比較的生成が速いのを使うことをお勧めしたい。それでも1枚10～20秒かかるのだが……。 ■ MacとLLMについての余談 上記のような理由から、128GBメモリを活用する本命はLLMとなる。もちろん数B(illion)程度ならほかのGPU環境でも動くが、100B前後になると、何をしてもご家庭用Windows PC/GPUではまず動かない。その夢を叶えるのが、128GB搭載MacBook Pro 14と言うわけだ。個人的に動かしたいのは以下の辺りだろうか！？ ・Qwen/Qwen2.5-72B-Instruct ・meta-llama/Meta-Llama-3.1-70B-Instruct ・deepseek-ai/DeepSeek-V2.5 (238B) ここにちょっと面白いサイトがあって、メモリ容量と量子化ビット数を指定すると何BのLLMが動くか？簡単な計算ツールとなっている。これによれば、ざっくり4bit量子化で24GBだと41.95Bまで。GeForce RTX 5090は32GBと噂されているが、それでも57.95Bだ。つまり、1bitや2bitなど思いっきり精度落とすのはなしとした場合、上記はどう頑張っても家庭用GPUでは動かない。 ただしチャットするだけなら、HuggingChatを使えばことは足りる。執筆時、対応しているのは、 ・Qwen/Qwen2.5-72B-Instruct ・meta-llama/Meta-Llama-3.1-70B-Instruct ・CohereForAI/c4ai-command-r-plus-08-2024 ・nvidia/Llama-3.1-Nemotron-70B-Instruct-HF ・Qwen/Qwen2.5-Coder-32B-Instruct ・meta-llama/Llama-3.2-11B-Vision-Instruct ・NousResearch/Hermes-3-Llama-3.1-8B ・mistralai/Mistral-Nemo-Instruct-2407 ・microsoft/Phi-3.5-mini-instruct と、結構有名どころが並んでいる。加えて少し前にツールが追加され、Web検索や画像生成、PDFパーサーなど数多くが登録され勝手も向上。これが無料なのだから試さない手はない。 LLM目的で大容量VRAM搭載GPU(もしくはユニファイドメモリ)を考えている方はまずこれでいろいろ遊んでほしい。70Bクラスでどの程度使えるか？分かるはずだ。 ■ mlx_lmとLM Studio さてここから本論なのだが、OS起動直後と筆者の標準的な環境を起動(PhotoshopやDockerなどは含まず)した後のメモリ状態を見ると以下のような感じだ。 OS起動直後で14.1GB、筆者の環境を起動すると28.5GB。PhotoshopやDockerが加わるので、やはり最低32GBは欲しいところ。これをベースにLLMなどをロードすることになる。 以降、システムモニタは「asitop」を使用する。ご覧の様にE-CPU / P-CPU / GPU / Memory / Powerが一目瞭然で分かるモニタリングアプリだ。インストールと実行は簡単！ % pip install asitop % sudo asitop これでOK。刻一刻と状態が変わるのをモニタリングできる。 次にLLMの簡易チャットとしてmlx_lmを試してみた。名前の通りAppleのMLX対応となる。インストールは % pip install mlx % pip install mlx_lm これだけ。実行は以下の通り。 % mlx_lm.generate --prompt ""Create a Python program to create a snake game"" --model Qwen/Qwen2.5-Coder-32B-Instruct --max-tokens 8000 該当するモデルが「~/.cache/huggingface/hub」にない場合は自動的にダウンロードが始まる。huggingfaceにログインしないとダウンロードできないものもあるため、huggingface-cli loginを使い事前にログインを済ませておいた方が無難だ。 MLX非対応のQwen2.5-Coder-32B-Instructをまんま実行した場合。 % mlx_lm.generate --prompt ""Create a Python program to create a snake game"" --model Qwen/Qwen2.5-Coder-32B-Instruct --max-tokens 8000 Prompt: 38 tokens, 55.439 tokens-per-sec Generation: 1177 tokens, 7.401 tokens-per-sec Peak memory: 65.875 GB 次にMLX対応のmlx-community/Qwen2.5-Coder-32B-Instruct-6bitを実行した場合。 % mlx_lm.generate --prompt ""Create a Python program to create a snake game"" --model mlx-community/Qwen2.5-Coder-32B-Instruct-6bit --max-tokens 8000 Prompt: 38 tokens, 71.576 tokens-per-sec Generation: 1181 tokens, 16.480 tokens-per-sec Peak memory: 26.975 GB 6bit化しているので単純比較でないが、速度もメモリ使用量も全然違うことが分かる。mlx-communityには、MLX化したモデルが1,077登録されており(執筆時)、Apple Siliconユーザーにとってありがたい存在になってる。 mlx_lm.generate --prompt ""Create a Python program for quicksort. Explanation is in Japanese"" --model mlx-community/Qwen2.5-Coder-32B-Instruct-6bit --max-tokens 4000 mlx_lmコマンドは、サーバーモードもあり、mlx_lm.server --model ＜path_to_model_or_hf_repo＞ とすれば、http://localhost:8080/v1でOpenAI API互換となる。ただ後述するVSCodeのExtensionがうまく動かなかったので、サーバーモードは何か不都合があるのかも知れない。 次はお馴染みLM Studio。GUIで使いやすいこともあり、以降はこちらがベースになっている。 筆者が日頃使うのは ・qwen2.5-coder-32b-instruct-q4_0.gguf ※ もしくはmlx-community/Qwen2.5-Coder-32B-Instruct-4bit | -8bit。模索中 ・Tiger-Gemma-9B-v3-Q4_K_M.gguf この2つ。前者はプログラミング用、後者は生成AI画像のPrompt用となる。また設定しているコンテキスト長は8Kと4K。 Qwen2.5は128Kまで対応しているものの、さすがにそこまでするとメモリを食い遅くなる。加えて筆者の用途的にせいぜいファンクションの骨組み+α程度。8Kあれば特に問題はない。 Tiger-Gemma-9B-v3はGemmaの非検閲改造版なので、LM Studio / Server / OpenAI API経由で、Open WebUIを使いPromptの生成、確認をComfyUI APIで画像生成と言うコンビネーションで使用。 Open WebUIは、画像生成だけでなく、RAGやPipelines Plugin Frameworkなどにも対応しており、かなり本格的に利用できる。 この2つをロードした状態でメモリは約半分使用。まだ半分残っている(笑)。 ■ VSCodeのExtension、ContinueとCline 前置きが長くなってしまったが、ここからが本命！VSCodeの拡張(Extension)、「Continue」と「Cline」を使った例となる。どちらもLM StudioのServer / OpenAI API経由でqwen2.5-coder-32b-instruct-q4_0.ggufを使用している(もしくはMLX対応版)。 Continueは、プログラミング支援的な機能を持ち、例えばあるコードを開き”このコードは何をしていますか？”と聞くと以下の動画となる。 “このスクリプトは、ユーザーが画像をアップロードすると、その画像からキャプションを生成し表示する単純なウェブアプリケーションを作成します。” という回答が出たが、正解。このコードはJoyCaptionと呼ばれるVLLMをGradioで作動させるコードだ。 次にCUDA用に書かれているのでMacで作動するよう、CPU用に書き換える。基本CUDAの部分をCPUへ、bfloat16はないのでfloat32へとなる(速度的に後でfloat16へ変更)。 うまく動くか？実行してみる。 出力結果 woman standing indoors, possibly in an office or modern living room. The woman has long, straight black hair that falls just past her shoulders, and she has a fair complexion with a light dusting of makeup, including pink blush and subtle eyeliner. She is wearing a black blazer over a white collared shirt, giving her a professional appearance. In the foreground, she holds a black rectangular sign with white text that reads ""PC Watch"" in a casual, handwritten style. Her expression is neutral, with a slight smile, and she gazes directly at the camera, creating a sense of engagement with the viewer. The background is softly blurred but suggests a modern, minimalist setting with large floor-to-ceiling windows on the left side of the image. Through the windows, a blurred view of greenery and a car outside can be seen, indicating a possibly urban or suburban location. A potted plant with large green leaves is visible on the right side of the image, adding a touch of nature to the otherwise sleek and contemporary environment. The lighting is natural, suggesting the photograph was taken during the day. 翻訳(Google翻訳) おそらくオフィスかモダンなリビングルームの屋内に立つ女性。女性は、肩を少し超えるくらいの長くて真っ直ぐな黒髪をしており、ピンクのチークや繊細なアイライナーなど、軽くメイクを落とした色白の肌をしています。彼女は白い襟付きシャツの上に黒いブレザーを着ており、プロフェッショナルな印象を与えています。 前景で、彼女はカジュアルな手書きスタイルで「PC Watch」と白い文字で書かれた黒い長方形の看板を持っています。彼女の表情は、ほんのり微笑みを浮かべたニュートラルで、カメラをまっすぐに見つめており、見る者との関わりを感じさせます。 背景は柔らかくぼかされていますが、画像の左側に床から天井までの大きな窓があるモダンでミニマルな環境を示唆しています。窓を通して、ぼやけた緑と外の車が見え、おそらく都市部または郊外の場所であることがわかります。画像の右側には大きな緑の葉を持つ鉢植えが見え、洗練された現代的な環境に自然のタッチを加えています。照明は自然であり、写真が日中に撮影されたことを示唆しています。 コード変換にしてもJoyCaption実行にしても、もう少し速く動いて欲しいところだが、GPUコア40基だとこの程度なのだろう。実際はこんな長いコードを扱わず、ファンクションの雛形を作る程度なので、それほど速度面は気にならない。 その後、Apple Silicon用のPyTorchをインストールし、cpuをmpsへ変更、実行したところ13秒ほどになった。 pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu 次はCline。これは最近流行りのtask型。コードを生成し、実行までできる。ある意味、夢の環境だ(笑)。 今回はpythonでquick sortのコードを生成、ファイルへ保存、そして実行してみる。以下の動画をご覧いただきたい。 動きを見ていると分かると思うが、保存や実行時などには確認が入るので、人間が判断する。実行結果はもちろんOKだった。 さて、こうなるとプログラマー不要論にすぐなるが、それは違う。ContinueにしてもClineにしても、実用的なコードをAIに作ってもらうには、仕様を整理しPromptにしなければならない。つまりプログラムが分かってないと指示できないのだ。 ネットなどでプログラムしたことない人でもできた！的なのを見かけるが、コードで何をしているのか分からない状態でたまたま動いている的な感じだろう。趣味ならいいが、仕事では怖くて使えないコードとなる。 いずれにしても現状のAIは指示するのも確認/実行するのも人間の役目。つまりプログラマー不要ではなく、より熟練されたプログラマーが必要になるのでは？と筆者は思っている。 以上のように、VSCodeと組み合わせて使えば便利なAI系ExtensionのContinueやCline、実は、プロバイダにOpenAIやAnthropicのAPI対応しており、API課金さえすれば同じ(以上)のことができ、MacBook Pro 14に約75万円も払う必要はない(笑)。API課金してもなかなかこの金額には届かないだろう。 最後に。M4 Maxと128GBの環境でVRAMとして使える最大容量はメモリの75% = 96GBとなっているが、これは標準設定というだけで変更可能だ。ただ128GB全部にしてしまうと、最大時アプリが動かなくなるため、8GB残して120GBとするには % sudo sysctl iogpu.wired_limit_mb=122880 Password: iogpu.wired_limit_mb: 0 -＞ 122880 ※ デフォルト:0(75%)。120×1024=122880 と設定。これだと236BのDeepSeek-V2.5が動く。 実際はLM Studioでダウンロード/実行可能な「DeepSeek-V2.5-i1-GGUF」を使ったが、238Bがローカルで動くのはちょっと感動！ ただi1なのであまり賢くなく、LP生成“Create an LP for an IT company using bootstrap.”、1と2 take目はカッコいいのができず、動画は3 take目。Open WebUIもArtifacts機能があり、ご覧のように生成したコードの表示ができる。メモリは約110GB使用。ほぼギリギリ。加えてこの時、ファンの音を初めて聞いた(高出力設定)。相当負荷がかかるようだ。 後で分かったのだが、同じお題ならqwen2.5-coder-32b-instruct-q4_0.ggufの方がカッコいいLPができた(笑)。 以上のようにM4 Max 128GBを搭載したMacBook Pro 14は、一般的な家庭用GPU搭載PCでは実行不可能なLLMを実行可能だった。 大規模LLMをローカルで動かす旨みは、以前なら無検閲が挙げられたものの、今ではほぼ全て検閲あり。ほかにあるとすればコンテキスト長を大きくできる程度。+αで、新しいモデルが出た時、即試せることだろうか。 筆者の場合は、まだ知らない使い方や次々出てくるモデルを即試せる……という意味で将来に投資した感じとなる。従って現状、高い買い物だったのか、安い買い物だったのかは不明。数年後に振り返ってどう思うか！？……となる。時期が来たら、また感想を書いてみたい。 PC Watch,西川 和久",[],[]
