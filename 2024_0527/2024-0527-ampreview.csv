headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
生成AIに熟慮促す仕組みが登場　Quiet-STaRで出力前の再考が可能に　AGIへの試金石となるか？（AMP［アンプ］）,https://news.yahoo.co.jp/articles/28b191986769f18d2a3382ded646f55e71d2b0a3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240527-00010000-ampreview-000-1-view.jpg?exp=10800,2024-05-27T06:01:54+09:00,2024-05-27T06:01:54+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,3321,\n生成AIにおける推論の課題\n生成AIにおける推論の課題\n人間のように発言前に内容を吟味する、そんな生成AIの登場が現実のものとなりつつある。スタンフォード大学とNotbad AI社の研究者らが開発した「Quiet-STaR」は、AIモデルに出力前の「思考」を促すことでパフォーマンス向上を実現。推論タスクにおける正答率の大幅な改善が確認された。生成AIの進化に新たな道筋をつけるテクニックとして注目を集めている。\n\nChatGPTの背後にあるGPTなどの大規模言語モデルは、「次に来る言葉は何か」を推測するために膨大なデータでトレーニングされている。昨今GPT-4やClaude3 Opusなど、パフォーマンス向上が顕著だが、これは別の言い方をすると、次に来る言葉を推測する能力が上がっているということになる。\n\n一方、AIモデルは依然、因果関係を考えたり、「なぜ」「もし」といった推論を行うことが苦手であり、それをどう克服するのかが大きな課題だ。なぜ、AIモデルは、推論や言外の意味を読み取ることが苦手なのか。それには、大きく2つの理由があるといわれている。\n\n1つ目は、AIモデルが主に大量のテキストデータから言葉の統計的な規則性を学習する手法で開発されてきたことに起因する。統計的な規則性から、どの言葉がどの言葉の後に来やすいかといったパターンを見出すことは得意だが、言葉の深層にある因果関係や文脈を理解することが困難であるのだ。たとえば、「ジョージはリンゴが好きだ。なぜなら、甘くておいしいからだ」という文では、「なぜなら」以下がジョージがリンゴを好きな理由を説明しているが、AIにはその因果関係を読み取ることが難しいのだ。\n\n2つ目は、AIの学習に用いられてきたテキストデータの性質が挙げられる。SNSの投稿やニュース記事など、インターネット上のテキストの多くは断片的で、書き手の前提知識が多く省略されている場合がほとんど。これらが学習データに使用されているため、表層的な言葉の繋がりを把握するのは得意だが、言外の意味を汲み取ったり、仮定に基づいて推論したりするのが苦手となってしまうのだ。\n\nまた、データセットの普遍性が限定的である点も生成AIの能力を制限する要因となっている。従来の手法では、AIに解かせたい問題を集めた訓練用データを用意し、そのデータを使って特定のタスクをこなすようにAIを学習させることが一般的だった。しかし、これらの手法では、AIが学習できる問題の種類が訓練データに限定されてしまうという問題が浮上。この問題を解決するため日々研究が進められている。\nQuiet-STaRが実現する、人間のような「思考」\nスタンフォード大学とNotbad AI社の研究者らが最近発表した新たなアプローチ「Quiet-STaR」は、この分野における大きな進歩になる可能性があり、注目を集めている。Quiet-STaRは、STaRモデルを拡張したバージョンだ。\n\nそもそもSTaRモデルとは何かを簡単に解説したい。STaR（Self-Taught Reasoner）は、AIが自分自身で生成した文章から推論することを学習するモデル。これは特に、質問応答の文脈で提案された手法となる。従来、質問応答向けのAIは、大量の質問とその答えのペアを学習することで開発される。\n\nSTaRは以下のように、従来とは異なるアプローチを取る。\n\n・まず、AIは質問に対していくつかの答えの候補を生成する\n・次に、それぞれの答えについて、それが正しい答えである理由（根拠）を自分で考える\n・そして、それらの根拠から、どの答えが最も確からしいかを推論する\n・最後に、AIは自身が推論した答えと実際の正解を比べ、正解につながった根拠を強化する\n\nつまり、STaRは「考えるプロセス」自体を学習するモデルといえるだろう。最初は直感的に答えを出す可能性が高いが、次第により論理的で正確らしい根拠を生成できるようになるといわれている。\n\nこのSTaRの拡張版となるQuiet-STaRの特徴は、AIモデルに人間のような「思考」を促す点にある。\n\nたとえば、「ジャネットのアヒルは1日に16個の卵を産む。彼女は毎朝3つを朝食に食べ、4つを使って友人のためにマフィンを焼く。彼女は残りを毎日ファーマーズマーケットで新鮮なアヒルの卵1個2ドルで売る。彼女は毎日ファーマーズマーケットで何ドル稼ぐのだろうか？」という質問を投げかけると、Quiet-STaRはこの問題文を読み進める過程で、以下のような「思考」を巡らせる。\n\n「アヒルが1日に産む卵の数は16個。これが卵の総数だ」\n「朝食に3つ食べる。これが朝食に食べる卵の数」\n「マフィンを作るのに4つ使う。これがマフィン作りに使う卵の数」\n「16-3-4=9。9個がファーマーズマーケットで売られる卵の数」\n「卵1個の値段は2ドル」\n「2×9=18。18ドルが卵の合計金額」\n\nこうして問題文の各部分に根拠を示しながら、最終的に「卵の合計金額は18ドル」という答えに至る。\n\n一方、Quiet-STaRを適用していないモデルの場合、問題文を読み終えてから一気に答えを出力するような思考の流れになりがちだ。\n\n以下の推論は、Quiet-STaRを適用していないモデルが同じ質問に対して出した回答だ。\n\n「ジャネットは毎日平均12個の新鮮なアヒルの卵をファーマーズマーケットで売っている。卵1個2ドルで売っているとすると、1週間で彼女はいくら稼ぐことになるか。ほとんど毎日ファーマーズマーケットで売っていると仮定する」\n\n「ジャネットが毎日ファーマーズマーケットで売る新鮮なアヒルの卵は平均12個。これは12×7、つまり12×7=84になる。そうすると彼女が稼ぐ総額は84×2ドル、すなわち168ドルになる。よってジャネットは卵を売って週に168ドル稼ぐ」\n\nこのように、途中計算を飛ばして結論を急ぐようなプロセスでは、論理の飛躍が起きやすく、間違った答えに行き着く恐れがある。\n\nQuiet-STaRは、言語モデルが文章を読み進めながら各所で立ち止まって考えを巡らせ、推論の根拠を言語化するように促す。それにより、論理的に筋道を立てて考える習慣が身につき、最終的な出力の質が向上するというわけだ。\n新しいテクニックで期待される生成AIの進化\nでは、Quiet-STaRのようにAIモデルに熟慮を促すアプローチは、生成AIの発展にどのような変化をもたらすのだろうか。\n\nQuiet-STaRの効果としてまず挙げられるのが、モデルによる文脈の読み取り力の向上だ。従来、言語モデルは目の前のテキストから直接的に情報を抽出するだけだったが、一文一文に立ち止まって根拠を示す訓練を受けたモデルは、より深いレベルで文脈を理解し、言外の意味までも汲み取れるようになる。\n\nこれは質問応答や要約、文書分類など、高度なテキスト処理タスクでの精度向上につながるとみられる。カスタマーサポートなど、文脈や言外の意味の理解が重要となる分野で重宝されることになるかもしれない。\n\nまた、熟慮を重ねることで論理的な思考力も鍛えられる。Quiet-STaRの実験では、モデルの思考に割り当てる言葉数が多いほど推論タスクの正答率が上がる傾向が見られたが、これはより長く深く考えることが合理的な判断を導く上で効果的だからだろう。ビジネスや科学分野など専門性の高い領域での活用にも道が開けそうだ。\n\nさらに、推論能力の向上は生成AIの説明責任の強化にもつながることが期待される。AIがどのような思考プロセスを経て回答を導出したのかを示せるようになれば、システムの判断の妥当性を人間が評価しやすくなる。医療や金融、自動運転など、AIの判断ミスが重大な結果を招きかねない分野での応用にも弾みがつくだろう。\n文：細谷元（Livit）,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240527-00010000-ampreview-000-1-view.jpg?pri=l&w=640&h=426&exp=10800'],['https://news.yahoo.co.jp/articles/28b191986769f18d2a3382ded646f55e71d2b0a3/images/000']
