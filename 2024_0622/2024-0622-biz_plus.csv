headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
Llama 3（ラマスリー）をやさしく解説、試してわかったメタのオープンソースLLMの弱点（ビジネス＋IT）,https://news.yahoo.co.jp/articles/5151f4f226d634151b16fec1d086c7b2de7c73de,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240622-00142771-biz_plus-000-1-view.jpg?exp=10800,2024-06-22T07:10:05+09:00,2024-06-22T07:10:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,4531,"\nLlama 3と他の言語モデルとパフォーマンスの違い（出典：メタ）\nメタが4月に発表したオープンソース大規模言語モデル（LLM）が「Llama 3（ラマスリー）」だ。80億と700億のパラメータを持つバージョンが公開され、いずれも他社モデルに匹敵する高いベンチマークスコアを記録する。特に80億モデルは同規模の他モデルを凌駕し、数学やコーディング能力の大幅改善を見せた。Llama 3を搭載した新チャットボット「Meta AI」のリリースにより、ChatGPTやClaude、HuggingChatへのキャッチアップを図る。本稿では、実際にいくつかのプロンプトで試して、その実力を試してみた。その結果見えてきた強みと弱みとは。\n【詳細な図や写真】Meta AI（出典：メタ社）\nLlama 3とは何か？ その概要\n「Llama 3」とは、メタが2023年2月に発表したオープンソースの大規模言語モデル「LLaMA」の最新版で、2024年4月に発表された。\n\n 発表時点では80億（8B）パラメータと700億（70B）パラメータの2つのバージョンで構成され、現在4000億（400B）パラメータモデルも現在トレーニング中だという。\n\n メタ幹部のラガバン・スリニバサン氏は4000億モデルについて「ベンチマークの観点からみると、本当に桁外れの性能を発揮している」とコメント。また同社AIチームのVP、マノハル・パルリ氏は「Llama 3の80億、700億モデルは、オープンモデルで最高の性能を発揮しており、一部のクローズドモデルにも匹敵、あるいはそれ以上だ」と豪語している。\n\n メタのザッカーバーグ氏とネット上で一悶着あったイーロン・マスク氏も、Llama 3については「Not Bad（悪くない）」と評価するなど、おおむね好評価を得ている。\n\n Llama 3はメタのチャットプラットフォーム「Meta AI」にも統合された。OpenAIのChatGPT、AnthropicのClaude、HuggingFaceのHuggingChatなど競合へのキャッチアップを目指す。Meta AIは、フェイスブックアカウントでのログインが必要だが、画像生成モデル「Meta Imagine」が使用可能となっている。ただし現時点ではマルチモーダル非対応で、画像やドキュメントのアップロードはできない。\n\n\n なお、Llama 3はメタのオープンソースポリシーの下で公開されるが、ライセンス条件は一般的なオープンソースとは異なるため注意が必要だ（ソースは公開しているが、正確に言うとオープンソースソフトウェアではない）。\nLlama 3のベンチマーク比較\nでは、Llama 3はライバル各社のモデルと比べてどのような実力を持つのだろうか。ベンチマークスコアを比較してみたい。\n\n Llama 3の80億、700億モデルは、グーグルのGemmaやGemini Pro 1.5、AnthropicのClaude 3 Sonnet、MistralのInstruct 7Bなどのモデルと比べ、多くのベンチマークで同等の性能を示している。\n\n\n 特に多肢選択問題（MMLU）とコーディング（HumanEval）で高得点を獲得した。一方で、700億モデルは、Gemini Pro 1.5には高度数学問題（MATH）と大学院レベルの多肢選択問題（GPQA）でやや及ばなかった。\n\n 対して80億モデルの健闘ぶりは目覚ましい。Gemma 7BやMistral 7B Instructをすべてのベンチマークで上回り、特に算数の文章問題（GSM-8K）で大きく引き離した。\n\n 700億、80億モデルともにみられるのは、コーディングにおける強みだろう。Pythonコーディングの生成能力を見るHumanEvalでは、700億モデルが81.7％を達成。これは、GPT-4の67％を大きく上回り、Claude 3 Opusの84.9％に迫る数値だ。GPT-4oは90.2％であり、これにはやや及ばないが、主要モデルの中でもトップクラスの水準にあるといってよいだろう。\n\n 80億モデルもパラメータ数が小さいながら、HumanEvalでは62.2％と、同規模のモデルの中では非常に高い数値を叩き出している。ちなみにGPT-3.5は48.1％と、80億モデルには遠く及ばない状況だ。\nLlama 3の「特筆すべき」2つの強みと弱点\nこのほかLlama 3に関して特筆すべきは、スピードと価格だ。\n\n スピードでは、AIチップ企業Groqが展開するチャットプラットフォームで、80億モデルが1秒あたり844トークンという驚異的な処理スピードを達成。1秒あたりの処理トークンの平均スピードを評価するリーダーボードでは、これまで、Mixtral 8x7BやClaude 3 Haikuが100トークンほどでトップに君臨していたが、80億モデルはそれらを2倍以上上回るスピードで、一気にトップに躍り出た。\n\n\n\n 価格も各APIプロバイダーの平均価格をまとめた数値では、80億モデルが100万トークンあたり、0.1ドルと圧倒的な低価格だ。700億モデルも100万トークンあたり0.9ドルとGPT-3.5 Turbo（0.8ドル）に並ぶ安さとなっている。\n\n\n センセーショナルな登場となったLlama 3だが、弱点もある。\n\n まず、コンテキストウィンドウの少なさが挙げられる。Llama 3は2モデルとも、コンテキストウィンドウが8000トークンに限定される。\n\n コンテキストウィンドウとは、プロンプトに入力できるトークン数のこと。この数が多いほど、LLMに対し多くのコンテキスト（文脈）情報を与えることができる。文脈情報が多いほど、正確な回答を生成できる傾向があり、主要モデルにおいては10万トークン以上のコンテキストウィンドウが主流となっている。10万トークンを超えてくると、数百ページのドキュメントに匹敵する情報をLLMに与えることができる。\n\n たとえば、GPT-4 Turboは12万8000トークン、AnthropicのClaude 3は20万トークンを誇る。このほかグーグルが現在、100万トークンのコンテキストウィンドウの研究開発を進めるなど、コンテキストウィンドウは拡大傾向にある。\n\n このほかにも実際使ってみた中で、いくつかの弱みが確認できた。以下で、その詳細をお伝えしたい。\nLlama 3 vs GPT-4 vs Claude 3 vs Gemini Pro 1.5\nここでは、Llama 3と他の主要モデルの回答を比較しながら、Llama 3の特徴をあぶり出してみたい。比較対象としてはClaude、GPTシリーズ、Geminiをピックアップした。\n\n まず「What is Claude3?」という基本的な質問を投げかけ、各LLMの反応をみてみた。Claude 3は、Anthropicが2024年3月にリリースした新しいモデルであり、主要LLMの学習データには入っていない可能性が高い。このため「学習データに入っていないため、分かりません」というのが模範解答になる。\n\n 結論からいうと、Llama 3は80億、700億モデルともに、ハルシネーションともとれる回答を生成してしまい、ハルシネーションリスクを露呈した。\n\n 80億モデルは、Claude 3とは「3Dスキャン技術」であると回答。一応、Claude 3という3Dスキャン技術があるのかを調べたが、そのような技術を確認することはできなかった。この回答はハルシネーションである可能性が非常に高い。\n\n\n 700億モデルは、Claude 3はAnthropicが開発したAIモデルであると回答したが、その解説は、LLMの一般的な性質を述べるにとどまり、Claude 3を本当に理解しているのかを確認することはできなかった。その証拠に、続けて、「if you know Claude3, tell me more detailed information about that（Claude 3を知っている場合、その詳細を教えてください）」と追加質問をしたところ、Claude 3とは関係のない情報を羅列。Claude 3を理解していないにもかかわらず、あたかもClaude 3を知っているかのように振る舞うハルシネーションの傾向が確認できた。\n\n\n ただし、これらの質問に関しては、当のClaude 3（Sonnet、Haiku）に加え、Gemini Pro 1.5（preview）、ともにハルシネーションを生成。「Claude 3について情報がない」とはっきり言い切ったのは、GPT-3.5 Turbo、GPT-4 Turboのみという結果になった。最近、エンタープライズ向けの攻勢を強めるOpenAIがハルシネーション防止対策を進めていることを示す結果といえるだろう。\n\n\n 英語でLlama 3を使う場合でも、現状では明らかなハルシネーションリスクが伴うということには留意が必要だ。\nLLM比較でさらに露呈したLlama 3の弱点\n続いて日本語での使用感を見てみたい。\n\n 最初の質問は「Anthropicが開発したClaude 3とは何か」。まず日本語で回答できたのは、GPTモデル、Gemini、そしてClaude 3のみ。肝心のLlama 3は英語での回答となり、やはり最新モデルでも多言語対応能力が依然乏しいことが確認できた。Llama 2のときと同様に、これをベースとして、ファインチューニングによる各言語版が登場することに期待したい。\n\n また英語の回答内容は、80億、700億モデルともに、LLMに関する一般的な情報を述べるにととどまり、Claude 3の特徴を正確に解説したものにはなっていない。パラメータ数など、不正確な情報を列挙しており、ここでもハルシネーションの傾向が観察された。\n\n\n この質問において、言語、内容ともに正しい回答を生成したのは、GPT-4 Turboのみ。「具体的な内容は公開されていない」と率直に述べ、その信頼度の高さを見せつけた。\n\n\n 一方GPT-3.5は、「Anthropicが開発したクロード3は、自動運転技術の開発を目的としたプラットフォームです」とハルシネーションに満ちた回答を生成してしまった。\n\n 以上から、日本語環境下ではLlama 3の実用性はかなり限定的と言えそうだ。やはり日英を含む多言語の壁は厚く、英語での利用を前提とした調整が不可欠といえるだろう。また、ハルシネーションを防止するためのプロンプトエンジニアリングやRAGアプローチの併用などが必須となりそうだ。\n執筆：細谷 元",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240622-00142771-biz_plus-000-1-view.jpg?pri=l&w=640&h=377&exp=10800'],"['https://news.yahoo.co.jp/articles/5151f4f226d634151b16fec1d086c7b2de7c73de/images/000', 'https://www.sbbit.jp/article/cont1/142771#image180050']"
