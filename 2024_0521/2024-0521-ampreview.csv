headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
メタに挑戦、Databricksもオープンソースモデル開発に参戦　最新モデルが示す意外な日本語能力（AMP［アンプ］）,https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-000-1-view.jpg?exp=10800,2024-05-21T06:02:34+09:00,2024-05-21T06:02:34+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,3213,"\nDatabricksのオープンソースモデル「DBRX」、既存モデルを超える性能\nDatabricksのオープンソースモデル「DBRX」、既存モデルを超える性能\nOpenAI、Anthropic、Cohere、グーグルが強い存在感を示す生成AI市場だが、メタを筆頭にオープンソースモデルの展開により、AIコミュニティでの支持を集める企業も増えつつある。\n\nデータ管理プラットフォームを提供するDatabricksも最近オープンソースモデルをリリースし、この流れに乗る算段だ。\n\n2023年4月、DatabricksはオープンソースAIモデル「DBRX」を発表した。同モデルは1,320億のパラメータを有する比較的大きなモデルで、言語理解（MMLU）、プログラミング能力（Human Eval）、数学的スキル（GSM 8K）などの主要ベンチマークで、Llama 2-70BやMixtralといった主要なオープンソースモデルを上回る性能を示したとされる。\n\nDBRXの特徴は、「mixture-of-experts」アーキテクチャにある。DBRXモデルは16のエキスパートサブモデルを含んでおり、各トークンに対して最も関連性の高い4つを動的に選択することで、高いパフォーマンスを実現している。このアーキテクチャにより、実質的にアクティブなのは360億パラメータのみで、高速かつ低コストな動作が可能になるという。\n\nDatabricksは昨年、AIスタートアップMosaicを買収しており、同チームが以前研究していたMega-MoEのアプローチをDBRX開発に活用した。DBRXの開発期間は約2カ月、コストは1,000万ドル程度だったと報じられている。\n\nDatabricksがDBRXをオープンソース化した背景には、独自のアーキテクチャを普及させつつ、AI市場における存在感を強めたい意図が見え隠れする。また、顧客の非公開データを用いた独自AIモデルの構築とホスティングを行う同社の主力事業を強化する狙いも見受けられる。\n\nDBRXは英語でのベンチマークでは高い数値を示しているが、実際の商用利用を考えた場合、多言語対応が欠かせない。次項では、DBRXを含むオープンソースモデルの日本語処理能力を検証してみたい。\n日本語における評価はどうか？英語論文要約タスクでの検証\nプロンプトの一部抜粋\n前項で紹介したDBRXは、英語でのベンチマークでは非常に高い評価を得ている。しかし、日本語での性能はどうだろうか。この疑問に答えるべく、AnthropicのClaude3に関する英語の技術論文を各モデルに日本語で要約させるテストを行った。\n\n検証にあたり、まず論文のテキストを抽出。全42ページのうち、最初の5ページ分の内容を日本語で要約するように指示するプロンプトを入力した。プロンプトの文字数は、空白込みで、19,615文字、空白なしで16,973文字と、比較的長めの文章となる。\nDBRXの回答\n検証の結果、オープンソースモデルの日本語対応には大きな課題があることが明らかになった。DBRXやMistral 7B Instruct、Llama v2 70B Chatはいずれも、日本語でサマリーを書くよう指示されているにもかかわらず、英語で回答を生成してしまったのだ。これは、これらのモデルが日本語の指示を正しく理解できていないことを示唆している。\nDBRXの回答\nこの結果から、現時点でのオープンソースモデルは日本語への対応が不十分であり、実用レベルには程遠いと言わざるを得ない。日本語の指示に適切に応答できなければ、日本語圏のユーザーに満足のいくサービスを提供することは難しいだろう。\n\n一方、OpenAIのGPTシリーズは比較的良好な結果を示した。GPT-3.5 TurboとGPT-4はいずれも、日本語の指示を的確に理解し、英文の内容を要領よくまとめられている。\nGPT-3.5 Turboの回答\nこの結果から、現時点でのオープンソースモデルは日本語への対応が不十分であり、実用レベルには程遠いと言わざるを得ない。日本語の指示に適切に応答できなければ、日本語圏のユーザーに満足のいくサービスを提供することは難しいだろう。\n\n一方、OpenAIのGPTシリーズは比較的良好な結果を示した。GPT-3.5 TurboとGPT-4はいずれも、日本語の指示を的確に理解し、英文の内容を要領よくまとめられている。\n\n日本企業がAIを活用する際は、モデルの多言語対応力を十分に見極める必要がある。英語のベンチマークだけを過信するのは危険といえるだろう。\n日本語に強いモデル：GPT3.5、GPT4、Claude、Gemini、Cohere Command\nClaude3 Opusの回答\nでは、大規模言語モデルの中で、日本語処理に長けているのはどのモデルだろうか。日本語が強いと思われる6つのモデルを比較してみた。評価対象は、Cohere Command R, Cohere Command R+, Gemini Pro1.0, Gemini Pro1.5 (preview), Claude3 Haiku, Claude3 Opusだ。\n\n前項と同様に、AnthropicのClaude3に関する技術論文を日本語で要約するタスクを課した。予想通り、6モデルはいずれも原文の内容を的確に要約することができた。\n\n中でも特に優れた要約を生成したのが、Claude3 OpusとGPT4だった。この2モデルは、原文の本質をコンパクトにまとめ上げる能力が秀でていると言える。Opusは、Claude3モデルの中で最も高性能なモデルとされ、推論や数学、プログラミングなどの分野で卓越した性能を示すことで知られる。一方、GPT4はOpenAIが開発したフラッグシップモデルで、最近までは市場最高峰と称されていたモデルだ。\nGemini Pro 1.5の回答\n続いて高く評価できたのはGemini ProシリーズとCohereのCommand RおよびCommand R+だ。Gemini Proは1.0と1.5の2つのバージョンを評価したが、いずれも要点を日本語で簡潔明瞭にまとめる力を発揮した。\nCommand R+の回答\nCohere Command Rは若干冗長な表現が見られるものの、原文の大意をしっかりと捉えて日本語に置き換えている。さらに、Cohere Command R+は、Command Rの要約をより洗練させたような印象を受ける。不要な情報を削ぎ落とし、よりコンパクトでまとまりのある要約を生成できている。\nClaude3 Haikuの回答\nClaude3シリーズの中で、Haikuは最も軽量なモデルに位置づけられているが、要約タスクにおいては、限られたリソースながらも優れた日本語処理能力を示した点が特筆に値する。\n\n以上の検証結果から、6つの大規模言語モデルは総じて日本語の理解力が高く、英文を的確に要約できる能力を備えていることが明らかになった。一方で、DBRXのようなオープンソースモデルの日本語対応は遅れを取っているのが実情だ。今後は、オープンソースモデルにおいても日本語処理能力の強化が求められるだろう。\n\n日本企業にとっては、目的に適したモデル選定がこれまで以上に重要になるはず。単に最新のモデルを導入すればいいわけではなく、日本語を含む多言語処理の実力を見極める目が求められる。GPT4やClaude3のような、多言語タスクで実績のあるモデルは、安心して活用できる選択肢と言えそうだ。\n文：細谷元（Livit）","['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-000-1-view.jpg?pri=l&w=640&h=426&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-001-1-view.jpg?exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-002-1-view.jpg?pri=l&w=640&h=359&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-003-1-view.jpg?pri=l&w=640&h=365&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-004-1-view.jpg?pri=l&w=640&h=365&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-005-1-view.jpg?pri=l&w=640&h=439&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-006-1-view.jpg?pri=l&w=640&h=462&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-007-1-view.jpg?pri=l&w=640&h=298&exp=10800', 'https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240521-00010000-ampreview-008-1-view.jpg?pri=l&w=640&h=550&exp=10800']","['https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/000', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/001', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/002', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/003', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/004', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/005', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/006', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/007', 'https://news.yahoo.co.jp/articles/c5e026e27a91b0b1b5a23fb6026a4182dbae7a03/images/008']"
