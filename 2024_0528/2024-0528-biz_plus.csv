headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
"断トツ「介護保険料」が高い都道府県とは？ 最安山口県より2,000円も負担が重いワケ（ビジネス＋IT）",https://news.yahoo.co.jp/articles/11a8b83e341f627d46ef7fbc4a0d64c582967241,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140669-biz_plus-000-1-view.jpg?exp=10800,2024-05-28T06:30:05+09:00,2024-05-28T06:30:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,2614,"\nなぜ、保険料には地域差があるのか？（Photo/Shutterstock.com）\n65歳以上の高齢者が支払う介護保険料の全国平均が過去最高を更新した。介護保険料は高齢化の進展によって上がる一方だが、保険料には地域差がある。住む場所と介護保険料についてどう考えれば良いのだろうか。\n【詳細な図や写真】介護保険料が最も高いのは大阪市で9,240円、最も安いのは東京都小笠原村で3,374円。大阪市と小笠原村では3倍近い差が生じている（Photo：Byjeng / Shutterstock.com）\n費用の半分は税金から支出されている\n厚生労働省は2024年5月14日、65歳以上の高齢者が2024～2026年度に支払う介護保険料の全国平均が月額6,225円になったと発表した。前期と比較すると3.5％の増加となっており、過去最高を更新した。\n\n\n生成AIで1分にまとめた動画\n\n 介護保険を利用する場合には、利用者が原則として1割を自己負担する仕組みになっている（所得によって最大3割負担になる）。残りの費用は介護保険から拠出され、半分は税金、残りの半分は国民から徴収する保険料で賄われる。\n\n 保険料は40～65歳までの現役世代については、各人が加入している医療保険を通じて給料から引き落とされる。65歳以上の高齢者については、年金を受給している場合、年金からの引き落としとなり（特別徴収）、無年金もしくは年金の額が低い場合には直接納付となる（普通徴収）。\n\n 今回、金額が上がったのは、65歳以上の高齢者が納付する保険料で、3年に1度見直しが行われている。高齢者が納める保険料は自治体によって違いがあり、国民負担の大きさが異なる。\n\n\n 介護保険料が最も高いのは大阪市で9,240円、最も安いのは東京都小笠原村で3,374円となっており、大阪市と小笠原村では3倍近い差が生じている。都道府県別でもそれなりの違いがあり、最も高いのは大阪府で7,486円、最も安いのは山口県で5,568円だった。\n\n 保険料にここまで違いが生じるのは、介護事業者に対する支出額が地域によって異なるからである。基本的に介護を受ける人（要介護者）の数が多ければ多いほど、事業者に対する支出が増えることになるのだが、要介護者数は必ずしも高齢者の数に比例しているわけではない。\n保険料を左右する要素とは？\n高齢になって体が思うように動かなくなっても、家族がいる世帯の場合、家族がある程度の支援をしてくれるので、すぐには要介護にならないケースが多い。特に地方の場合、核家族化が都市部ほど進んでいないところもあり、そうした地域の場合、親子のみならず親戚なども支援に加わるので、介護サービスの利用頻度は相対的に少なくなる。また地域によって介護サービス事業者の数も異なっており、サービスを受けやすいかどうかも影響するだろう。\n\n 都市部の場合、総じて核家族化が進んでいるものの、単身者と夫婦の世帯を比較すると、やはり夫婦の世帯の方が介護サービスの利用度は低い。夫婦どちらかが元気であれば、ある程度までは家庭内で介護ができるので、単身者とは状況が大きく異なる。\n\n 結局のところ、介護保険料の違いというのは、単身の高齢者数に起因する部分が大きいと思われる。健康寿命については所得と関連性があるとの指摘もあり、経済的な要因も関係しているかもしれない。したがって介護保険料が安い地域＝潤沢に介護サービスを受けられる、という図式とは限らないので注意が必要である。\n\n 介護保険制度が始まった2000年度における平均の保険料は2,911円と半分以下の水準だった。今後も高齢化や核家族化が進むことから2040年度には月9,000円程度になるという推計もある。現在、大阪市は9,000円を超えているが、多くの自治体において現在の大阪市に近い状況になると考えて良いだろう。\n支払う保険料に対して「妥当な介護サービス」と言える？\n今回の改定は高齢者が支払う保険料だが、現役世代が支払う保険料も同じように増額が続く。現役世代の保険料については加入する健康保険ごとに料率が異なるが、半分は企業が負担しているので平均的な年収の人は月あたり3,000～4,000円程度の負担になっているはずだ。\n\n 現役世代の場合、介護について具体的なイメージが湧かないことも多いので、負担ばかり背負わされていると感じるかもしれない。だが、実際に自分が介護される立場になる、あるいは家族が要介護となり、家庭内で介護しなければならない状態になると、事の重大さが嫌でも認識できるようになるだろう。\n\n 筆者も実際に経験したことがあるのでよく分かるのだが、家族を介護するというのは並大抵のことではない。仕事を続けながら親などを介護することの負担は想像を絶するレベルであり、（要介護レベルにもよるが）公的な介護サービスなしではとても乗り切れない。\n\n 日本の介護保険制度は相対的に見ると良く設計されており、行政が行っているサービスとしてはかなりレベルが高い。こうした良質なサービスが月々わずか3,000～4,000円の負担で利用できるのは、むしろ画期的なことと言えるだろう。\n上がり続ける保険料、どうすれば負担を減らせるか\n加えて言うと、介護士など介護業務に従事する人たちの賃金は、職務内容や求められるスキルに対して低く抑えられており、従事者には過大な負荷がかかっている。現在、介護業界では人手不足が慢性化しており、待遇を改善していかなければ状況はさらに悪化するだろう。その意味でも、ある程度の国民負担はやむを得ないと考えるべきだ。\n\n 一方で、政府も国民負担をできるだけ増やさないよう、対策を講じていく必要がある。\n\n 最も効果的なのは、要介護になる人の絶対数を減らすことである。近年、予防医学というキーワードが定着しつつあり、可能な限り健康寿命を延ばす試みが各地で進められている。国民の健康増進を進める施策を強化することで、ある程度までは要介護率を引き下げることが可能となる。加えて、富裕層など経済的に余裕のある人から、より高い保険料率を適用するといった仕組みも導入していく必要があるだろう。\n執筆：経済評論家 加谷珪一",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140669-biz_plus-000-1-view.jpg?pri=l&w=640&h=360&exp=10800'],"['https://news.yahoo.co.jp/articles/11a8b83e341f627d46ef7fbc4a0d64c582967241/images/000', 'https://www.sbbit.jp/article/fj/140669#image177692']"
アクセンチュア流やらないとマズい「生成AIリスク管理」、3つのワナを回避せよ（ビジネス＋IT）,https://news.yahoo.co.jp/articles/27ac8ba4b1d0cab8f4e1faef0f0f64199c82bac8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140133-biz_plus-000-1-view.jpg?exp=10800,2024-05-28T07:10:05+09:00,2024-05-28T07:10:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,4696,"\n生成AIのリスクとAIガバナンスで陥りやすい3つのワナとは？（後ほど詳しく解説します）（出典：アクセンチュア）\n前回はジェネレーティブAI（生成AI）のビジネスでの活用方法を紹介し、アイデアの創出や思考を深めることに生成AIを使うことをおすすめした。一方、生成AIから出力された情報を鵜呑みにせず、人間が確認することを怠ってはならないとも強調した。今回は生成AIを活用する際のリスクやAIガバナンスで陥りやすい3つのワナを取り上げたい。\n【詳細な図や写真】図1：生成AIの事前に検討すべきリスクと利用時に考慮すべきリスク（出典：アクセンチュア作成）\n生成AIのリスクは開発者が想定していない形で現れる\n2024年2月、グーグル（Google）は同社の生成AIサービス「Gemini（旧Bard）」が「歴史的な画像の描写が不正確」という指摘を受け、サービスを一時停止し調整する方針を発表した。「1943年のドイツ兵を描いて」という指示文（プロンプト）で、黒人やアジア人の画像を生成したことなどが問題視されている。\n\n 一般的に、画像生成AIの生成結果は学習データのバイアスを反映し、偏った生成結果をアウトプットしてしまうことがたびたび指摘されている。たとえば「CEOを描いて」というプロンプトに対して白人男性が生成されやすいといったこともそうだ。\n\n これには多様性を考慮した画像生成になるように調整するという手法がとられるが、今回のGeminiの例はこれが裏目に出た形となった。Geminiが多様な人物を生成するように調整されたことにより、逆に多様な人物を「表示すべきでない」場合が考慮から漏れていたことが原因と見られている。\n\n この事例は図1の生成AIの「アウトプットにおけるリスク」のうち「誤情報の混入」に相当するリスクだ。生成AIのリスクは開発者が想定していないような形で現れることが多く、サービスを提供する企業はもちろんのこと、そのサービスを利用する企業も対策を行わなければならない。\n\n\n 欧州連合（EU）ではAIに対する包括規制の制定が進められており、2024年3月13日には欧州議会にて最終案が賛成多数で可決、5月21日には閣僚理事会が承認し正式に成立している。本規制案はAIのリスクを4つに分類し、それぞれのリスクに応じた措置を事業者に義務付けるものだ。違反をすると最大3,500万ユーロ（もしくは世界売上高7％）の制裁金が科されるという厳しいものだ。\n\n 生成AIについては、AIモデルを提供する事業者に対し、学習の際に用いた著作物の情報開示や品質管理などが求められており、川下のサービス提供者がEUでの義務を遵守できるよう、詳細な技術文書やわかりやすい使用説明書を作成することが義務付けられている。\n\n したがって生成AIを利用したサービス提供者はこれらの情報に基づき適切な対応が求められることになる。AI規制の施行に向けて前進している欧州の動向は、今後のAI関連ビジネスの動向を予測していく上でも注目されている。\nアクセンチュア流「責任あるAI」の構成要素\nこのような潮流にあって、企業としての「価値の創出」、あらゆるステークホルダーからの「信頼の構築」、AIにまつわる「リスクの排除」を目指す『責任あるAI』がますます重要になる。\n\n 責任あるAIはAIライフライクル全般に関わる概念なので、企業戦略に初めから組み込んでおく「Responsible by Design」の考え方が有効だ。\n\n\n Responsible by Designの考え方は日本でも徐々に浸透しつつある。AIガバナンス組織を設立し、企業におけるAI開発・利活用における早期のリスク管理のためアセスメントチェックリストを整備したり、AI倫理のリテラシー向上のための研修メニューを整備したりする企業は今後増えてくると予想される。\n\n しかし、これらの取り組みを進めていくうえで実は陥りやすいワナが存在している。今回は3つのワナについて解説し、Responsible by Designを成功に導くためのコツをお伝えしたい。\nワナ（1）AI起因リスクを低く見積もる甘いガバナンス\n長年、生産性向上が企業における経営課題となっており、そのブレークスルーとして、さまざまな企業で生成AIの活用検討が進んでいる。生成AIの適用範囲はフロントオフィス業務からミドルオフィス、バックオフィス業務支援など多岐にわたる。\n\n そのため専任の検討組織を設けることで、それぞれの業務におけるユースケースの策定、KPIの設定、開発の優先順位付け、実業務への適用を通した効果検証などが行われている。\n\n 今はまだ、生成AIという新しい技術に対する技術的楽観性に基づく熱狂期にあるといえるだろう。「責任あるAI」は生成AIの登場により踏み込まれたアクセルに対する、いわばブレーキの位置づけだ。\n\n 熱狂の中にあるからこそ、冒頭のような予測できないリスクが発生したときに企業として対処すべく、AIガバナンスの構築が必要不可欠だ。\n\n AIガバナンス組織を設ける企業も増えてきた。しかしアクセルとブレーキをどのように踏み分けるのかは実は判断が非常に難しい。ビジネスにある程度のリスクテイクは付き物だが、そのリスクがAI起因によるものである場合には、発生確率や影響度をどのように定義するかが肝だ。そしてビジネス成長というプレッシャー下においてはそのリスクは低く見積もられる可能性がある。これが第一のワナだ。\n\n リスクを正しく見積もり、AIガバナンス組織が機能するためには、外部の観点でリスク評価を行う「レッドチーム」の存在が重要だ。\n\n\n 米国政府は2023年10月に「AIの安全で安心・信頼できる開発と利用」という大統領令を発令した。AIシステムの開発者に対し、レッドチームによるテスト結果の提出を義務付け、テストに対する厳格な基準を設定することを求めている。\n\n この発令をうけ、米国ではAIに対するレッドチームの重要性が高まっており、日本におけるAIガバナンス組織の在り方にも参考になると考えている。\n\n もちろんリスクが低いAIのプロジェクトにまでこのような厳格なテストを実施するのは現実的ではないが、リスク判定基準でリスクが高いと判定された場合には、レッドチームによるテストあるいは評価結果の提出を義務付ける、などの施策によりリスク管理の合理性が向上していくと考えられる。\nワナ（2）チェックリストを作ったあとは部門に丸投げ\nAIリスクのスクリーニングを行うためには、前述のようにリスク評価基準を設け、評価用のチェックリストを作成、運用していく方法が一般的だ。評価のチェックリストにはデータやAIに関する質問事項が並ぶ。\n\n AI倫理の観点からは、公平性・透明性・説明可能性・安全性・データプライバシー・コンプライアンスなどといった質問事項も並ぶ。さらに、従来の業務特化型のAIと生成AIでは特性が異なるので、生成AI専用の質問項目も並べることになるだろう。\n\n たとえば開発者向けのチェックリストに、「開発中のシステムは生成AIに個人情報が含まれるデータを入力するか」という項目を入れる場合を考える。すると、システムとして個人情報の取り扱いに必要なセキュリティ対策がされているか、適切な期間の監査証跡が取得できるようになっているか、AIの出力ログは一定期間保持されているか・・・などなどの項目も入れたくなってくる。\n\n こうして考えうるリスクを盛り込んだチェックリスを作成後、AIプロジェクトを遂行している部門に展開し、定期的にチェックを実施してもらい、その結果を管理部門が管理すればOKと思われるかもしれない。だがそれでは組織的な管理はできないのが実情だ。\n\n 何の調整もしていないチェックリストはその煩雑さのために部門でのチェックがされないといったことが発生し、やがて形骸化していくだろう。リスクを網羅したアセスメントチェックリストが完成すればリスクは検知できるはずと誤解し、あとは部門に丸投げしてしまうというのが第2のワナだ。\n\n ここでの成功のカギはズバリ「現場の腹落ち感」だ。個人情報や機密情報を扱う場合には、既に企業内にデータプライバシーポリシーやデータセキュリティ・ガイドラインが存在している場合がほとんどだ。\n\n 個人情報を扱う場合には具備すべきセキュリティ要件についてはそちらで確認されているので、AIのアセスメントにまでデータセキュリティやデータプライバシーの詳細要件についてのチェックがあると冗長になってしまう。\n\n また、人種などのデータバイアスを確認することは公平性の観点で重要だが、製品の外観検査AIではチェック不要の概念だ。\n\n このように、アセスメントチェックリストを作成する場合には現場の実態、既存の認証・認可のプロセスなどと整合させながら実運用に向けたカスタマイズが重要になる。\nワナ（3）人材育成で多様性が考慮されない\nPythonでのデータ分析やAIモデル構築に関する研修メニューをeラーニングなどで提供する企業も増えてきた。これまで述べてきたように責任あるAIが重要になりつつある現在、研修メニューにも責任あるAIに関するコンテンツが必要だ。\n\n 社内のAI人材が責任あるAIに関するリテラシーを身に付ければ、生成AI時代における企業としてのリスクの排除、顧客を含むステークホルダーからの信頼の構築にも寄与する。\n\n IT技術関連職の従業員にこういった研修メニューが提供されるケースも増えていくだろうが、研修を受講する従業員の多様性を考慮する必要性を訴えたい。\n\n AIのリスクはさまざまな観点から想定する必要がある。アウトプットに、誰もが持つ無意識のバイアスを反映されていないかなど、開発者側およびチェックする側における多様な観点が必要だ。\n\n Indeedの調査によるとIT技術関連職の職場に関する質問で、チームや部署の男性比率が6割以上（女性が4割以下）と回答した人は全体の73.2%にのぼっている。\n\n 日本においてはIT分野における女性の就業率はまだまだ低いというのが実情だ。したがって、責任あるAI研修が設けられているとしても、たとえば、その研修を受ける女性が少なければ女性に対する無意識のバイアスが見過ごされる可能性が高まる。これが第3のワナだ。\n\n 責任あるAIはIT技術関連職だけでなく、法務・コンプライアンス・サステナビリティ・ユーザー部門などさまざまな職種・部門でも必要な概念だ。しかし、「AI」と名前がついていると、AIの学習モデル構築方法のような技術的な話だと思われてしまい、技術職以外の方々から敬遠されてしまうのではと懸念している。\n\n 生成AIの影響範囲は企業全体にわたっているので、企業においてもあらゆる部門・職種に対し、多様性を考慮した責任あるAI研修の展開を目指していく必要がある。\n本稿は、2023年11月に刊行された書籍『生成AI時代の「超」仕事術大全』をもとに再構成し加筆したものです。\n執筆：アクセンチュア ビジネス コンサルティング本部 AIセンター 鈴木博和",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140133-biz_plus-000-1-view.jpg?pri=l&w=640&h=343&exp=10800'],"['https://news.yahoo.co.jp/articles/27ac8ba4b1d0cab8f4e1faef0f0f64199c82bac8/images/000', 'https://www.sbbit.jp/article/cont1/140133#image177176']"
研究者視点で見た「GPT-4o」の評価と謎、GPT-5に向けた「たった1秒」の伏線とは（ビジネス＋IT）,https://news.yahoo.co.jp/articles/68511c2b317bed30dfe1415ffa37a0bfdab06381,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140615-biz_plus-000-1-view.jpg?exp=10800,2024-05-28T06:10:04+09:00,2024-05-28T06:10:04+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,5465,\nGPT-4oは数年前なら「AGI（汎用人工知能）」といわれるレベルに達した（出典：OpenAI）\n新型AIモデル「GPT-4o」が発表されたものの、実は多くの謎が残されており、研究者たちからもさまざまな疑問が投げかけられています。特に、旧GPT-4に比べて驚異的に高速化された出力スピードは、単なるハードウェアの改善だけでは説明できないレベルのものです。一方、性能の一部が低下しているという報告もあり、今後の詳細な検証が求められそうです。GPT-4oは汎用人工知能（AGI）に近づく一歩とされており、次世代の「GPT-5」への期待も高まっています。この記事では、『生成AIで世界はこう変わる』の著者で、東大 松尾研究室の今井翔太氏が、研究者の視点でGPT-4oの性能と次世代のGPT-5への可能性について解説します。\n【詳細な図や写真】サム・アルトマン氏ですらGPT-4oについて触れている期間は1週間程度だったという（出典：Sam Altman talks GPT-4o and Predicts the Future of AI）\n前回記事・前々回記事はこちら\nGPT-4oをわかりやすく解説、専門家が「時代の転換点」と評価するヤバすぎる能力\n（https://www.sbbit.jp/article/cont1/140613）\n\nGPT-4oの動画・画像、音声の能力は？ これから使える機能、今わかっていることまとめ\n（https://www.sbbit.jp/article/cont1/140613）\n研究者の視点から見てもGPT-4oは「謎が多いモデル」\nここからは少し研究的な視点での解説になります。用語についても少し研究的な色が強くなり、使われている用語の傾向が少し変わること（言語生成AI→大規模言語モデルなど）をご了承ください。\n\n 手前味噌で恐縮ですが、以下のような生成AIに関する研究的な内容も理解したいという方のために拙著『生成AIで世界はこう変わる』をおすすめさせていただきます。\n\n ここまでGPT-4oの圧倒的な性能を解説してきたところですが、GPT-4oのまとまった研究報告や論文といったものは公式からも他の研究機関からも（少なくともこの記事の執筆時点では）まだ少ない状況です。\n\n すべての情報が明らかにされないまでも一応Technical Reportが存在していたGPT-4と比べてもGPT-4oは謎が多いモデルです。\n\n なお、OpenAI CEOサム・アルトマン氏が後日出演した対談動画によると、アルトマン氏本人もGPT-4oに触れている期間は1週間程度しかないということらしく、グーグルの発表に合わせて急遽リリースしたというのも背景にありそうです。\n\n\n ただ、発表から1週間程度が経過し、私自身や他のユーザーが実際に利用した知見も貯まってきていますので、そこからある程度推測可能なGPT-4oの詳しい性能を書いてみようと思います。\n出力スピードが「異常なレベル」で高速化\nまず、GPT-4oの処理スピードとテキストの出力性能に関するものです。GPT-4oの出力スピードは旧GPT-4oと比較しても「異常なレベル」で早くなっています。\n\n GPT-4などの大規模言語モデルは一般的にとてつもなく巨大なニューラルネットワークを利用しており、そのニューラルネットワークのTransformerというアーキテクチャーの仕様からも、処理はどうしても遅くならざるを得ませんでした。\n\n 一度のやり取りで数十秒かかることすらザラであり、筆者などは、GPT-4の出力が完了するまでの間にメールを書いたり、YouTubeの動画を見ていたくらいです。\n\n これに対して、GPT-4oの処理はかなり長い文章であっても数秒レベルであり、これはChatGPTの処理の最適化やハードウェアをどうにかした程度で実現できるものではありません。\n\n おそらく、ベースとなるGPT-4oのニューラルネットワーク自体に、GPT-4と比べてかなり仕様が異なるものを利用しています。\n\n 出力スピードを考えるとGPT-4oのニューラルネットワークは旧GPT-4と比べて相当に小型なものを利用していることが推測されます。\n\n 大きなニューラルネットワークの出力をまねるように小型のニューラルネットワークを学習する蒸留（distillation）、不要なパラメーターを削除する枝狩り（pruning）、パラメーターの値の低精度化して表現幅を減らす量子化（quantization）、良質なデータを学習に使う、トークナイザーを改善することなど、大規模言語モデルを圧縮して高性能な小型のモデルを使う手法はいくつかありますが、GPT-4oはこれらの技術のいずれか、あるいはOpenAI内で開発した新手法などをつかってGPT-4oの小型化を実現していると考えられます。\n\n 旧GPT-4は有料ユーザーのみに開放されていましたが、OpenAIがGPT-4oを一般ユーザーに無料で公開し始めたという点を見ても、GPT-4oが小型モデル化に成功したがゆえに運用コストが下がり、収益の目処が立ったと考えることができます。\n「スケーリング則」を無視した飛躍がもたらす意味\nさて、ここまでの話なら単に「小型の大規模言語モデルでGPT-4レベルの性能を出すことに成功した」ということになるのですが、今まで研究者の間で常識とされていたことを考えると、これは「はい、そうですか」と済ませることはできません。\n\n 大規模言語モデルに関する有名な説として「スケーリング則」というものがあります。これは一言でいうと、「Transformerを使った言語モデルの性能は、モデルサイズ（パラメーター数）、学習に利用するデータの量、学習に使う計算量によって決まる」というものです。\n\n これら3つの変数を「同時に」大きくする（スケーリングさせる）ことでGPTのような言語モデルの性能は上昇していくと主張していくわけです。\n\n もう少し詳しく言うと、これらの3つの変数を10倍、100倍と増やしていくと、それに合わせて言語モデルの「間違いやすさ」を示す学習中のテスト誤差が綺麗な直線関係で下がっていきます。\n\n このスケーリング則を考えると、報告されているGPT-4oの圧倒的な性能は（実は）少し不自然なのです。\n\n 上述のようにスケーリング則が成立するには、モデルサイズ、データ量、計算量を「同時に」上昇させる必要があります。\n\n つまり、小型のモデルでGPT-4並みの性能を出そうといっても、モデルサイズが小型で固定される以上は、どれだけデータ量を増やそうが、計算量を増やそうが、普通は実現できません。\n\n スケーリング則自体は、あくまでテスト誤差が3つの変数を上げることで小さくなっていくことを主張しているに過ぎないため、厳密にはスケーリング則のみで小型のモデル＝性能が低いという結論をそのまま導けるわけではありません。\n\n ただ、スケーリング則は、現在の研究者たちの世界ではおおむねそのまま生成AIの言語性能に直結する絶対的なものであると認識されています。\n\n 実際、GAFAMや世界中の研究機関による小型モデルの開発、私自身も研究室で開催された大規模言語モデルのコンペの結果を見ていた結果などを考慮すると、ほとんどの結論は「大規模言語モデルの性能は大きさが正義である」というものです。\n\n 先ほど大規模言語モデルの小型化の研究を紹介しましたが、それらの研究によって本当に小型化に成功して実運用されている最先端モデルはほとんどなく、実用的な大規模言語モデルの性能を比較・ランキング化するChatbot Arenaというサイトの上位はまさに「大規模言語モデルの性能は大きさが正義である」を体現したような巨大モデルばかりです（参考：https://chat.lmsys.org/）。\n\n ましてGPT-4oの元の旧GPT-4は約1.8兆パラメーターを持つとされる（※これはリーク情報によるもので公式の確定情報ではありません）、特別に大きなモデルです。\n\n GPT-4oがその性能を保ったまま、あそこまで高速に動作するモデルになるのは考えにくいのです。先ほど、小型化の研究をいくつか紹介しましたが、最近の高性能モデルはすでに知識がギリギリまでそのパラメーターに詰め込まれているせいか、圧縮がほとんどできないという報告もあります。\nGPT-4oは一部の機能で性能低下がみられる？\nここまでの議論を考えると、（OpenAIが従来の生成AI技術の枠を超えるオーパーツ的なスーパーテクノロジーを開発しているなどでない限り）GPT-4oは表面上は見えにくいなんらかの能力が犠牲になっていると考えるのが自然です。\n\n これについて、まだ執筆時点でまとまった研究は存在しませんが、SNSなどは、実際に一部の利用形態などで性能が低下していることが報告されています。\n\n たとえばコードの生成については、速度はともかく旧GPT-4のほうが性能が高いという報告がいくつか上がっています。\n\n 一応OpenAIの公式評価ではコードの生成能力もきちんとGPT-4より上であるという結果（HumanEval）が出ているのですが、ベンチマークのように整理されたものではなく、実用上の複雑なコード生成では性能が落ちるのかもしれません。\n\n 知識の幅広さについても、GPT-4と比べると欠けている部分があるという報告があります。\n\n また、大規模言語モデルの評価においては、大規模言語モデルが嘘の出力をする「ハルシネーション」を少なくすることが極めて重視されますが、これについてはある程度第三者によるまとまった評価が出ています。\n\n これによると、GPT-4oは、旧GPT-4どころか、さらにその前のGPT-3.5よりもハルシネーションしやすい（＝嘘の出力をしやすい）という結果になっています。\n\n\n 現時点では、GPT-4oのマルチモーダル機能のほとんどは公開されておらず、現在、我々が確認できるGPT-4oの正確な性能は、ほぼテキスト性能に限られます。\n\n 今後、マルチモーダル機能の開放も進めば、他の機能についても性能が低下している部分が見つかるかもしれません。あるいは、OpenAIが公式の技術報告・論文を出してくる可能性もあります。\nGPT-4oは汎用人工知能（AGI）なのか？\nOpenAIのライブの最後に表示されたスライドには、「Frontier models coming soon」と書いてあります。また、プレゼンターを務めたMuriti氏も「次の大きいことに関するお知らせをすぐにできるかもしれない」と締めくくっています。\n\n GPT-4oの登場を持って、現在のAI技術の最先端は、おおよそ、ほとんどの人が考えるSFの「人間のような」AIそのものになったと言えます。\n\n 運動系の能力はまだですが、それ以外の知的能力に関してはAI研究者たちが「AGI（Artificial General Intelligence、汎用人工知能）」と呼んでいるものに相当近づいています。\n\n というより、数年前の研究者が思い浮かべていたAGIそのものと言ってもいいでしょう。個人的にはChatGPT登場からしばらく経って感覚が麻痺し、研究者の考えるAGIのハードルが上がってしまっていると考えています。\n\n 2022年前半にタイムスリップして、GPT-4oを見せれば、当時の研究者のほとんどは「これはAGIだ！」と言うのではないでしょうか。\n\n 一方で、少し冷静な視点で見ると、今回のGPT-4oは、音声による高速な対話や、感情表現といった、ユーザー体験の部分を強調して見せることで、その成果が少し大げさに受け止められている感もあります（それでも十分にすごいのですが）。\nGPT-5に向けた「たった1秒」の伏線\nそして、OpenAIが見ているところはGPT-4oのさらに先にあるようです。OpenAIは以前からGPT-5の開発をすでに始めていることを公言しています。GPT-4oはあくまで「GPT-4」と付いている以上は、旧GPT-4の延長に過ぎない、OpenAIからすると、ついでの、つなぎのモデルということでしょう。\n\n 次のGPT-5は、本当に現在の我々がAGIと呼ぶものや、あるいは人間の知能を超えるSuper Intelligence（超知能）と呼ばれるものに近い可能性すらあります。\n\n 実はOpenAIのライブでは最後のほうに一瞬だけ伏線がありました。25分26秒-27秒付近に1秒だけ、先ほども少し触れた「Frontier models coming soon」と書かれたスライドが表示されています。\n\n\n OpenAIの中ではすでに次の超高性能モデルが準備できており、近いうちに公開されるのかもしれません。\n執筆：AI研究者（元・東京大学松尾研究室） 今井 翔太,['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140615-biz_plus-000-1-view.jpg?pri=l&w=640&h=358&exp=10800'],"['https://news.yahoo.co.jp/articles/68511c2b317bed30dfe1415ffa37a0bfdab06381/images/000', 'https://www.sbbit.jp/article/cont1/140615#image177687']"
デンソーの「生成AIロボット」は何ができる？「体」を手に入れた生成AIの衝撃の実力（ビジネス＋IT）,https://news.yahoo.co.jp/articles/efe9e8262d5ea0fe8948317754eb2215c964cb4b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140316-biz_plus-000-1-view.jpg?exp=10800,2024-05-28T06:50:05+09:00,2024-05-28T06:50:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,6061,"\n何が凄い？ デンソーが開発した「生成AIロボット」の全貌とは（Photo：sdx15 / Shutterstock.com）\n近年、急速に活用が進む生成AIは、モノづくりを支えるロボットにも大きな変革を起こしている。今回は、ロボットに生成AIを融合させ、新しいロボット活用や、人間とロボットの在り方を探求するデンソーが開発した「生成AIロボット」の全貌を解説する。同社が目指す“ドラえもんの世界”とは何か。\n【詳細な図や写真】従来のロボットオペレーションと、生成AI融合による変化（出典：筆者作成）\n生成AIが「ロボット」を激変させる理由、何が変わるのか？\nロボットは、単に調達すればその日から自社のオペレーションの中ですぐに活躍してくれるわけではない。当然、自社の業務オペレーションや用途に合わせてロボットにインテグレーション（調整・据え付け）が必要になる。あらかじめロボットに実施させたい動作を定義しておき、その通りに動くようにロボットをティーチングすることで、ようやく業務の中で使えるようになるわけだ。\n\n また、そうしたティーチングには、ある程度のノウハウや知見が求められることから、ロボットを導入したいと考える企業の多くは、ロボットシステムインテグレーター（ロボットSI）と呼ばれる企業にティーチングを外注することが多い。\n\n こうした「やってほしい動作を教え込む必要がある」という特徴から、従来型のロボットは、繰り返し業務と相性が良いとされ、たとえば、製造業における加工、塗装、溶接、搬送などの工程において、歴史的にロボットが多く導入されてきた。\n\n 一方で、事前にすべての動作をロボットに学習させておくことは困難であることから、人のニーズに合わせて柔軟に動作を切り替えなければならない作業はロボットの苦手分野とされてきた。そのため、製造業や物流を超えて、一品一様が求められる建設業やサービス業、農業などの分野では一部のロボット導入に留まっていた。\n\n しかし、そうした状況が生成AIとロボットの融合により変わりつつある。事前に動作をすべてティーチングしなくても、自然言語による指示や、その場の状況判断を基に、柔軟に動作を切り替えることができるようになるのだ。\n\n\n これにより、ロボットのティーチングの負荷が最小化されるため、導入企業にノウハウがなくとも、導入しやすくなる。また、今までロボットの導入対象とされてこなかった工程に、ロボットの適用範囲が広がることになる。\n\n ここからは、ロボットに生成AIを融合させることで、新しいロボット活用や、人間とロボットの在り方を模索するデンソーの取り組みを解説する。\nデンソーの生成AIロボット「Generative-AI-Robot」とは\nデンソーが開発した生成AIロボット「Generative-AI-Robot」は、人間との会話の中から実行タスクをロボット自身が判断して動作するロボットだ。事前のティーチング通りに動くロボットとは大きく異なるロボットの在り方なのだ。\n\n たとえば、Generative-AI-Robotに人が話しかけ、「水・お茶・ペンを取って」や「ベルを組み立てて鳴らして」と指示をすると、その指示に応じてロボットが動作を判断・実行する。また、「甘い飲み物が欲しい」「書けるものが欲しい」といったあいまいな指示であっても、生成AIが実施タスクを判断し・実行することができる。\n\n\n Generative-AI-Robotは、人の指示をテキストに変換する音声認識AIと、その指示から実行タスクを判断する生成AIの大きく2つの仕組みによって構成されている。\n\n まず、あいまいなものも含めた人の指示や会話を音声認識AIがテキスト化する。そのテキスト化された人の指示を基に、「スキル」と呼ばれる事前にプログラムされた小さい単位の動作モジュール（例：掴む、組み立てる、渡す）などを組み合わせ、「どのタスクを実施すべきか」を生成AIが判断する仕組みだ。生成AIには、事前にどういったスキルができるロボットなのかなどをプロンプトとして指示をしており、その前提に基づきロボットは動作する。\n「生成AI×ロボット」が活躍する分野\nデンソーは、Generative-AI-Robotのような生成AIロボットの登場により、今までロボットの導入対象であった製造業の大量生産ラインから導入シーンは大きく広がり、人が作業をするシーンすべてが導入範囲になっていくと考えている。\n\n たとえば、製造業においては、製品のニーズやライフサイクルの変化の中で、「試作段階」、「大量生産段階」、「少量生産段階」といった段階を踏むことが一般的だ。\n\n このうち「大量生産段階」では、従来通り、事前のティーチングが必要なロボットが活用され、高速で同じ作業を繰り返す製造ラインとなるだろう。\n\n 一方、今回のGenerative-AI-Robotが対象とするのは、「試作段階」や「少量生産段階」となる。これらの段階で利用されるロボットには、状況や生産計画に応じてフレキシブルにオペレーションを変えることができる能力が求められる。\n\n たとえば、そうした領域において使われている従来の協働ロボットは、動作速度が遅いほか、衝突停止機能が付いていることから、ロボットの周りに設置する柵（工場内で働く人間の安全確保のため）の必要のない「安全な産業ロボット」としての使い方が主流であり、本当の意味で人間と作業を協働して取り組むケースはまれであった。\n\n 一方、Generative-AI-Robotはこうした協働ロボットと人の連携の在り方も変えることになり得る。\n\n 加えて、食品製造業、建設業などの人との協働が求められるかつ、フレキシブルな対応が求められるモノづくりの領域や、物流・小売・医療・サービス業、さらには農業をはじめとした1次産業、そして通信がなくとも自律的に復旧し動作する宇宙ロボット、家庭内で人と一緒に調理するロボット、部屋の状況を判断し分担して片付けをしてくれるロボットなど、生成AIとの融合によって今までロボットが導入されてこなかった分野に適用範囲が広がっていくかもしれない。\n\n\n 今までも人とコミュニケーションしながら協働するロボットやソフトウェア開発の取り組みは、AIコンシェルジュなどをはじめ、あらゆる企業によって取り組みがすすめられてきた。ただし、それの多くは、デジタルの「画面上」における“人との協調”の域を超えていないケースがほとんどであった。\n\n 一方、Generative-AI-Robotでは、AIが分析・検討した結果を踏まえ、ロボットが人間と協働しながら動作をすることにより、デジタル空間の枠を越え、現実空間とつながるようになる。\n\n 「生成AIには身体性がない（物理的な実行手段がない）」と言われていたが、デンソーの取り組みは、生成AIの分析・検討結果に、物理的な実行手段・身体性（＝ロボット）を付与することになる大きな変化である。\n生成AIでロボットの「ティーチング」はどう変わる？\nまた、生成AIにより、ロボットの動作をプログラムするティーチングの在り方も大きく変わる。今まではティーチングペンダントと呼ばれる入力・操作装置を使い、専門知識を有するエンジニアがロボットに動作をプログラムしていた。\n\n 一方、同社のGenerative-AI-Robotでは、「つかむ」「わたす」「組み立てる」などの基本スキルは事前にプログラムをする必要があるものの、それらをどう組み合わせて動作するかは、生成AI自身が考えて実施することになる。そのため、動作全体は、生成AIとのコミュニケーションを通じて、生成AIに考えさせながらプログラムしていくことになる。\n\n たとえば、予想外の動作をした際に、ロボットに対して「なぜそのような動作をしたのか」と聞くと、AI側が「●●と考えるから、XXと動作しました」と回答するとする。それに対して、「じゃあここを修正しようか」と指示を出し、プロンプトに盛り込んでいくことにより、人間の意思を伝えながらロボットを作り上げていく形へと変化してきている。\n\n これにより、ロボットの導入やインテグレーション自体も民主化していくこととなる。専門のエンジニアや、ロボットSIerと呼ばれるロボットのインテグレーションを行う専門企業がいなくとも、事前のモジュールが定義されていれば、ロボット導入企業自身が、直接ロボットとの対話の中で、ロボット動作のプログラミングや、ロボットの調整ができるようになる世界も想定される。\n【事例】カフェ店員「生成AIロボット」の衝撃の働きぶり\nさらには、事前にプログラムした小さな動作単位（スキル）を組み合わせて、生成AI自体が新しいスキルを考えて作り出す可能性も出てくるだろう。デンソーとしては、今後、指示通りに動作してくれるだけではなく、自分なりに考えて工夫をし、人間が想定していなかった新しい方法で課題にアプローチすることができるロボットの在り方を提示していく考えだ。これにより、人間の意図とロボットの工夫により新しいオペレーションが生まれるかもしれない。\n\n 実際に、Generative-AI-Robotがカフェのバリスタ業務を担当したときの事例がある。事前に作り方を教えていない「アメリカン（コーヒーをお湯で割った飲み方）」の注文を受けたが、これに対し、アメリカン＝薄いコーヒーという知識を基に、試行錯誤しながらコーヒーをウォーターサーバーの水で割って提供したのだ。\n\n このアメリカンの例は一例でしかないが、そのほかの領域においても目的の実行にあたって、人間の常識では思いつかない新しい方法をロボットなりに考えて実行していく可能性を持っていると、Generative-AI-Robot推進チームは語る。\n\n もちろん、大量生産の工場においては、決められたプロセスで正確に実施することが求められ、ロボットが自分なりに考えて新しい方法を提案することは許されないが、別のフィールドにおいては新しい発想・価値として期待される。また、プログラムの動作にエラーがでた際に、ロボット自身が考え直して自身で復旧してやり直すということもできるようになってきている。\n\n 工場においては、そぎ落として余分な動きをなくし限界まで効率化したシンプル・単純化した形でロボットが重要であった。しかし、その他の領域のロボット展開においては可能性を広げていく方向性で生成AI×ロボットを育てていくことが重要だろう。\nデンソーが「ロボットが醸し出す雰囲気」を重視する理由\nこれまでデンソーは、生産現場におけるたった1秒のカイゼンを生み出すべく、あらゆる開発に取り組んできたが、Generative-AI-Robotはこれまでとはまったく異なる開発アプローチとなっている。\n\n キーワードは「ヒューマンセントリック（人間中心）」だ。ヒューマンセントリックなロボット作りでは、ロボットと人間の関係性や、人間がロボットに話しかけたり、仕事を依頼しやすい雰囲気・環境をデザインすること、さらにロボット側が人間を理解したり、感情に寄り添ったりできるかが、開発における重要なポイントになる。\n\n つまり、従来のように、ロボットの性能や機能を追求していくだけでなく、Generative-AI-Robotを通じた、人間側の体験や価値、感情や行動の変化をデザインしていくことが求められるのだ。\n\n たとえば、待機時間がその例だ。これまで、稼働していないロボットは、当然ながらその時間、下を向いている状況があった。一方、人と人のコミュニケーションにおいては、「下を向いている人」に対して話しかけにくさを感じるはずだ。人と協働することを想定する場合、こうした人同士のコミュニケーションにおける当たり前をロボットに取り入れていくことが求められる。\n\n たとえば、デンソーのGenerative-AI-Robotでは、人間がロボットに話しかけやすいよう、人の目を見て「こんにちは」「今日はどこから来たのですか？」などと話しかけ、人間が話しかけやすくなるキッカケを生むとともに、その後の会話につながる仕掛けづくりも行う。また待機姿勢（ロボットが稼働していない時間）もピッタリと停止しているのではなく、少しだけロボットの身体を揺らすことにより、人間に安心感を与える工夫が盛り込まれている。\n\n これはゲームのキャラクターが待機時間にも揺れの動作をしていることからヒントを得たという。デンソーとしては、今後ロボットの筐体のデザインも、ムダを排除した機能性の高いデザインから、より人間にとって安心感を与えるものへと変化していくと考えているようだ。\nデンソーが目指す「ドラえもんの世界」のようなロボット像\n今後、デンソーは先述の生成AIロボットが実施できる動作単位の「スキル」の拡充・蓄積を図るとともに、既存の「スキル」から新しいスキルを組み合わせて提案する力や、会話や環境認識・状況判断からロボット側に実行内容を考えさせる能力の精度を向上させていく考えだ。 \n\n また、現在は人の指示を認識する上で、「耳」を通じてロボットが実行内容を認識・検討しているが、今後は生成AIのマルチモーダル化が進む中で、ロボットの「目」としてのセンシング結果を活用することや、生産管理システムなどのシステムからの指示などを踏まえた実行検討・判断ができるよう発展させていく方針だ。\n\n 加えて、ドラえもんの世界のようにロボットと人との境目がなくなる中で、よりロボットが表情を持つことによって、人間が安心感を覚え、インタラクションが加速するヒューマンセントリックな生成AIロボットを追求していく考えだ。\n\n デンソーは、こうしたGenerative-AI-Robotを通じて今までのロボットの在り方や、人間との関係性の在り方をデザインし、より広い産業や工程にロボットを展開していくソリューション企業になっていくことを目指す。\n\n これまでデンソーは、産業用ロボットや協働ロボットの展開、FA（Factory Automation）と呼ばれる自動化支援により、あらゆる業界の企業を支援してきたが、Generative-AI-Robotによってその範囲や価値を拡張していくかもしれない。そんなデンソーの今後に注目したい。\n執筆：d-strategy,inc 代表取締役 、東京国際大学 特任准教授 小宮昌人",['https://newsatcl-pctr.c.yimg.jp/t/amd-img/20240528-00140316-biz_plus-000-1-view.jpg?pri=l&w=640&h=360&exp=10800'],"['https://news.yahoo.co.jp/articles/efe9e8262d5ea0fe8948317754eb2215c964cb4b/images/000', 'https://www.sbbit.jp/article/st/140316#image177443']"
